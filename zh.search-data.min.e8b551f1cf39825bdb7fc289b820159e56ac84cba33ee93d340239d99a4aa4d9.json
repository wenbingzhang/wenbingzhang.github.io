[{"id":0,"href":"/notes/2025/05/13/gfegatfpustuecdeaifds7/","title":"📝 defer实现","section":"🔖 Qt","content":" 实现类似Golang的defer的方式 # // // Created by 张文兵 on 2025/5/13. // #ifndef DEFER_H #define DEFER_H #include \u0026lt;functional\u0026gt; class Defer { public: explicit Defer(const std::function\u0026lt;void()\u0026gt; \u0026amp;func) : m_func(func) { } ~Defer() { m_func(); } // 离开作用域时自动调用 private: std::function\u0026lt;void()\u0026gt; m_func; }; #endif //DEFER_H 使用方式 # m_mutex.lock(); Defer defer([=]() { m_mutex.unlock(); }); "},{"id":1,"href":"/notes/2025/04/28/akhjvrsank3gkyirsrxgtc/","title":"📝 运行是崩溃","section":"🔖 build","content":" 启动软件时崩溃(crash) # 正常编译时没出现报错，但是运行时立即报段错误，且只有部分编译器存在这个问题\n解决方案 # 发现引入的sdk编译的时候没有添加-fPIC参数。\n-fPIC的作用 # -fPIC 是 Position Independent Code（位置无关代码） 的意思。\n它告诉编译器：生成的机器代码不能包含硬编码的绝对地址，而是要通过相对地址或表格跳转来访问数据和函数。这样，编译好的目标文件（比如 .o 文件）就可以被放到内存的任何位置执行，不需要在运行时修改代码本身。\n动态链接库（.so） # 动态库在运行时会被加载到任意的内存位置（取决于系统的调度、内存情况等）。\n如果目标文件里有固定地址（绝对地址），那一旦加载到不同位置，地址就错了，程序就崩了。\n所以，编译成动态库的 .o 文件必须加 -fPIC，保证它在任何位置都能正确执行。\n总结： # 编动态库时，一定要加 -fPIC，否则链接时出错，或者运行时崩溃。\n静态链接库（.a） # 静态库在链接阶段直接被打包到可执行文件中。\n可执行文件的链接器（ld）会知道最终程序要加载到哪儿，因此理论上可以不用 -fPIC。\n但是！如果你把静态库拿去生成动态库（比如 gcc -shared 链接 .a 文件），又出现了同样的问题\n总结： # 普通程序链接静态库时可以不加 -fPIC，但如果要把 .a 打包进 .so，静态库也必须是 -fPIC 编译的。\n"},{"id":2,"href":"/notes/2025/02/10/7auahqg8nnxm5ydhxzqrnr/","title":"📝 调用Python代码","section":"🔖 Python","content":"#include \u0026lt;cstdio\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;Python.h\u0026gt; // 包含 Python 头文件 int main() { // 初始化 Python 解释器 Py_Initialize(); // 创建一个 Python 字典来传递参数 PyObject* pName = PyUnicode_FromString(\u0026#34;__main__\u0026#34;); PyObject* pModule = PyImport_Import(pName); Py_XDECREF(pName); if (pModule != nullptr) { // 创建一个全局字典来存储参数 PyObject* pGlobals = PyModule_GetDict(pModule); // 将参数作为 Python 对象添加到全局字典中 PyDict_SetItemString(pGlobals, \u0026#34;param1\u0026#34;, PyLong_FromLong(42)); // 示例参数1 PyDict_SetItemString(pGlobals, \u0026#34;param2\u0026#34;, PyUnicode_FromString(\u0026#34;Hello from C++\u0026#34;)); // 示例参数2 // 定义并执行 Python 代码 const char* script = R\u0026#34;( import platform import sys import os system_info = { \u0026#39;param1\u0026#39;: param1, \u0026#39;param2\u0026#39;: param2, \u0026#39;OS\u0026#39;: platform.system(), \u0026#39;OS Version\u0026#39;: platform.version(), \u0026#39;Release\u0026#39;: platform.release(), \u0026#39;Machine\u0026#39;: platform.machine(), \u0026#39;Processor\u0026#39;: platform.processor(), \u0026#39;Python Version\u0026#39;: sys.version, } print(system_info) )\u0026#34;; // 执行 Python 代码 const auto result = PyRun_SimpleString(script); std::cout \u0026lt;\u0026lt; \u0026#34;Result from Python: \u0026#34; \u0026lt;\u0026lt; result \u0026lt;\u0026lt; std::endl; Py_XDECREF(pModule); } else { PyErr_Print(); std::cerr \u0026lt;\u0026lt; \u0026#34;Failed to load the Python script\u0026#34; \u0026lt;\u0026lt; std::endl; } // 关闭 Python 解释器 Py_Finalize(); return 0; } "},{"id":3,"href":"/notes/2024/08/01/rnc4n7cfifidx8ca2rhjme/","title":"📝 QML鼠标事件","section":"🔖 QtQml","content":" 示例代码 # import QtQuick 2.15 import QtQuick.Controls 2.15 ApplicationWindow { visible: true width: 640 height: 480 Rectangle { id: container width: 200 height: 200 color: \u0026#34;lightblue\u0026#34; MouseArea { anchors.fill: parent onEntered: { console.log(\u0026#34;Mouse entered\u0026#34;) container.color = \u0026#34;lightgreen\u0026#34; } onExited: { console.log(\u0026#34;Mouse exited\u0026#34;) container.color = \u0026#34;lightblue\u0026#34; } } } } 问题描述 # 鼠标进入矩形区域时，不会改变矩形的颜色。\n解决方法 # 需要在MouseArea中设置hoverEnabled: true属性，这样鼠标进入矩形区域时，会触发onEntered事件，改变矩形的颜色。\n"},{"id":4,"href":"/notes/2024/06/06/sf4ff6x8cuyhvzougj9dwg/","title":"📝 MacOS签名","section":"🔖 MacOS","content":" 下载根证书 # https://www.apple.com/certificateauthority/DeveloperIDG2CA.cer\n导入根证书 # sudo security import ~/Downloads/DeveloperIDG2CA.cer \\ -k /Library/Keychains/System.keychain \\ -T /usr/bin/codesign \\ -T /usr/bin/security \\ -T /usr/bin/productbuild 查看和清理特殊属性 # xattr -lr xxx.app xattr -cr xxx.app 签发APP # codesign --deep --force --verbose --sign \u0026#34;xxxx\u0026#34; xxx.app 验证签名 # spctl --assess --type execute --verbose=4 xxx.app 参考文档 # https://testerhome.com/topics/33338\nhttps://www.apple.com/certificateauthority/\nhttps://www.jianshu.com/p/f420649fba42\n"},{"id":5,"href":"/notes/2024/03/11/j3c62fv8dglvf2kg975zlv/","title":"📝 标签操作","section":"📔 Git","content":" 创建标签 # git tag \u0026lt;tagname\u0026gt; 推送标签到远程仓库 # git push origin \u0026lt;tagname\u0026gt; 推送所有标签到远程仓库 # git push origin --tags 查看本地所有标签 # git tag 查看远程所有标签 # git ls-remote --tags origin 删除本地或远程标签 # git tag -d \u0026lt;tagname\u0026gt; # 删除远程标签 git push origin :refs/tags/\u0026lt;tagname\u0026gt; "},{"id":6,"href":"/notes/2024/03/06/e3ksq3zkmps14gcxuirwzx/","title":"📝 所有权","section":"🔖 学习笔记","content":" 所有权 # 所有权规则 # Rust 中的每一个值都有一个 所有者（owner）。 值在任一时刻有且只有一个所有者。 当所有者（变量）离开作用域，这个值将被丢弃。 可Copy的类型 # 所有整数类型，比如 u32 。 布尔类型，bool ，它的值是 true 和 false 。 所有浮点数类型，比如 f64 。 字符类型，char 。 元组，当且仅当其包含的类型也都实现 Copy 的时候。比如，(i32, i32) 实现了 Copy ，但(i32, String) 就没有。 "},{"id":7,"href":"/notes/2025/05/13/6dhpyx7jyybzrnvw7qremy/","title":"📝 异步更新UI","section":"🔖 Qt","content":" 异步定时更新UI # 尽量的减少卡UI问题\n// // Created by 张文兵 on 2025/5/13. // #ifndef TASKRUNNER_H #define TASKRUNNER_H #include \u0026lt;QFuture\u0026gt; #include \u0026lt;QElapsedTimer\u0026gt; #include \u0026lt;QtConcurrent\u0026gt; #include \u0026lt;atomic\u0026gt; #include \u0026lt;functional\u0026gt; #include \u0026lt;QThread\u0026gt; class TaskRunner { public: TaskRunner() = default; ~TaskRunner() { stop(); } void start(const int intervalMs, const std::function\u0026lt;void()\u0026gt; \u0026amp;task) { if (m_future.isRunning()) { return; } m_exit = false; m_future = QtConcurrent::run([=]() { QElapsedTimer timer; task(); // 立即执行一次 timer.start(); while (!m_exit) { if (timer.elapsed() \u0026gt;= intervalMs) { task(); // 周期执行 timer.restart(); } if (!m_exit) { QThread::msleep(100); // 可调精度 } } }); } void stop() { m_exit = true; if (m_future.isRunning()) { m_future.waitForFinished(); } } private: std::atomic\u0026lt;bool\u0026gt; m_exit = false; QFuture\u0026lt;void\u0026gt; m_future; }; #endif //TASKRUNNER_H 使用方式 # // 运行任务 m_taskRunner-\u0026gt;start(5000, [this]() { onUpdateTaskInfo(); }); // 停止任务 m_taskRunner-\u0026gt;stop(); "},{"id":8,"href":"/notes/2025/04/30/fqog2lfxmepcxbbyzucxeq/","title":"📝 内存重叠","section":"🔖 build","content":" sprintf/snprintf 与内存重叠问题分析（Ubuntu/Debian） # 背景 # 在 Ubuntu/Debian 系统中，最近针对 sprintf 和 snprintf 函数在内存重叠情况下的行为展开了讨论。尤其是在启用编译器优化选项后，这类问题可能导致程序行为异常，甚至出现数据丢失。\n函数原型与 restrict 关键字 # int sprintf(char *restrict s, const char *restrict format, ...); restrict 是 C99 引入的关键字，用于告诉编译器该指针是访问其指向内存的唯一手段。这意味着多个参数如果指向同一块内存区域，则行为是未定义的（undefined behavior）。\n问题示例 # 许多程序员在使用 sprintf 时，将其作为增强版的 strcat 使用，例如：\nsprintf(buf, \u0026#34;%s foo %d %d\u0026#34;, buf, var1, var2); 在上述代码中，第一个参数和第三个参数（buf）指向同一内存区域，违反了 restrict 语义。这种用法虽然广泛存在，但属于未定义行为，可能在某些编译环境下出现问题。\n示例代码 # 以下程序在 GCC 中，启用优化（如 -O1, -O2）后会输出 \u0026quot;fail\u0026quot;，而不是预期的 \u0026quot;not fail\u0026quot;：\n#include \u0026lt;stdio.h\u0026gt; char buf[80] = \u0026#34;not \u0026#34;; int main() { sprintf(buf, \u0026#34;%sfail\u0026#34;, buf); puts(buf); // 输出可能为 \u0026#34;fail\u0026#34; return 0; } 解释 # 在启用优化时，GCC 假设 buf 只被 sprintf 的第一个参数修改，因此可能先清空目标内存，从而导致源字符串内容丢失。\n推荐做法 # 为了避免此类未定义行为，推荐使用以下方式：\nsprintf(buf + strlen(buf), \u0026#34; foo %d %d\u0026#34;, var1, var2); 这样可以确保目标内存与源数据不重叠，符合 restrict 的语义。\n关于 snprintf # snprintf 同样存在类似问题，因为其第一个参数也是带有 restrict 限定的指针。\n总结 # sprintf 和 snprintf 的参数不能指向重叠的内存区域。 启用编译器优化时，使用重叠内存的 sprintf 调用可能导致意料之外的结果。 正确做法是将目标地址移至字符串末尾，避免与源数据冲突。 参考 # C99 标准文档中关于 restrict 的定义 GCC 编译器行为与优化策略 "},{"id":9,"href":"/notes/2025/02/10/gqci9riugfetribe6j6fou/","title":"📝 调用Python方法","section":"🔖 Python","content":"#include \u0026lt;Python.h\u0026gt; #include \u0026lt;iostream\u0026gt; int main() { // 初始化 Python 解释器 Py_Initialize(); // 创建 Python 字典并将参数传递给 Python PyObject* pName = PyUnicode_FromString(\u0026#34;__main__\u0026#34;); PyObject* pModule = PyImport_Import(pName); Py_XDECREF(pName); if (pModule != nullptr) { // 创建一个全局字典来存储参数 PyObject* pGlobals = PyModule_GetDict(pModule); // 创建 Python 函数 const char* func_code = R\u0026#34;( def my_function(param1, param2): return f\u0026#34;Received param1: {param1}, param2: {param2}\u0026#34; )\u0026#34;; // 执行定义函数的代码 PyRun_SimpleString(func_code); // 获取 Python 函数对象 PyObject* pFunc = PyDict_GetItemString(pGlobals, \u0026#34;my_function\u0026#34;); if (PyCallable_Check(pFunc)) { // 准备参数 PyObject* pArgs = PyTuple_Pack(2, PyLong_FromLong(42), PyUnicode_FromString(\u0026#34;Hello from C++\u0026#34;)); // 调用函数 PyObject* pValue = PyObject_CallObject(pFunc, pArgs); if (pValue != nullptr) { // 打印函数返回值 std::cout \u0026lt;\u0026lt; \u0026#34;Function returned: \u0026#34; \u0026lt;\u0026lt; PyUnicode_AsUTF8(pValue) \u0026lt;\u0026lt; std::endl; Py_XDECREF(pValue); } else { PyErr_Print(); } Py_XDECREF(pArgs); } else { PyErr_Print(); } } else { PyErr_Print(); std::cerr \u0026lt;\u0026lt; \u0026#34;Failed to load the Python module\u0026#34; \u0026lt;\u0026lt; std::endl; } // 关闭 Python 解释器 Py_Finalize(); return 0; } "},{"id":10,"href":"/notes/2024/08/06/ny773erqjgbzmzgfikfvds/","title":"📝 QML虚拟列表","section":"🔖 QtQml","content":"import QtQuick 2.15 import QtQuick.Controls 2.15 ApplicationWindow { visible: true width: 640 height: 28 Flickable { id: flickable width: parent.width height: parent.height contentWidth: 51200 // 根据需要调整刻度尺长度（1000个刻度，每个刻度间隔51.2） clip: true Component.onCompleted: updateVisibleRange() onContentXChanged: updateVisibleRange() onWidthChanged: updateVisibleRange() function updateVisibleRange() { var itemWidth = 51.2; var firstIndex = Math.floor(flickable.contentX / itemWidth); var visibleCount = Math.ceil(flickable.width / itemWidth) + 1; firstVisibleIndex = firstIndex; lastVisibleIndex = firstIndex + visibleCount; createVisibleItems(); } property int firstVisibleIndex: 0 property int lastVisibleIndex: 0 function createVisibleItems() { itemContainer.children.forEach(function(item) { item.destroy(); }); for (var i = firstVisibleIndex; i \u0026lt;= lastVisibleIndex; i++) { var item = itemComponent.createObject(itemContainer, { index: i, width: 1, height: flickable.height, x: i * 51.2 }); } } Item { id: itemContainer anchors.fill: parent } Component { id: itemComponent Item { property int index Rectangle { property int itemIndex: index anchors.bottom: parent.bottom width: 1 height: index % 10 === 0 ? 18 : index % 5 === 0 ? 9 : 4 color: \u0026#34;black\u0026#34; Repeater { model: index % 10 === 0 ? 1 : 0 Label { anchors.left: parent.right anchors.leftMargin: 2 anchors.bottom: parent.bottom anchors.bottomMargin: 4 // color: activePalette.windowText text: parent.itemIndex } } } } } } } "},{"id":11,"href":"/notes/2024/05/28/3txbbb7iruppjsg4p7rwnb/","title":"📝 MacOS堆栈大小","section":"🔖 MacOS","content":" 问题代码 # char buffer[8*1024*1024]; 问题分析 # macos系统默认的堆栈大小为8MB，可以通过ulimit命令查看和修改。 但是，如果代码中使用了大量的堆栈变量，可能会导致栈溢出，导致程序崩溃。 # 查看系统默认的堆栈大小 ulimit -a # 或者 ulimit -s 解决方案 # char *buffer = new char[8*1024*1024]; // 记得释放 delete[] buffer; "},{"id":12,"href":"/notes/2024/03/14/5kqlzqjqawbxf2t6vusxar/","title":"📝 删除Commit","section":"📔 Git","content":"# 获取commit信息 git log # commit-id 要删除commit的下一个commit-id git rebase -i (commit-id) # 编辑文件，将要删除的commit之前的pick改为drop # 保存文件退出 # 再次查看commit信息，确认删除成功 git log "},{"id":13,"href":"/notes/2024/03/06/o4arkqgfnqygr5ckif2gkk/","title":"📝 借用与引用","section":"🔖 学习笔记","content":" 借用与引用 # 创建一个引用的行为称为 借用 允许使用值但不获取其所有权 引用规则 # 在任意给定时间，要么 只能有一个可变引用，要么 只能有多个不可变引用。 引用必须总是有效的。 可变引用 # 允许修改一个借用的值，这就是可变引用（\u0026amp;mut）。\nfn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); change(\u0026amp;mut s); } fn change(some_string: \u0026amp;mut String) { some_string.push_str(\u0026#34;, world\u0026#34;); } 悬垂引用（Dangling References） # fn main() { let reference_to_nothing = dangle(); } fn dangle() -\u0026gt; \u0026amp;String { // dangle 返回一个字符串的引用 let s = String::from(\u0026#34;hello\u0026#34;); // s 是一个新字符串 \u0026amp;s // 返回字符串 s 的引用 } // 这里 s 离开作用域并被丢弃。其内存被释放。 // 危险！ "},{"id":14,"href":"/notes/2025/02/10/pkdrvn9md3ggfmbxahx4ef/","title":"📝 注册Python模块","section":"🔖 Python","content":"#include \u0026lt;Python.h\u0026gt; #include \u0026lt;iostream\u0026gt; // 示例结构体（C++对象） struct MyStruct { int value; }; // C++ 从 Python 获取 `void*` 并使用 static PyObject* use_object(PyObject* self, PyObject* args) { PyObject* capsule; if (!PyArg_ParseTuple(args, \u0026#34;O\u0026#34;, \u0026amp;capsule)) { return nullptr; } // 取回 `void*` 并转换回 C++ 指针 auto* obj = static_cast\u0026lt;MyStruct*\u0026gt;(PyCapsule_GetPointer(capsule, \u0026#34;this\u0026#34;)); if (!obj) { PyErr_SetString(PyExc_RuntimeError, \u0026#34;Invalid capsule!\u0026#34;); return nullptr; } std::cout \u0026lt;\u0026lt; \u0026#34;Received C++ object with value: \u0026#34; \u0026lt;\u0026lt; obj-\u0026gt;value \u0026lt;\u0026lt; std::endl; return PyLong_FromLong(obj-\u0026gt;value); } // Python 方法表 static PyMethodDef CppMethods[] = { {\u0026#34;use_object\u0026#34;, use_object, METH_VARARGS, \u0026#34;Use a C++ object from PyCapsule\u0026#34;}, {nullptr, nullptr, 0, nullptr} }; // Python 模块定义 static struct PyModuleDef cppModule = { PyModuleDef_HEAD_INIT, \u0026#34;cppModule\u0026#34;, nullptr, -1, CppMethods }; // 初始化 Python 模块 PyMODINIT_FUNC PyInit_cppModule(void) { return PyModule_Create(\u0026amp;cppModule); } int main() { // 初始化 Python 解释器 Py_Initialize(); PyObject* pModule = PyImport_AddModule(\u0026#34;__main__\u0026#34;); PyObject* pGlobals = PyModule_GetDict(pModule); // 注册 C++ 方法到 Python PyObject* pCppModule = PyModule_Create(\u0026amp;cppModule); PyDict_SetItemString(pGlobals, \u0026#34;cppModule\u0026#34;, pCppModule); // 执行 Python 代码 const auto python_code = R\u0026#34;( def my_function(capsule): result = cppModule.use_object(capsule) # 传回 C++ 处理 print(f\u0026#34;Python received: {result}\u0026#34;) return result )\u0026#34;; PyRun_SimpleString(python_code); // 获取 Python 函数对象 if (PyObject* pFunc = PyDict_GetItemString(pGlobals, \u0026#34;my_function\u0026#34;); PyCallable_Check(pFunc)) { auto* obj = new MyStruct{42}; // 创建 C++ 对象 const auto capsule = PyCapsule_New(obj, \u0026#34;this\u0026#34;, nullptr); // 返回封装的指针 // 准备参数 PyObject* pArgs = PyTuple_Pack(1, capsule); // 调用函数 if (PyObject* pValue = PyObject_CallObject(pFunc, pArgs); pValue != nullptr) { // 打印函数返回值 std::cout \u0026lt;\u0026lt; \u0026#34;Function returned: \u0026#34; \u0026lt;\u0026lt; PyLong_AsLong(pValue) \u0026lt;\u0026lt; std::endl; Py_XDECREF(pValue); } else { PyErr_Print(); } Py_XDECREF(pArgs); } else { PyErr_Print(); } // 关闭 Python 解释器 Py_Finalize(); return 0; } "},{"id":15,"href":"/blog/git/WNYzxj6GR/","title":"📝 git之删除远程分支","section":"📔 Git","content":" git删除远程分支就这么简单\ngit push origin --delete [branch_name] "},{"id":16,"href":"/blog/git/-fZeBsu3T/","title":"📝 git更新.gitignore","section":"📔 Git","content":" 一般直接修改.gitignore是不生效的，需要先清理缓存，再修改.gitignore。\ngit rm -r --cached . git add . git commit -m \u0026#39;update .gitignore\u0026#39; "},{"id":17,"href":"/blog/git/H1Krv6b-4/","title":"📝 git修改历史cimmit信息","section":"📔 Git","content":" git 使用rebase修改历史提交的cimmit信息\n1、修改指定commit # git rebase -i 36224db 或:\ngit rebase -i HEAD~3 2、把pick改为edit # pick：保留该commit（缩写:p）\nreword：保留该commit，但我需要修改该commit的注释（缩写:r）\nedit：保留该commit, 但我要停下来修改该提交(不仅仅修改注释)（缩写:e）\nsquash：将该commit和前一个commit合并（缩写:s）\nfixup：将该commit和前一个commit合并，但我不要保留该提交的注释信息（缩写:f）\nexec：执行shell命令（缩写:x）\ndrop：我要丢弃该commit（缩写:d）\n3、修改commit信息 # git commit --amend git rebase --continue 4、推送到远程仓库 # git push -f origin master "},{"id":18,"href":"/blog/git/By9OI51xN/","title":"📝 git基础笔记","section":"📔 Git","content":" git是一个开源的分布式版本控制系统，可以有效、高速的处理从很小到非常大的项目版本管理。\n克隆项目 # git clone https://github.com/golang/go.git 查看远程仓库 # git remote -v 添加远程仓库 # 要添加一个新的远程仓库，可以指定一个简单的名字，以便将来引用，运行 git remote add [shortname] [url]：\ngit remote add pb https://github.com/golang/go.git 现在可以用字符串 pb 指代对应的仓库地址了。比如说，要抓取所有 Paul 有的，但本地仓库没有的信息，可以运行 git fetch pb\n从远程仓库抓取数据 # git fetch [remote-name] 推送数据到远程仓库 # git push [remote-name] [branch-name]\ngit push origin master 查看远程仓库信息 # git remote show [remote-name]\ngit remote show origin 重命名远程仓库 # git remote rename old_remote-name new_remote-name\ngit remote rename pb test 删除远程仓库 # git remote rm remote-name\ngit remote rm test "},{"id":19,"href":"/blog/git/Hk6GGp6cQ/","title":"📝 Git回滚到某个commit","section":"📔 Git","content":" git是一个开源的分布式版本控制系统，可以有效、高速的处理从很小到非常大的项目版本管理。\n回滚命令 # git reset --hard HEAD^ #回滚到上个版本 git reset --hard HEAD~3 #回滚到前3次提交之前，以此类推，回退到n次提交之前 git reset --hard commit_id #回滚到指定commit的sha版本 推送命令 # git push origin HEAD --force #强制推送到远程 温馨提示 # 回滚有风险，请提前做好备份。\n"},{"id":20,"href":"/links/","title":"🤝 友情链接","section":"Docs","content":" "},{"id":21,"href":"/articles/2025/05/13/zjrbjxuzwztru8utgsmvbf/","title":"FFmpeg自动检测裁剪黑边","section":"📚 我的文章","content":"#!/bin/bash # 用法提示 if [ \u0026#34;$#\u0026#34; -ne 1 ]; then echo \u0026#34;用法: $0 \u0026lt;输入文件路径\u0026gt;\u0026#34; exit 1 fi INPUT=\u0026#34;$1\u0026#34; OUTPUT=\u0026#34;${1%.*}\u0026#34; OUTPUT_EXT=\u0026#34;${1##*.}\u0026#34; # 自动检测 crop 参数 CROP=$(ffmpeg -i \u0026#34;$INPUT\u0026#34; -vf cropdetect=24:16:0 -t 30 -f null - 2\u0026gt;\u0026amp;1 | grep -o \u0026#39;crop=[^ ]*\u0026#39; | sort | uniq -c | sort -nr | head -n1 | awk \u0026#39;{print $2}\u0026#39;) if [ -z \u0026#34;$CROP\u0026#34; ]; then echo \u0026#34;未能检测到有效的 crop 参数\u0026#34; exit 1 fi echo \u0026#34;检测到裁剪参数: $CROP\u0026#34; # 执行裁剪 ffmpeg -i \u0026#34;$INPUT\u0026#34; -vf \u0026#34;$CROP\u0026#34; -c:v libx264 -crf 10 -c:a copy \u0026#34;${OUTPUT}_crop.${OUTPUT_EXT}\u0026#34; "},{"id":22,"href":"/articles/2024/12/23/wvkjyjt7qhumo4jpucheca/","title":"Linux硬盘故障相关的查询命令","section":"📚 我的文章","content":" 查看硬盘及对应的UUID信息 # # 查看硬盘及对应的UUID信息 或者是所有硬盘的UUID信息 blkid [/dev/sda1] # lsblk -o NAME,UUID -p 查看UUID对应的硬盘路径 # blkid -U 383bc776-fc1a-4040-ad8f-45f4f5d96fcf 查看硬盘信息 # lshw -class disk 检测磁盘是否损坏 # badblocks -b 4096 -v /dev/sda # 也有坏快的屏蔽方式这个里就不列举了 点亮硬盘LED # dd if=/dev/sda of=/dev/null bs=1M count=100 # 点亮硬盘LED 查看服务器序列号 # dmidecode -t 1 # 查看对应的\u0026#39;Serial Number\u0026#39;字段 "},{"id":23,"href":"/articles/2024/11/15/mcagbs9lfdrnxxu9k29t9j/","title":"使用FFmpeg生成测试视频","section":"📚 我的文章","content":" 生成23.976fps的测试视频 # ffmpeg -f lavfi -i testsrc=size=1280x720:rate=30 -vf \u0026#34;drawtext=text=\u0026#39;%{pts\\:hms} %{n}\u0026#39;:x=(w-text_w)/2:y=100:fontsize=48:fontcolor=white:boxcolor=black@0.5:borderw=2\u0026#34; -r 23.976 -t 10 -y output.mp4 "},{"id":24,"href":"/articles/2024/03/27/e4c2nybngzu5eddbnmdjgq/","title":"Mamba替代Conda","section":"📚 我的文章","content":"mamba是一个conda的替代品，可以加速conda的包管理，提升包管理的效率。\n安装 # brew install micromamba 配置 # # 根据命令提示，修改~/.zshrc文件 micromamba shell init -s zsh -p ~/.micromamba # 添加配置文件 $ cat ~/.mambarc channels: - conda-forge always_yes: false 使用 # micromamba create -n python310 python=3.10 # 激活环境 micromamba activate python310 # 然后可以用 micromamba 或者 pip 装东西 micromamba install package_1 package_2=version ## 具体请参考 https://mamba.readthedocs.io/en/latest/ micromamba --help "},{"id":25,"href":"/articles/2024/03/06/9mzhfnl58azjmeibfblvjy/","title":"Hugo网站建设","section":"📚 我的文章","content":" 安装 Hugo # 下载地址：https://github.com/gohugoio/hugo/releases\n创建网站 # hugo new site book cd book git init git submodule add https://github.com/alex-shpak/hugo-book themes/hugo-book 本地调试 # hugo server --disableFastRender --minify --ignoreCache github actions # mkdir -p .github/workflows touch .github/workflows/build.yml name: Build on: push: branches: - main # Set a branch to deploy pull_request: jobs: deploy: runs-on: ubuntu-20.04 concurrency: group: ${{ github.workflow }}-${{ github.ref }} steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.123.7\u0026#39; # 是否启用 hugo extend extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 if: ${{ github.ref == \u0026#39;refs/heads/main\u0026#39; }} with: github_token: ${{ secrets.GH_PAGE_ACTION_TOKEN }} publish_dir: ./public github pages # 可以在项目的 Settings 中开启 Pages 服务，然后选择 Branch 为gh-pages即可。\n如果想要定制域名，可以参考官方文档 About custom domains and GitHub Pages\n"},{"id":26,"href":"/articles/2024/02/06/kkcc5t2y88hybafpourudv/","title":"FFmpeg检测透明通道","section":"📚 我的文章","content":" 检测透明通道 # FFmpeg命令 # $ ffmpeg -v error -i 123.mp4 -vf \u0026#34;select=\u0026#39;eq(n,0)\u0026#39;, alphaextract\u0026#34; -f null /dev/null [Parsed_alphaextract_1 @ 0x7fe8f5208100] Requested planes not available. [Parsed_alphaextract_1 @ 0x7fe8f5208100] Failed to configure input pad on Parsed_alphaextract_1 [vf#0:0 @ 0x7fe8f5005f40] Error reinitializing filters! Failed to inject frame into filter network: Invalid argument Error while filtering: Invalid argument [out#0/null @ 0x7fe8f5004900] Nothing was written into output file, because at least one of its streams received no packets. 判断条件 # 如果出现以上报错信息，则说明视频中没有透明通道。\n"},{"id":27,"href":"/blog/linux/fSHb366Mg/","title":"ssh客户端于服务端保持连接","section":"📚 我的文章","content":" linux ssh 默认没有开启心跳，所以很容易导致连接断开。\n服务端设置 # sudo vim /etc/ssh/sshd_config TCPKeepAlive yes ClientAliveInterval 60 ClientAliveCountMax 3 客户端设置 # 一般还是建议在客户端设置。\nsudo vim /etc/ssh/ssh_config TCPKeepAlive yes ServerAliveInterval 60 ServerAliveCountMax 3 "},{"id":28,"href":"/blog/linux/G0DCCusMR/","title":"Centos7系统升级内核版本","section":"📚 我的文章","content":" 使用ELRepo仓库升级系统内核\n查看内核版本 # uname -r uname -a cat /etc/redhat-release 安装ELRepo yum源 # rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm 查看可用的内核版本 # yum --disablerepo=\u0026#34;*\u0026#34; --enablerepo=\u0026#34;elrepo-kernel\u0026#34; list available ... kernel-lt.x86_64 4.4.155-1.el7.elrepo kernel-lt-devel.x86_64 4.4.155-1.el7.elrepo ... 安装稳定版本内核 # yum --enablerepo=elrepo-kernel install kernel-lt 设置引导（grub2） # 查看所有内核版本 # sudo awk -F\\\u0026#39; \u0026#39;$1==\u0026#34;menuentry \u0026#34; {print i++ \u0026#34; : \u0026#34; $2}\u0026#39; /etc/grub2.cfg 0 : CentOS Linux (4.4.241-1.el7.elrepo.x86_64) 7 (Core) 1 : CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core) 2 : CentOS Linux (0-rescue-651e1b90bb3149809cdeb8cc80e72c43) 7 (Core) 设置新的默认引导的内核版本 # 方法1\ngrub2-set-default 0 #其中 0 是上面查询出来的可用内核 方法2\nvim /etc/default/grub GRUB_DEFAULT=0 #其中 0 是上面查询出来的可用内核 grub2-mkconfig -o /boot/grub2/grub.cfg #生成 grub 配置文件 reboot # 重启机器 验证及删除旧内核（可选） # uname -r # 查看内核版本 4.4.241-1.el7.elrepo.x86_64 yum install yum-utils package-cleanup --oldkernels # 删除旧的内核版本 # 也可以使用 rpm -qa | grep kernel 先把所有的内核版本查询出来，然后使用 yum remove 删除掉旧的内核版本 升级失败的处理方法 # 如果发现升级内核版本并重启，发现机器无法启动，需要在开机进入引导内核选择界面手动选择老的内核启动，然后再讲默认引导的内核版本改回来的内核版本进行回滚。\n"},{"id":29,"href":"/blog/linux/xd2UELYGR/","title":"dnsmasq安装与配置","section":"📚 我的文章","content":" dnsmasq是一个小巧且方便地用于配置DNS和DHCP的工具，适用于小型网络，它提供了DNS功能和可选择的DHCP功能。\n安装服务 # sudo yum install dnsmasq 常用配置 # cat /etc/dnsmasq.conf #######这里表示 严格按照 resolv-file 文件中的顺序从上到下进行 DNS 解析, 直到第一个成功解析成功为止 #strict-order ###同时发送所有的查询到所有的dns服务器，谁快就用谁 all-servers listen-address=127.0.0.1 ###不让dnsmasq去读/etc/hosts文件 no-hosts ## 设置缓存条目 cache-size=10240 #允许客户端缓存的时间单位为秒 local-ttl=10 max-cache-ttl=15 ###开启日志 #log-queries ##配置日志文件 #log-facility=/data/logs/dnsmasq.log cat /etc/resolv.dnsmasq.conf nameserver 223.5.5.5 nameserver 114.114.114.114 nameserver 222.246.129.80 启动服务 # systemctl start dnsmasq 验证方法 # dig www.zhangwenbing.com 其他配置 # 国内指定DNS # server=/cn/114.114.114.114 server=/taobao.com/114.114.114.114 server=/taobaocdn.com/114.114.114.114 国外指定DNS # server=/google.com/8.8.8.8 屏蔽网页广告 # address=/ad.youku.com/127.0.0.1 address=/ad.iqiyi.com/127.0.0.1 其他功能 # 除了DNS，还支持DHCP和TFTP，由于暂时用不到，这里就不一一例举了。\n"},{"id":30,"href":"/blog/linux/SNyWJwbGR/","title":"使用ssh配置跳板机","section":"📚 我的文章","content":" 简单的修改/etc/ssh/ssh_config文件即可通过跳板机，直达目标服务器。\n配置方法 # cat /etc/ssh/ssh_config Host jump-server User xxxx Hostname yyy.yyy.yyy.yyy Port 22 Host 10.* ProxyCommand ssh -q -W %h:%p jump-server Host 支持通配符 * 和 ?\nxxxx 跳板机用户名\nyyy.yyy.yyy.yyy 跳板机IP地址\n需要注意的问题 # 跳板机最好是免秘钥登录，不然的话会需要输入密码。\n"},{"id":31,"href":"/blog/linux/tqj7MybMg/","title":"centos6镜像站停止维护的解决办法","section":"📚 我的文章","content":" 2020年11月30日 centos6各大开源镜像站已经停止维护了，但是阿里云还有其他源可以使用。\n错误提示 # http://mirrors.aliyun.com/epel/6/x86_64/repodata/repomd.xml: [Errno 14] PYCURL ERROR 22 - \u0026#34;The requested URL returned error: 404 Not Found\u0026#34; 解决办法 # cat /etc/yum.repos.d/CentOS-Base.repo # CentOS-Base.repo # # The mirror system uses the connecting IP address of the client and the # update status of each mirror to pick mirrors that are updated to and # geographically close to the client. You should use this for CentOS updates # unless you are manually picking other mirrors. # # If the mirrorlist= does not work for you, as a fall back you can try the # remarked out baseurl= line instead. # # [base] name=CentOS-6.10 - Base - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos-vault/6.10/os/$basearch/ gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6 #released updates [updates] name=CentOS-6.10 - Updates - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos-vault/6.10/updates/$basearch/ gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6 #additional packages that may be useful [extras] name=CentOS-6.10 - Extras - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos-vault/6.10/extras/$basearch/ gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6 #additional packages that extend functionality of existing packages [centosplus] name=CentOS-6.10 - Plus - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos-vault/6.10/centosplus/$basearch/ gpgcheck=1 enabled=0 gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6 #contrib - packages by Centos Users [contrib] name=CentOS-6.10 - Contrib - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos-vault/6.10/contrib/$basearch/ gpgcheck=1 enabled=0 gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6 yum clean all yum makecache "},{"id":32,"href":"/blog/ffmpeg/ROS_KIbGg/","title":"ffmpeg规范音频的响度","section":"📚 我的文章","content":" 通过FFmpeg内置滤镜、手动调整音量、或者ffmpeg-normalize实现对响度的控制。\n内置归一化滤波器 # loudnorm：通过EBU R.128进行响度标准化。您可以设置积分的体积目标，体积范围目标或最大真实峰。建议用于发布音频和视频，并被世界各地的广播公司使用。\ndynaudnorm：“智能”响度归一化，不进行裁剪。动态地将规范化应用于文件的窗口部分。应谨慎使用，因为这可能会改变声音的特性。\n#fdk_aac编码器 ffmpeg200421 -i \u0026#34;source_audio.ts\u0026#34; -c:a libfdk_aac -strict -2 -ac 2 -ar 48000 -ab 196k -af \u0026#34;[0:a]pan=stereo| FL \u0026lt; FL + 0.5*FC + 0.6*BL + 0.6*SL | FR \u0026lt; FR + 0.5*FC + 0.6*BR + 0.6*SR,loudnorm=I=-23:LRA=6:tp=-1\u0026#34; -y -cutoff 20000 \u0026#34;ac_5m.ts\u0026#34; #aac编码器 ffmpeg -i \u0026#34;source_audio.ts\u0026#34; -c:a aac -strict -2 -ac 2 -ar 48000 -ab 196k -af \u0026#34;loudnorm=I=-23:LRA=6:tp=-1\u0026#34; -y -cutoff 20000 \u0026#34;1_aac_dynaudnorm_ac_5m.ts\u0026#34; 常用方式 # ffmpeg -i input.mp4 -vn -acodec libfdk_aac -ac 2 -ar 44100 -af loudnorm=I=-16:TP=-1:LRA=7:print_format=json -f null /dev/null 手动规范音频的响度 # 首先，您需要分析音频流以获取最大音量，以查看规范化是否起作用。\nffmpeg -i video.avi -af \u0026#34;volumedetect\u0026#34; -vn -sn -dn -f null /dev/null [Parsed_volumedetect_0 @ 0x7f8ba1c121a0] mean_volume: -16.0 dB [Parsed_volumedetect_0 @ 0x7f8ba1c121a0] max_volume: -5.0 dB [Parsed_volumedetect_0 @ 0x7f8ba1c121a0] histogram_0db: 87861 使用音量过滤器（volume）\nffmpeg -i video.mp4 -af \u0026#34;volume=5dB\u0026#34; -c:v copy -c:a aac -cutoff 20000 output.mp4 volume=5dB 表示增加5分贝的音量\nvolume=-5dB 表示减少5分贝的音量\nvolume=1.5 表示放大1.5倍的音量\nffmpeg-normalize # ffmpeg-normalize 是一个Python库，可以使用pip安装，详细的使用方式在github上有文档，这里就不做过多的介绍了。\n"},{"id":33,"href":"/blog/linux/-vpymjJGg/","title":"tcpdump之UDP抓包","section":"📚 我的文章","content":" 使用tcpdump抓UDP包，过滤过滤IP和port，并且自动拆分片段。\n安装tcpdump # yum install -y tcpdump 使用方法 # tcpdump -i bond0 udp port xxxx and host xxx.x.xx.xxx -s0 -G 600 -w %Y_%m%d_%H%M_%S.pcap 参数说明 # -i 指定监听的网卡\nudp 监听UDP协议\nport 指定过滤的端口\nhost 指定过滤的ip\n-s 表示从一个包中截取的字节数，0表示包不截断\n-G 按照固定的时间间隔切割输出的文件（单位：秒）\n-w 直接将包写入文件中，并不分析和打印出来；\n取非运算是 ‘not ’ ‘! ‘，与运算是’and’，’\u0026amp;\u0026amp;;或运算 是’or’ ,‘||’\n定时抓包(python) # #!/usr/bin/env python # -*- coding: UTF-8 -*- # # @author 张文兵 # @blog https://zhangwenbing.com/ # @datetime 2020-12-18 14:56:01 # @description # import os import time from apscheduler.schedulers.blocking import BlockingScheduler def system(cmd): t = time.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;, time.localtime(time.time())) print(\u0026#39;{} 执行 {}\u0026#39;.format(t, cmd)) stat = os.system(cmd) if stat != 0: print(\u0026#39;{} 执行 {} 失败\u0026#39;.format(t, cmd)) scheduler = BlockingScheduler() # 星期1-5的17点40分执行抓包任务 scheduler.add_job(system, \u0026#39;cron\u0026#39;, day_of_week=\u0026#34;mon,tue,wed,thu,fri,sat\u0026#34;, hour=17, minute=30, args=[\u0026#39;/sbin/tcpdump -i bond0 udp port xxxx and host xxx.x.xx.xxx -s0 -G 3600 -w /your_path/%Y_%m%d_%H%M_%S.pcap \u0026amp;\u0026gt;/dev/null\u0026#39;]) # 星期1-5的20点01分执行kill scheduler.add_job(system, \u0026#39;cron\u0026#39;, day_of_week=\u0026#34;mon,tue,wed,thu,fri,sat\u0026#34;, hour=20, minute=1, args=[\u0026#39;pkill -9 tcpdump \u0026amp;\u0026gt;/dev/null\u0026#39;]) scheduler.start() # 星期1-5的23点59分执行自动清理7天之前的抓包文件 scheduler.add_job(system, \u0026#39;cron\u0026#39;, day_of_week=\u0026#34;mon,tue,wed,thu,fri,sat\u0026#34;, hour=23, minute=59, args=[\u0026#39;/usr/bin/find /your_path/ -type f -ctime +7 -exec rm -f {} \\; \u0026amp;\u0026gt;/dev/null\u0026#39;]) scheduler.start() 切分抓包文件 # tcpdump -r old_file -w new_files -C 10 -r 指定需要切分的文件\n-w 指定新的文件名前缀\n-C 指定切分的文件大小（单位：M）\n"},{"id":34,"href":"/blog/linux/h5sGcU1MR/","title":"Linux收录UDP视频花屏总结","section":"📚 我的文章","content":" 最近在Linux下使用ffmpeg收录UDP流花屏问题，发现机器有双网卡，添加路由指定网卡收录导致无法收录了。另附一些解决花屏的优化方法。\n优化内核参数 # cat /etc/sysctl.conf net.ipv4.conf.default.rp_filter = 0 net.ipv4.conf.all.rp_filter = 0 # 修改默认网络的缓存大小 这个很重要不然 net.core.rmem_max = 50000000 net.core.rmem_default = 50000000 sysctl -p # 添加以上配置后需要重启系统 reboot # 不重启的话一定要执行以下命令 for i in /proc/sys/net/ipv4/conf/*/rp_filter ; do echo 0 \u0026gt; \u0026#34;$i\u0026#34;; done 吐槽 # 由于博主只修改了上面的 sysctl.conf 并且只执行了 sysctl -p 所以悲剧了，添加路由之后一直无法收录。\n20201218更新 # 刚开始以为是存储和收录走同一网口导致花屏，没想到经过一番抓包分析之后，最后确定是交换机有瓶颈（交换机老旧），是交换机的数据处理不过来导致的丢包。\ncifs(samba) # 如果收录文件是存储到cifs的话，一定要在挂载的时候指定 cache=none 禁用缓存，不然收录长视频时会导致收录中断。\n"},{"id":35,"href":"/blog/linux/loBZJ41MR/","title":"CentOS添加静态路由之route","section":"📚 我的文章","content":" route命令参数详细说明及常用命令\n原文地址 docs.lvrui.io\n\u0026gt; route Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface default localhost 0.0.0.0 UG 100 0 0 eno16780032 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 192.168.10.0 0.0.0.0 255.255.255.0 U 100 0 0 eno16780032 macOS 中使用 netstat -nr 命令来查看当前路由表\nDestination 目标网路\nGateway 网关\nGenmask 掩码\nFlags 标识\nU 路由已经启动\nH 路由目标为主机\nG 使用网关\nR 为动态路由复原路由表\nD 由守护进程或间接动态安装\nM 被路由守护进程或间接修改\nA 通过 addrconf 修改\nC 缓存条目\n! 拒绝路由\nMetric 路由开销, 到目标的‘距离’（通常基于跳数统计）\nRef 参考此路由的数量\nUse 路由查找计数。依赖与使用 - F 还是 - C 选项，这个值要么是路由缓存未命中数要么是命中数\nIface 此路由数据包发送到的网络接口\n添加到主机的路由 # route add –host 192.168.59.2 dev eth1 route add –host 192.168.59.2 gw 192.168.10.85 添加到网络的路由 # route add -net 192.168.248.0/24 gw 192.168.10.85 route add –net 192.168.248.0 netmask 255.255.255.0 gw 192.168.10.85 route add –net 192.168.248.0 netmask 255.255.255.0 dev eth1 添加默认网关 # route add default gw 192.168.10.85 route add -net 0.0.0.0 gw 192.168.10.85 使用 route 命令添加的路由，机器重启或者网卡重启后路由就失效了\nroute del –host 192.168.10.85 dev eth1 怎么 add 的就怎么 del 掉. 但是 del 的时候可以不写网关\n在 /etc/rc.local 里添加路由信息\nroute add -net 192.168.247.0/24 dev eth1 route add -net 192.168.110.0/24 gw 192.168.10.85 在 /etc/sysconfig/network 里添加到末尾 GATEWAY=gw-ip 或者 GATEWAY=gw-dev\n在 /etc/sysconfig/static-router 添加 any net x.x.x.x/24 gw y.y.y.y\n添加永久路由 # CentOS7 下推荐使用上面第三种方法添加永久静态路由\n[root@centos7 ~] 10.15.150.0/24 via 192.168.150.253 dev enp0s3 10.25.250.0/24 via 192.168.150.253 dev enp0s3 将永久静态路由需要写到 /etc/sysconfig/network-scripts/route-interface 文件中\n注意:\nifcfg-enp0s3 文件改名为 ifcfg-eth0 后，route-enp0s3 文件也要改名为 route-eth0\n参考文档:\nhttps://www.cnblogs.com/panblack/p/Centos7_Static_Routes.html "},{"id":36,"href":"/blog/macos/aaELFz1Mg/","title":"macos Lauchpad(启动台) 重置","section":"📚 我的文章","content":" 重置macos的Lauchpad(启动台)，及设置Lauchpad(启动台)的行数和列数。\n打开终端程序，按需求执行以下命令即可。\n重置 Lauchpad # defaults write com.apple.dock ResetLaunchPad -bool TRUE; 重启 Dock # killall Dock 设置 Lauchpad 图标的列数 # defaults write com.apple.dock springboard-columns -int 7 设置 Lauchpad 图标的行数 # defaults write com.apple.dock springboard-rows -int 7 "},{"id":37,"href":"/blog/linux/bdpp4QAMg/","title":"nginx及php-fpm优化","section":"📚 我的文章","content":" 简单的讲讲nginx+php的一些常用优化，以及相关的内核参数优化。\nNginx 优化 # 1. TCP 与 UNIX 套接字 # UNIX 域套接字提供的性能略高于 TCP 套接字在回送接口上的性能（较少的数据复制，较少的上下文切换）。如果每个服务器需要支持超过 1000 个连接，请使用 TCP 套接字 - 它们可以更好地扩展。\nupstream backend { server unix:/var/run/fastcgi.sock; } 2. 调整 worker_processes 参数 # 现代硬件是多处理器，NGINX 可以利用多个物理或虚拟处理器。在大多数情况下，您的 Web 服务器计算机不会配置为处理多个工作负载（例如同时提供 Web 服务器和打印服务器的服务），因此您需要配置 NGINX 以使用所有可用的处理器，因为 NGINX 工作进程是不是多线程的。\n将 nginx.conf 文件中的 worker_processes 设置为计算机所具有的核心数。\n当你在它的时候，增加 worker_connections 的数量（每个核心应该处理多少个连接）并将 multi_accept 设置为 ON，如果你在 Linux 上则设置为 epoll：\nworker_processes 4; events { worker_connections 1024; multi_accept on; } 3. 禁用访问日志 # access_log off; log_not_found off; error_log /var/log/nginx-error.log warn; 如果有需要不可以关闭，至少是缓存他们\naccess_log /var/log/nginx/access.log main buffer=16k; 4. 开启 gzip 压缩 # gzip on; gzip_disable \u0026#34;msie6\u0026#34;; gzip_vary on; gzip_proxied any; gzip_comp_level 6; gzip_min_length 1100; gzip_buffers 16 8k; gzip_http_version 1.1; gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; 5. 缓存访问频次较高的文件 # open_file_cache max=2000 inactive=20s; open_file_cache_valid 60s; open_file_cache_min_uses 5; open_file_cache_errors off; 6. 调整客户端超时 # client_max_body_size 50M; client_body_buffer_size 1m; client_body_timeout 15; client_header_timeout 15; keepalive_timeout 2 2; send_timeout 15; sendfile on; tcp_nopush on; tcp_nodelay on; 7. 调整输出缓存 # fastcgi_buffers 256 16k; fastcgi_buffer_size 128k; fastcgi_connect_timeout 3s; fastcgi_send_timeout 120s; fastcgi_read_timeout 120s; fastcgi_busy_buffers_size 256k; fastcgi_temp_file_write_size 256k; reset_timedout_connection on; server_names_hash_bucket_size 100; 8. 负载均衡策略 # Nginx 提供轮询（round robin）、用户 IP 哈希（client IP）和指定权重 3 种方式。\n默认情况下，Nginx 会为你提供轮询作为负载均衡策略。但是这并不一定能够让你满意。比如，某一时段内的一连串访问都是由同一个用户 Michael 发起的，那么第一次 Michael 的请求可能是 backend2，而下一次是 backend3，然后是 backend1、backend2、backend3…… 在大多数应用场景中，这样并不高效。当然，也正因如此，Nginx 为你提供了一个按照 Michael、Jason、David 等等这些乱七八糟的用户的 IP 来 hash 的方式，这样每个 client 的访问请求都会被甩给同一个后端服务器。\nupstream backend { ip_hash; server unix:/var/run/php7.2-fpm.sock1 weight=100 max_fails=5 fail_timeout=5; server unix:/var/run/php7.2-fpm.sock2 weight=100 max_fails=5 fail_timeout=5; } 9. 持续监控日志 # 尤其是在调优最初期，在一个窗口\ntail -f /var/log/nginx/error.log 在另外两个窗口分别：\ntail -f /var/log/php-fpm/error.log tail -f /var/log/php-fpm/www-error.log PHP-fpm 优化 # 1. 修改进程管理模式 # static 管理模式适合比较大内存的服务器，而 dynamic 则适合小内存的服务器，你可以设置一个 pm.min_spare_servers 和 pm.max_spare_servers 合理范围，这样进程数会不断变动。ondemand 模式则更加适合微小内存，例如 512MB 或者 256MB 内存，以及对可用性要求不高的环境。\npm = dynamic #指定进程管理方式，有3种可供选择：static、dynamic和ondemand。 pm.max_children = 16 #static模式下创建的子进程数或dynamic模式下同一时刻允许最大的php-fpm子进程数量。 pm.start_servers = 10 #动态方式下的起始php-fpm进程数量。 pm.min_spare_servers = 8 #动态方式下服务器空闲时最小php-fpm进程数量。 pm.max_spare_servers = 16 #动态方式下服务器空闲时最大php-fpm进程数量。 pm.max_requests = 2000 #php-fpm子进程能处理的最大请求数。 pm.process_idle_timeout = 10s request_terminate_timeout = 120 pm = static，始终保持一个固定数量的子进程，这个数由 pm.max_children 定义，这种方式很不灵活，也通常不是默认的。\npm = dynamic，启动时会产生固定数量的子进程（由 pm.start_servers 控制）可以理解成最小子进程数，而最大子进程数则由 pm.max_children 去控制，子进程数会在最大和最小数范围中变化。闲置的子进程数还可以由另 2 个配置控制，分别是 pm.min_spare_servers 和 pm.max_spare_servers。如果闲置的子进程超出了 pm.max_spare_servers，则会被杀掉。小于 pm.min_spare_servers 则会启动进程（注意，pm.max_spare_servers 应小于 pm.max_children）。\npm = ondemand，这种模式和 pm = dynamic 相反，把内存放在第一位，每个闲置进程在持续闲置了 pm.process_idle_timeout 秒后就会被杀掉，如果服务器长时间没有请求，就只会有一个 php-fpm 主进程。弊端是遇到高峰期或者如果 pm.process_idle_timeout 的值太短的话，容易出现 504 Gateway Time-out 错误，因此 pm = dynamic 和 pm = ondemand 谁更适合视实际情况而定。\n2. 释放内存的配置 # pm.max_requests = 1000 设置每个子进程重生之前服务的请求数. 对于可能存在内存泄漏的第三方模块来说是非常有用的. 如果设置为 ‘0’ 则一直接受请求. 等同于 PHP_FCGI_MAX_REQUESTS 环境变量. 默认值: 0.\n也就是当一个 PHP-CGI 进程处理的请求数累积到 1000 个后，自动重启该进程，防止第三方库造成的内存泄漏。 重启时可能会导致 502 错误，在高并发站点时有出现。\n3. php-fpm 慢日志 # request_terminate_timeout = 30s #将执行时间太长的进程直接终止 request_slowlog_timeout = 2s #2秒 slowlog = log/$pool.log.slow #日志文件 内核优化 # 1. TIME_WAIT产生原因： # 1、nginx现有的负载均衡模块实现php fastcgi负载均衡，nginx使用了短连接方式，所以会造成大量处于TIME_WAIT状态的连接。\n2、TCP/IP设计者本来是这么设计的\n主要有两个原因\n(1) 防止上一次连接中的包，迷路后重新出现，影响新连接（经过2MSL，上一次连接中所有的重复包都会消失）\n(2) 可靠的关闭TCP连接\n在主动关闭方发送的最后一个 ack(fin) ，有可能丢失，这时被动方会重新发fin, 如果这时主动方处于 CLOSED 状态 ，就会响应 rst 而不是 ack。所以主动方要处于 TIME_WAIT 状态，而不能是 CLOSED 。\n2. 过多TIME_WAIT危害 # TIME_WAIT 并不会占用很大资源的，除非受到攻击。只要把TIME_WAIT所占用内存控制在一定范围。一般默认最大是35600条TIME_WAIT。\n3. 解决方法 # net.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭。\nnet.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭。\nnet.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。\nnet.ipv4.tcp_fin_timeout = 30 表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。\nnet.ipv4.tcp_keepalive_time = 1200 表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。\nnet.ipv4.ip_local_port_range = 1024 65000 表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。\nnet.ipv4.tcp_max_syn_backlog = 8192 表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。\nnet.ipv4.tcp_max_tw_buckets = 5000 表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默 认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于Squid，效果却不大。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。\n注:\nnet.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1 设置这两个参数： reuse是表示是否允许重新应用处于TIME-WAIT状态的socket用于新的TCP连接； recyse是加速TIME-WAIT sockets回收\n"},{"id":38,"href":"/blog/ffmpeg/Mv3bzfgqM/","title":"ffmpeg在特定的时间混合一个或多个音频","section":"📚 我的文章","content":" 使用FFmpeg中的adelay和amix滤镜给音频做混音\n在30秒后混合1个音频\nffmpeg -i 1-1.mp3 -i 2.mp3 -filter_complex \u0026#34;[1]adelay=delays=30s:all=1[aud1];[0][aud1]amix=inputs=2\u0026#34; -vsync 2 -y 3.mp3 在30秒后混合2个音频\nffmpeg -i 1-1.mp3 -i 2.mp3 -i 3.mp3 -filter_complex \u0026#34;[1]adelay=delays=30s:all=1[aud1];[2]adelay=delays=30s:all=1[aud2];[0][aud1][aud2]amix=inputs=3\u0026#34; -vsync 2 -y 4.mp3 混合多个参照混合2个的命令修改下即可\n"},{"id":39,"href":"/blog/linux/HTLMANZea/","title":"[supervisord]填坑之最大连接数","section":"📚 我的文章","content":" 修改supervisord配置突破1024最大连接数\n问题描述 # 最近在使用supervisord服务时发现，无论如何修改系统的最大连接数，由supervisord管理的程序都无法突破1024的限制。\n解决办法 # cat /etc/supervisord.conf [supervisord] minfds=81920 minprocs=81920 cat /etc/supervisord.d/xxx.ini [program:xxx] minfds=81920 minprocs=81920 systemctl restart supervisord.service "},{"id":40,"href":"/blog/ffmpeg/UtHueryud/","title":"FFmpeg 水印","section":"📚 我的文章","content":" 图片水印、文字水印、画中画\n图片水印 # ffmpeg -i input.mp4 -vf \u0026#34;movie=wenzi.png[watermark];[in][watermark] overlay=main_w-overlay_w-10:main_h-overlay_h-10[out] \u0026#34; output.mp4 -i :一般表示输入\ninput.mp4:这里表示要处理的视频源\n-vf:滤镜相关，视频裁剪，水印等等操作都需要它完成\nwenzi.png: 要添加的水印图片地址\noverlay:水印参数\nmain_w-overlay_w-10 : 水印在x轴的位置，也可以写成x=main_w-overlay_w-10\nmain_h-overlay_h-10：水印在y轴的位置\nffmpeg -i input.mp4 -i logo.png -filter_complex \u0026#39;overlay=x=10:y=main_h-overlay_h-10\u0026#39; output.mp4 -filter_complex: 相比-vf,\nfilter_complex适合开发复杂的滤镜功能，如同时对视频进行裁剪并旋转。参数之间使用逗号（，）隔开即可\nmain_w:视频宽度\noverlay_w: 要添加的图片水印宽度\nmain_h : 视频高度\noverlay_h:要添加的图片水印宽度\n文字水印 # ffmpeg -i input.mp4 -vf \u0026#34;drawtext=fontfile=simhei.ttf: text=‘技术是第一生产力’:x=10:y=10:fontsize=24:fontcolor=white:shadowy=2\u0026#34; output.mp4 fontfile:字体类型\ntext:要添加的文字内容\nfontsize:字体大小\nfontcolor：字体颜色\n画中画 # 只显示1遍，后边重复显示最后一帧。\nffmpeg -i bunny.mp4 -vf \u0026#34;movie=test.mov[logo];[0:v][logo]overlay=x=100:y=100\u0026#34; -y out.mp4 mov一直循环显示。 添加 loop=0,setpts=N/FRAME_RATE/TB 即可。\nffmpeg -i bunny.mp4 -vf \u0026#34;movie=test.mov:loop=0,setpts=N/FRAME_RATE/TB[logo];[0:v][logo]overlay=x=100:y=100\u0026#34; -y out.mp4 只显示一遍 添加eof_action即可。\nffmpeg -i bunny.mp4 -vf \u0026#34;movie=test.mov[logo];[0:v][logo]overlay=x=100:y=100:eof_action=pass\u0026#34; -vframes 1000 -y out.mp4 "},{"id":41,"href":"/blog/linux/QNIBzjz3k/","title":"supervisor 常见坑及解决办法","section":"📚 我的文章","content":" Too many open files、获取不到$HOME等\nToo many open files # vim /etc/supervisord.conf [supervisord] minfds=81920 minprocs=81920 # systemctl restart supervisord 获取不到$HOME # [program:apache2] command=/home/chrism/bin/httpd -c \u0026#34;ErrorLog /dev/stdout\u0026#34; -DFOREGROUND user=chrism environment=HOME=\u0026#34;/home/chrism\u0026#34;,USER=\u0026#34;chrism\u0026#34; supervisorctl update "},{"id":42,"href":"/blog/linux/N2EsU3hZT/","title":"linux nvidia 获取显卡信息","section":"📚 我的文章","content":" 使用deviceQuery获取显卡信息\n环境 # Linux、nvidia、cuda\n命令 # /usr/local/cuda/extras/demo_suite/deviceQuery CUDA Device Query (Runtime API) version (CUDART static linking) Detected 2 CUDA Capable device(s) Device 0: \u0026#34;GeForce RTX 2080 Ti\u0026#34; CUDA Driver Version / Runtime Version 10.1 / 10.1 CUDA Capability Major/Minor version number: 7.5 Total amount of global memory: 11019 MBytes (11554717696 bytes) (68) Multiprocessors, ( 64) CUDA Cores/MP: 4352 CUDA Cores GPU Max Clock rate: 1545 MHz (1.54 GHz) Memory Clock rate: 7000 Mhz Memory Bus Width: 352-bit L2 Cache Size: 5767168 bytes Maximum Texture Dimension Size (x,y,z) 1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384) Maximum Layered 1D Texture Size, (num) layers 1D=(32768), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(32768, 32768), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 1024 Maximum number of threads per block: 1024 Max dimension size of a thread block (x,y,z): (1024, 1024, 64) Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535) Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and kernel execution: Yes with 3 copy engine(s) Run time limit on kernels: No Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Alignment requirement for Surfaces: Yes Device has ECC support: Disabled Device supports Unified Addressing (UVA): Yes Device supports Compute Preemption: Yes Supports Cooperative Kernel Launch: Yes Supports MultiDevice Co-op Kernel Launch: Yes Device PCI Domain ID / Bus ID / location ID: 0 / 1 / 0 Compute Mode: \u0026lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) \u0026gt; Device 1: \u0026#34;GeForce RTX 2080 Ti\u0026#34; CUDA Driver Version / Runtime Version 10.1 / 10.1 CUDA Capability Major/Minor version number: 7.5 Total amount of global memory: 11019 MBytes (11554717696 bytes) (68) Multiprocessors, ( 64) CUDA Cores/MP: 4352 CUDA Cores GPU Max Clock rate: 1545 MHz (1.54 GHz) Memory Clock rate: 7000 Mhz Memory Bus Width: 352-bit L2 Cache Size: 5767168 bytes Maximum Texture Dimension Size (x,y,z) 1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384) Maximum Layered 1D Texture Size, (num) layers 1D=(32768), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(32768, 32768), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 1024 Maximum number of threads per block: 1024 Max dimension size of a thread block (x,y,z): (1024, 1024, 64) Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535) Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and kernel execution: Yes with 3 copy engine(s) Run time limit on kernels: No Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Alignment requirement for Surfaces: Yes Device has ECC support: Disabled Device supports Unified Addressing (UVA): Yes Device supports Compute Preemption: Yes Supports Cooperative Kernel Launch: Yes Supports MultiDevice Co-op Kernel Launch: Yes Device PCI Domain ID / Bus ID / location ID: 0 / 2 / 0 Compute Mode: \u0026lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) \u0026gt; \u0026gt; Peer access from GeForce RTX 2080 Ti (GPU0) -\u0026gt; GeForce RTX 2080 Ti (GPU1) : Yes \u0026gt; Peer access from GeForce RTX 2080 Ti (GPU1) -\u0026gt; GeForce RTX 2080 Ti (GPU0) : Yes deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.1, CUDA Runtime Version = 10.1, NumDevs = 2 源码 # https://github.com/NVIDIA/cuda-samples/tree/master/Samples/deviceQuery\n编译 # /usr/local/cuda/bin/nvcc deviceQuery.cpp -I /usr/local/cuda/samples/common/inc/ -o deviceQuery "},{"id":43,"href":"/blog/ffmpeg/rdgQnFI6j/","title":"ffprobe详解","section":"📚 我的文章","content":" ffprobe是ffmpeg提供的三大工具之一，用来查看音视频文件的各种信息，比如：封装格式、音频/视频流信息、数据包信息等。\nffprobe的源码是ffprobe.c，开发过程中如果想获取ffprobe查看的信息，可以通过分析源码，获得对应字段。\n本文主要介绍format、stream、Packet和Frame信息，包含每个字段的说明以及对应的ffmpeg字段。\n查看音视频文件的封装格式 # ffprobe -show_format inputFile 输出信息：\n[FORMAT] // 文件名 filename=VID_20190811_113717.mp4 // 容器中流的个数，即AVFormatContext-\u0026gt;nb_streams nb_streams=2 // 即AVFormatContext-\u0026gt;nb_programs nb_programs=0 // 封装格式，即AVFormatContext-\u0026gt;iformat-\u0026gt;name format_name=mov,mp4,m4a,3gp,3g2,mj2 // 即AVFormatContext-\u0026gt;iformat-\u0026gt;long_name format_long_name=QuickTime / MOV // 即AVFormatContext-\u0026gt;start_time，基于AV_TIME_BASE_Q，换算为秒 start_time=0.000000 // 即AVFormatContext-\u0026gt;duration，基于AV_TIME_BASE_Q，换算为秒 duration=10.508000 // 单位字节，即avio_size(AVFormatContext-\u0026gt;pb) size=27263322 // 码率，即AVFormatContext-\u0026gt;bit_rate bit_rate=20756240 // 即AVFormatContext-\u0026gt;probe_score probe_score=100 [/FORMAT] 查看音视频文件的流信息 # ffprobe -show_streams inputFile 输出信息：\n[STREAM] // 当前流的索引信息,对应于AVStream-\u0026gt;index index=0 // AVCodecDescriptor * cd = avcodec_descriptor_get(AVStream-\u0026gt;codecpar-\u0026gt;codec_id) // 编码名称，即cd-\u0026gt;name codec_name=h264 // 编码全称，即cd-\u0026gt;long_name codec_long_name=H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 // 一个编码参数，可以为Baseline、Main、High等，Baseline无B帧，Main及以后可以包含B帧 // 通过avcodec_profile_name(AVStream-\u0026gt;codecpar-\u0026gt;codec_id, AVStream-\u0026gt;codecpar-\u0026gt;profile)获得 profile=High // 流类型，即av_get_media_type_string(AVStream-\u0026gt;codecpar-\u0026gt;codec_type) codec_type=video // 即AVStream-\u0026gt;codec-\u0026gt;time_base codec_time_base=14777/877500 // 通过宏av_fourcc2str(AVStream-\u0026gt;codecpar-\u0026gt;codec_tag)获得 codec_tag_string=avc1 // 对应AVStream-\u0026gt;codecpar-\u0026gt;codec_tag codec_tag=0x31637661 // 有效区域的宽度，即AVStream-\u0026gt;codecpar-\u0026gt;width width=1920 // 有效区域的高度，即AVStream-\u0026gt;codecpar-\u0026gt;height height=1080 // 视频帧宽度，可能与上面的宽度不同，即AVStream-\u0026gt;codec-\u0026gt;coded_width，例如：当解码帧在输出前裁剪或启用低分辨率时 coded_width=1920 // 视频帧高度，可能与上面的高度不同，即AVStream-\u0026gt;codec-\u0026gt;coded_height，例如：当解码帧在输出前裁剪或启用低分辨率时 coded_height=1088 // 视频的延迟帧数，即AVStream-\u0026gt;codecpar-\u0026gt;video_delay has_b_frames=0 // sar，图像采集时，横向采集点数与纵向采集点数的比例 // FFmpeg提供了多个sar：AVStream-\u0026gt;sample_aspect_ratio、AVStream-\u0026gt;codecpar-\u0026gt;sample_aspect_ratio、AVFrame-\u0026gt;sample_aspect_ratio // 通过av_guess_sample_aspect_ratio获取最终的sar sample_aspect_ratio=1:1 // dar，真正展示的图像宽高比，在渲染视频时，必须根据这个比例进行缩放 // 通过av_reduce计算得到，par * sar = dar display_aspect_ratio=16:9 // 像素格式，即av_get_pix_fmt_name(AVStream-\u0026gt;codecpar-\u0026gt;format) pix_fmt=yuvj420p // 编码参数，即AVStream-\u0026gt;codecpar-\u0026gt;level level=40 // 额外的色彩空间特征，即av_color_range_name(AVStream-\u0026gt;codecpar-\u0026gt;color_range)，AVCOL_RANGE_MPEG对应tv，AVCOL_RANGE_JPEG对应pc color_range=pc // YUV彩色空间类型，即av_color_space_name(AVStream-\u0026gt;codecpar-\u0026gt;color_space) color_space=bt470bg // 颜色传输特性，即av_color_transfer_name(AVStream-\u0026gt;codecpar-\u0026gt;color_trc) color_transfer=smpte170m // 即av_color_primaries_name(AVStream-\u0026gt;codecpar-\u0026gt;color_primaries) color_primaries=bt470bg // 色度样品的位置，即av_chroma_location_name(AVStream-\u0026gt;codecpar-\u0026gt;chroma_location) chroma_location=left // 交错视频中字段的顺序，即AVStream-\u0026gt;codecpar-\u0026gt;field_order field_order=unknown // av_timecode_make_mpeg_tc_string处理AVStream-\u0026gt;codec-\u0026gt;timecode_frame_start获得 timecode=N/A // 参考帧数量，即AVStream-\u0026gt;codec-\u0026gt;refs refs=1 is_avc=true // 表示用几个字节表示NALU的长度 nal_length_size=4 id=N/A // 当前流的基本帧率，这个值仅是一个猜测，对应于AVStream-\u0026gt;r_frame_rate r_frame_rate=30/1 // 平均帧率，对应于AVStream-\u0026gt;avg_frame_rate avg_frame_rate=438750/14777 // AVStream的时间基准，即AVStream-\u0026gt;time_base time_base=1/90000 // 流开始时间，基于time_base，即AVStream-\u0026gt;start_time start_pts=0 // 转换（start_pts * time_base）之后的开始时间，单位秒 start_time=0.000000 // 流时长，基于time_base，即AVStream-\u0026gt;duration duration_ts=945728 // 转换（duration_ts * time_base）之后的时长，单位秒 duration=10.508089 // 码率，即AVStream-\u0026gt;codecpar-\u0026gt;bit_rate bit_rate=19983544 // 最大码率，即AVStream-\u0026gt;codec-\u0026gt;rc_max_rate max_bit_rate=N/A // Bits per sample/pixel，即AVStream-\u0026gt;codec-\u0026gt;bits_per_raw_sample bits_per_raw_sample=8 // 视频流中的帧数，即AVStream-\u0026gt;nb_frames nb_frames=312 nb_read_frames=N/A nb_read_packets=N/A // 下面TAG为AVStream-\u0026gt;metadata中的信息 // 逆时针的旋转角度（相当于正常视频的逆时针旋转角度） TAG:rotate=90 // 创建时间 TAG:creation_time=2019-08-11T03:37:28.000000Z // 语言 TAG:language=eng TAG:handler_name=VideoHandle // SIDE_DATA为AVStream-\u0026gt;side_data数据 [SIDE_DATA] // side_data数据类型，Display Matrix表示一个3*3的矩阵，这个矩阵需要应用到解码后的视频帧上，才能正确展示 side_data_type=Display Matrix displaymatrix= 00000000: 0 65536 0 00000001: -65536 0 0 00000002: 0 0 1073741824 // 顺时针旋转90度还原视频 rotation=-90 [/SIDE_DATA] [/STREAM] [STREAM] // 当前流的索引信息,对应于AVStream-\u0026gt;index index=1 // AVCodecDescriptor * cd = avcodec_descriptor_get(AVStream-\u0026gt;codecpar-\u0026gt;codec_id) // 编码名称，即cd-\u0026gt;name codec_name=aac // 编码全称，即cd-\u0026gt;long_name codec_long_name=AAC (Advanced Audio Coding) // 通过avcodec_profile_name(AVStream-\u0026gt;codecpar-\u0026gt;codec_id, AVStream-\u0026gt;codecpar-\u0026gt;profile)获得 profile=LC // 流类型，即av_get_media_type_string(AVStream-\u0026gt;codecpar-\u0026gt;codec_type) codec_type=audio // 即AVStream-\u0026gt;codec-\u0026gt;time_base codec_time_base=1/48000 // 通过宏av_fourcc2str(AVStream-\u0026gt;codecpar-\u0026gt;codec_tag)获得 codec_tag_string=mp4a // 对应AVStream-\u0026gt;codecpar-\u0026gt;codec_tag codec_tag=0x6134706d // 采样点格式，通过av_get_sample_fmt_name(AVStream-\u0026gt;codecpar-\u0026gt;format)获取 sample_fmt=fltp // 采样率，即AVStream-\u0026gt;codecpar-\u0026gt;sample_rate sample_rate=48000 // 通道数，即AVStream-\u0026gt;codecpar-\u0026gt;channels channels=2 // 通道布局，与channels是相对应，通过av_bprint_channel_layout获取，stereo表示立体声 channel_layout=stereo // 每个采样点占用多少bit，即av_get_bits_per_sample(par-\u0026gt;codec_id) bits_per_sample=0 id=N/A r_frame_rate=0/0 avg_frame_rate=0/0 // AVStream的时间基准，即AVStream-\u0026gt;time_base time_base=1/48000 // 流开始时间，基于time_base，即AVStream-\u0026gt;start_time start_pts=0 // 转换（start_pts * time_base）之后的开始时间，单位秒 start_time=0.000000 // 流时长，基于time_base，即AVStream-\u0026gt;duration duration_ts=502776 // 转换（duration_ts * time_base）之后的时长，单位秒 duration=10.474500 // 码率，即AVStream-\u0026gt;codecpar-\u0026gt;bit_rate bit_rate=156002 // 最大码率，即AVStream-\u0026gt;codec-\u0026gt;rc_max_rate max_bit_rate=156000 // Bits per sample/pixel，即AVStream-\u0026gt;codec-\u0026gt;bits_per_raw_sample bits_per_raw_sample=N/A // 音频流中的帧数，即AVStream-\u0026gt;nb_frames nb_frames=491 nb_read_frames=N/A nb_read_packets=N/A TAG:creation_time=2019-08-11T03:37:28.000000Z TAG:language=eng TAG:handler_name=SoundHandle [/STREAM] SAR(Sample Aspect Ratio): 采样数宽高比，图像的横向采集点数与纵向采集点数的比值，即像素个数的比值。\nPAR(Pixel Aspect Ratio): 像素宽高比，即每个像素的宽度与高度的比值，所以可以认为像素不是正方形的。\nDAR(Display Aspect Ratio): 显示宽高比，图像最终展示的宽高比，播放器在渲染视频帧时，需要保持DAR的比例。\n它们之间的关系：PAR * SAR = DAR\n如上图所示：每个方格代表一个像素，宽度为5像素，高度为4像素，即SAR=5 : 4\n假设图像的显示宽度为160，高度为120，即DAR=4 : 3\n那么可以计算出PAR = DAR / SAR = 16 : 15，表示像素方格是一个长方形。\nFFmpeg提供了多个SAR：\nAVStream-\u0026gt;sample_aspect_ratio\nAVStream-\u0026gt;codecpar-\u0026gt;sample_aspect_ratio\nAVFrame-\u0026gt;sample_aspect_ratio\n最终的SAR是通过av_guess_sample_aspect_ratio获取的。\n对于DAR，AVStream-\u0026gt;display_aspect_ratio的值始终为0:0，参考ffprobe代码，可知DAR是通过av_reduce计算得到的，如下所示：\nAVRational sar, dar; // par AVCodecParameters *par = AVStream-\u0026gt;codecpar; // 计算出sar sar = av_guess_sample_aspect_ratio(AVFormatContext, AVStream, NULL); // 根据par和sar计算出dar av_reduce(\u0026amp;dar.num, \u0026amp;dar.den, par-\u0026gt;width * sar.num, par-\u0026gt;height * sar.den, 1024*1024); 查看音视频文件的数据包信息 # // -select_streams表示选择音频或者视频 ffprobe -show_format [-select_streams audio | video] inputFile 首先看下视频流的第一个Packet和第二个Packet：\n[PACKET] //Packet类型，即av_get_media_type_string(AVStream-\u0026gt;codecpar-\u0026gt;codec_type) codec_type=video // 当前帧所属流的索引信息,对应于AVStream-\u0026gt;index stream_index=0 // 帧展示时间，即AVPacket-\u0026gt;pts，基于AVStream-\u0026gt;time_base时间基准 pts=0 // 换算为秒 pts_time=0.000000 // 帧解码时间，即AVPacket-\u0026gt;dts，基于AVStream-\u0026gt;time_base时间基准 dts=0 // 换算为秒 dts_time=0.000000 // 当前帧的时长，等于下一帧的pts - 当前帧pts，即AVPacket-\u0026gt;duration，基于AVStream-\u0026gt;time_base时间基准 duration=12972 // 换算为秒 duration_time=0.144133 // AVPacket-\u0026gt;convergence_duration，也是基于AVStream-\u0026gt;time_base时间基准 convergence_duration=N/A // 换算为秒 convergence_duration_time=N/A // 当前帧的Size，字节，即AVPacket-\u0026gt;size size=187872 // 当前帧地址偏移量，即AVPacket-\u0026gt;pos pos=830842 flags=K_ [/PACKET] [PACKET] codec_type=video stream_index=0 pts=12972 // 即 12972 / 90000 pts_time=0.144133 dts=12972 dts_time=0.144133 duration=2999 duration_time=0.033322 convergence_duration=N/A convergence_duration_time=N/A size=31200 // 上一帧的pos + size pos=1018714 flags=__ [/PACKET] 然后看下音频流的第一个Packet和第二个Packet：\n[PACKET] // 音频帧 codec_type=audio // 当前帧所属流的索引信息,对应于AVStream-\u0026gt;index stream_index=1 // 帧展示时间，即AVPacket-\u0026gt;pts，基于AVStream-\u0026gt;time_base时间基准 pts=0 pts_time=0.000000 // 帧解码时间，即AVPacket-\u0026gt;dts，基于AVStream-\u0026gt;time_base时间基准 dts=0 dts_time=0.000000 // 当前帧的时长，等于下一帧的pts - 当前帧pts，即AVPacket-\u0026gt;duration，基于AVStream-\u0026gt;time_base时间基准 duration=1024 // 1024 / 48000 duration_time=0.021333 convergence_duration=N/A convergence_duration_time=N/A size=416 pos=810458 flags=K_ [/PACKET] [PACKET] // 音频帧 codec_type=audio stream_index=1 pts=1024 // 1024 / 48000 pts_time=0.021333 dts=1024 dts_time=0.021333 duration=1024 duration_time=0.021333 convergence_duration=N/A convergence_duration_time=N/A size=416 // 上一帧的pos + size pos=810874 flags=K_ [/PACKET] 查看音视频文件解码后的帧信息 # // -select_streams表示选择音频或者视频 ffprobe -show_frames [-select_streams audio | video] inputFile 首先看下视频流的第一帧和第二帧：\n[FRAME] // 帧类型，即av_get_media_type_string(AVStream-\u0026gt;codecpar-\u0026gt;codec_type) media_type=video // 当前帧所属流的索引信息, 对应于AVStream-\u0026gt;index stream_index=0 // 是否关键帧，1：关键帧，0：非关键帧，即AVFrame-\u0026gt;key_frame key_frame=1 // 帧展示时间, 即AVFrame-\u0026gt;pts, 基于AVStream-\u0026gt;time_base时间基准 pkt_pts=0 // 换算为秒 pkt_pts_time=0.000000 // 帧解码时间，从对应的AVPacket copy而来，即AVFrame-\u0026gt;pkt_dts，基于AVStream-\u0026gt;time_base时间基准 pkt_dts=0 // 换算为秒 pkt_dts_time=0.000000 // 帧时间戳，基本与pts相同，即AVFrame-\u0026gt;best_effort_timestamp，基于AVStream-\u0026gt;time_base时间基准 best_effort_timestamp=0 // 换算为秒 best_effort_timestamp_time=0.000000 // 对应的AVPacket的帧时长，即AVFrame-\u0026gt;pkt_duration，基于AVStream-\u0026gt;time_base时间基准 pkt_duration=12972 // 换算为秒 pkt_duration_time=0.144133 // 从最后一个已输入解码器的AVPacket重新排序的pos，即AVFrame-\u0026gt;pkt_pos pkt_pos=830842 // 对应的AVPacket的帧size，即AVFrame-\u0026gt;pkt_size pkt_size=187872 // 旋转之前的帧宽度，即AVFrame-\u0026gt;width width=1920 // 旋转之前的帧高度，即AVFrame-\u0026gt;height height=1080 // 视频帧的像素格式，即av_get_pix_fmt_name(AVFrame-\u0026gt;format) pix_fmt=yuvj420p // sar，图像采集时，横向采集点数与纵向采集点数的比例 // FFmpeg提供了多个sar：AVStream-\u0026gt;sample_aspect_ratio、AVStream-\u0026gt;codecpar-\u0026gt;sample_aspect_ratio、AVFrame-\u0026gt;sample_aspect_ratio // 通过av_guess_sample_aspect_ratio获取最终的sar sample_aspect_ratio=1:1 // 视频帧的图片类型，此处为I帧，即av_get_picture_type_char(frame-\u0026gt;pict_type) pict_type=I // picture number in bitstream order, 即AVFrame-\u0026gt;coded_picture_number coded_picture_number=0 // picture number in display order, 即AVFrame-\u0026gt;display_picture_number display_picture_number=0 // 视频帧内容是否是交错的, 即AVFrame-\u0026gt;interlaced_frame interlaced_frame=0 // 若视频帧内容是交错的，表示首先展示的顶部字段，即AVFrame-\u0026gt;top_field_first top_field_first=0 // 当解码时，这个信号表明视频帧必须延迟多少。extra_delay = repeat_pict / (2*fps), 即AVFrame-\u0026gt;repeat_pict repeat_pict=0 // 额外的色彩空间特征，即av_color_range_name(AVFrame-\u0026gt;color_range)，AVCOL_RANGE_MPEG对应tv，AVCOL_RANGE_JPEG对应pc color_range=pc // YUV彩色空间类型，即av_color_space_name(AVFrame-\u0026gt;colorspace) color_space=bt470bg // 即av_color_primaries_name(AVFrame-\u0026gt;color_primaries) color_primaries=bt470bg // 颜色传输特性，即av_color_transfer_name(AVFrame-\u0026gt;color_trc) color_transfer=smpte170m // 色度样品的位置，即av_chroma_location_name(AVFrame-\u0026gt;chroma_location) chroma_location=left [/FRAME] [FRAME] media_type=video stream_index=0 // 非关键帧 key_frame=0 pkt_pts=12972 // 12972 / 90000 pkt_pts_time=0.144133 pkt_dts=12972 pkt_dts_time=0.144133 best_effort_timestamp=12972 best_effort_timestamp_time=0.144133 pkt_duration=2999 pkt_duration_time=0.033322 pkt_pos=1018714 pkt_size=31200 width=1920 height=1080 pix_fmt=yuvj420p sample_aspect_ratio=1:1 // 视频帧的图片类型，此处为P帧，即av_get_picture_type_char(frame-\u0026gt;pict_type) pict_type=P coded_picture_number=1 display_picture_number=0 interlaced_frame=0 top_field_first=0 repeat_pict=0 color_range=pc color_space=bt470bg color_primaries=bt470bg color_transfer=smpte170m chroma_location=left [/FRAME] 然后看下音频流的第一帧和第二帧：\n[FRAME] // 帧类型，即av_get_media_type_string(AVStream-\u0026gt;codecpar-\u0026gt;codec_type) media_type=audio // 当前帧所属流的索引信息, 对应于AVStream-\u0026gt;index stream_index=1 // 是否关键帧 key_frame=1 // 帧展示时间, 即AVFrame-\u0026gt;pts, 基于AVStream-\u0026gt;time_base时间基准 pkt_pts=0 // 换算为秒 pkt_pts_time=0.000000 // 帧解码时间，从对应的AVPacket copy而来，即AVFrame-\u0026gt;pkt_dts，基于AVStream-\u0026gt;time_base时间基准 pkt_dts=0 // 换算为秒 pkt_dts_time=0.000000 // 帧时间戳，基本与pts相同，即AVFrame-\u0026gt;best_effort_timestamp，基于AVStream-\u0026gt;time_base时间基准 best_effort_timestamp=0 // 换算为秒 best_effort_timestamp_time=0.000000 // 对应的AVPacket的帧时长，即AVFrame-\u0026gt;pkt_duration，基于AVStream-\u0026gt;time_base时间基准 pkt_duration=1024 // 换算为秒 pkt_duration_time=0.021333 // 从最后一个已输入解码器的AVPacket重新排序的pos，即AVFrame-\u0026gt;pkt_pos pkt_pos=810458 // 对应的AVPacket的帧size，即AVFrame-\u0026gt;pkt_size pkt_size=416 // 音频采样点格式，即av_get_sample_fmt_name(AVFrame-\u0026gt;format) sample_fmt=fltp // 当前音频帧的采样点数，即AVFrame-\u0026gt;nb_samples nb_samples=1024 // 通道数，即AVFrame-\u0026gt;channels channels=2 // 通道布局，通过av_bprint_channel_layout得到，与channels对应 channel_layout=stereo [/FRAME] [FRAME] media_type=audio stream_index=1 key_frame=1 pkt_pts=1024 pkt_pts_time=0.021333 pkt_dts=1024 pkt_dts_time=0.021333 best_effort_timestamp=1024 best_effort_timestamp_time=0.021333 pkt_duration=1024 pkt_duration_time=0.021333 pkt_pos=810874 pkt_size=416 sample_fmt=fltp nb_samples=1024 channels=2 channel_layout=stereo [/FRAME] 参考文章 # FFmpeg获取视频正确的宽高比\n转载自-\u0026gt;https://www.zybuluo.com/ltlovezh/note/1534824\n"},{"id":44,"href":"/blog/macos/MiSev5_HW/","title":"upx for macos 之源码编译","section":"📚 我的文章","content":" UPX (the Ultimate Packer for eXecutables)是一款先进的可执行程序文件压缩器，压缩过的可执行文件体积缩小50%-70% ，这样减少了磁盘占用空间、网络上传下载的时间和其它分布以及存储费用。\n准备源码 # git clone https://github.com/upx/upx.git git clone https://github.com/upx/upx-lzma-sdk.git lzma-sdk wget http://www.oberhumer.com/opensource/ucl/download/ucl-1.03.tar.gz 编译源码 # tar -xzvf ucl-1.03.tar.gz cd ucl-1.03 ./configure --prefix=/home/o/ucl CC=clang make cd ../upx make all UPX_UCLDIR=../ucl-1.03 UPX_LZMADIR=../lzma-sdk 编译完成之后再src目录下能找到upx.out文件就成功了\n"},{"id":45,"href":"/blog/ffmpeg/ovfEIBOES/","title":"ffmpeg 删除音视频文件中的元数据","section":"📚 我的文章","content":" 清除mp3文件中自带的专辑（album），艺术家（artist），流派（genre）等元数据。\nffmpeg -i \u0026#34;test.mp3\u0026#34; -b:a 320k -map_metadata -1 -y \u0026#34;out.mp3\u0026#34; -map_metadata -1 表示清除所有元数据\n"},{"id":46,"href":"/blog/linux/roH7hpe6L/","title":"mediainfo 静态编译脚本","section":"📚 我的文章","content":" 因为需要mediainfo支持http协议，在老的版本中是不支持的，所以只能自己动手编译了。\n说明 # 系统：ubuntu 14.04 (其他版本可能会有少许改动)\nmediainfo版本：0.7.71\n编译环境：c/c++\n脚本 # #!/bin/bash cd ~/ apt-get install git automake autoconf libtool pkg-config make g++ zlib1g-dev libcurl4-gnutls-dev git clone https://github.com/MediaArea/ZenLib.git cd ZenLib make clean git checkout v0.4.37 cd Project/GNU/Library ./autogen.sh ./configure --enable-static make -j2 cd ~/ git clone https://github.com/openssl/openssl.git cd openssl make clean git checkout OpenSSL_1_0_2i ./Configure linux-generic64 make -j2 curl_vserion=7.50.0 cd ~/ wget --no-check-certificate https://curl.haxx.se/download/curl-$curl_vserion.tar.gz tar -zxvf curl-$curl_vserion.tar.gz cd curl-$curl_vserion/ make clean ./configure --enable-static --disable-share --disable-ldap --disable-ldaps --without-librtmp --without-libidn make -j2 cd ~/ git clone https://github.com/MediaArea/MediaInfoLib.git cd MediaInfoLib git checkout v0.7.71 cd Project/GNU/Library/ make clean ./autogen ## --with-libcurl 开启支持http和ftp ./configure --enable-static --with-libcurl=../../../../curl-$curl_vserion/ make -j2 cd ~/ git clone https://github.com/MediaArea/MediaInfo.git cd MediaInfo git checkout v0.7.71 cd Project/GNU/CLI make clean ./autogen ./configure --enable-staticlibs make -j2 # make install g++ -static -O2 -DUNICODE -DUNICODE -DSIZE_T_IS_LONG -o mediainfo CLI_Main.o CommandLine_Parser.o Help.o Core.o ../../../../MediaInfoLib/Project/GNU/Library/.libs/libmediainfo.a -lz ../../../../ZenLib/Project/GNU/Library/.libs/libzen.a ../../../../curl-$curl_vserion/lib/.libs/libcurl.a ../../../../openssl/libssl.a ../../../../openssl/libcrypto.a -lpthread -lstdc++ -pthread -Wl,-rpath -Wl,../../../../ZenLib/Project/GNU/Library/.libs -Wl,-rpath -Wl,../../../../curl-$curl_vserion/lib/.libs -Wl,-rpath -Wl,../../../../openssl -ldl "},{"id":47,"href":"/blog/linux/JQIo7dGc1/","title":"openssl - https SAN自签名证书","section":"📚 我的文章","content":" 使用openssl生产自签名证书，用于https测试。\nCA根证书制作 # #1.生成根证书密钥 $ openssl genrsa -out ca.key 4096 #建议长度为4096,1024长度已经被列为不安全。 #2.生成自签名根证书 $ openssl req -new -x509 -days 3650 -key ca.key -out ca.crt #这里在输入CommonName的时候输入名称而不是域名或者ip,就是证书上显示的颁发者，虽然是自签名证书，但是尽量让证书看起来标准一些 使用根证书来签名其它证书 # 1.生成证书密钥 # $ openssl genrsa -out server.key 4096 2. Subject Alt Name(SAN) # 高版本的Chrome浏览器会要求设置 subjectAltName,如果没有设置SAN会报证书错误\n参考openssl配置文件,Linux服务器上通常在 /etc/pki/tls/openssl.cnf\n新建文件 san.conf\n[req] default_bits = 4096 distinguished_name = req_distinguished_name req_extensions = v3_req [req_distinguished_name] countryName = country stateOrProvinceName = province localityName = city organizationName = company name commonName = domain name or ip [v3_req] subjectAltName = @alt_names [alt_names] NDS.1=domain #可以使用通配符 IP.1=xxx.xxx.xxx.xxx 3. 生成证书签名请求(CSR) # 向根证书请求签名一个新的证书，由于用户信任了你的根证书，所以根证书签名的其它证书也会被信任\n# 生成csr 注意要使用sha256算法（推荐是sha256算法，默认算法浏览器会报弱加密算法错误） $ openssl req -new -key server.key -out server.csr -config san.conf -sha256 # 查看csr信息 $ openssl req -text -in server.csr csr信息中会有类似的信息\nRequested Extensions: X509v3 Subject Alternative Name: IP Address:xxxxxx 4.使用根证书按照csr给证书签名，生成新证书server.crt # $ openssl x509 -req -days 365 -in server.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out server.crt -extfile san.conf -extensions v3_req 查看证书信息\n$ openssl x509 -text -in server.crt 证书信息中会有类似信息\nX509v3 extensions: X509v3 Subject Alternative Name: IP Address:xxxxxx "},{"id":48,"href":"/blog/linux/B1G3FwCaN/","title":"supervisor 安装和使用方法","section":"📚 我的文章","content":" Supervisor是用Python开发的一套通用的进程管理程序，能将一个普通的命令行进程变为后台daemon，并监控进程状态，异常退出时能自动重启。\n准备工作 # yum install epel-* -y yum install python34 -y wget --no-check-certificate python3 get-pip.py 安装supervisor # pip3 install supervisor 配置supervisor # echo_supervisord_conf \u0026gt;/etc/supervisord.conf vi /etc/supervisord.conf ...... ;[include] ;这个东西挺有用的，当我们要管理的进程很多的时候，写在一个文件里面就有点大了。我们可以把配置信息写到多个文件中，然后include过来 ;files = relative/directory/*.ini 去掉上面两行的”;“然后将files改成自己的目录\nvi /etc/supervisord.conf [unix_http_server] file=/tmp/supervisor.sock ;UNIX socket 文件，supervisorctl 会使用 ;chmod=0700 ;socket文件的mode，默认是0700;chown=nobody:nogroup ;socket文件的owner，格式：uid:gid ;[inet_http_server] ;HTTP服务器，提供web管理界面 ;port=127.0.0.1:9001 ;Web管理后台运行的IP和端口，如果开放到公网，需要注意安全性 ;username=user ;登录管理后台的用户名 ;password=123 ;登录管理后台的密码 [supervisord] logfile=/tmp/supervisord.log ;日志文件，默认是 $CWD/supervisord.loglogfile_maxbytes=50MB ;日志文件大小，超出会rotate，默认 50MB，如果设成0，表示不限制大小 logfile_backups=10 ;日志文件保留备份数量默认10，设为0表示不备份 loglevel=info ;日志级别，默认info，其它: debug,warn,trace pidfile=/tmp/supervisord.pid ;pid 文件 nodaemon=false ;是否在前台启动，默认是false，即以 daemon 的方式启动 minfds=1024 ;可以打开的文件描述符的最小值，默认 1024minprocs=200 ;可以打开的进程数的最小值，默认 200 [supervisorctl] serverurl=unix:///tmp/supervisor.sock ;通过UNIX socket连接supervisord，路径与unix_http_server部分的file一致;serverurl=http://127.0.0.1:9001 ; 通过HTTP的方式连接supervisord ; [program:xx]是被管理的进程配置参数，xx是进程的名称 [program:xx] command=/opt/apache-tomcat-8.0.35/bin/catalina.sh run ; 程序启动命令 autostart=true ; 在supervisord启动的时候也自动启动 startsecs=10 ; 启动10秒后没有异常退出，就表示进程正常启动了，默认为1秒 autorestart=true ; 程序退出后自动重启,可选值：[unexpected,true,false]，默认为unexpected，表示进程意外杀死后才重启 startretries=3 ; 启动失败自动重试次数，默认是3user=tomcat ; 用哪个用户启动进程，默认是root priority=999 ; 进程启动优先级，默认999，值小的优先启动 redirect_stderr=true ; 把stderr重定向到stdout，默认falsestdout_logfile_maxbytes=20MB ; stdout 日志文件大小，默认50MB stdout_logfile_backups = 20 ; stdout 日志文件备份数，默认是10; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件） stdout_logfile=/opt/apache-tomcat-8.0.35/logs/catalina.out stopasgroup=false ;默认为false,进程被杀死时，是否向这个进程组发送stop信号，包括子进程 killasgroup=false ;默认为false，向进程组发送kill信号，包括子进程 ;包含其它配置文件 [include] files = /etc/supervisord.d/*.ini ;可以指定一个或多个以.ini结束的配置文件 mkdir /etc/supervisord.d/ 启动supervisor # supervisord -c /etc/supervisord.conf 常用命令 # 查看状态 # supervisorctl status 启动服务 # supervisorctl start 服务名 停止服务 # supervisorctl stop 服务名 重启服务 # supervisorctl restart 服务名 增加服务 # vim /etc/supervisord.d/test.ini [program:test] #程序的名字，在supervisor中可以用这个名字来管理该程序。 directory = /root #相当于在该目录下执行程序 command = /root/1.sh #启动程序的命令 autorestart = true #是否自动重启 autostart = true #设置改程序是否虽supervisor的启动而启动 startsecs = 5 重新启动时，等待的时间 startretries = 3 #重启程序的次数 user = root #指定运行用户 redirect_stderr = true #是否将程序错误信息重定向的到文件 stdout_logfile_backups = 10 stdout_logfile_maxbytes = 10MB stdout_logfile = /var/log/supervisord/ameRender.log environment = HOME=\u0026#34;/root\u0026#34;,USER=\u0026#34;root\u0026#34; minfds=81920 minprocs=81920 supervisorctl update "},{"id":49,"href":"/blog/linux/HkCTnskvV/","title":"error while loading shared libraries: libc.so.6: cannot open shared object file: No such file or directory","section":"📚 我的文章","content":" 不小心误删libc.so的恢复方式\n安装完成后, 建立软链指向glibc-2.14, 执行如下命令:\nrm -rf /lib64/libc.so.6 ln -s /opt/glibc-2.14/lib/libc-2.14.so /lib64/libc.so.6 注意：删除libc.so.6之后可能导致系统命令不可用的情况, 可使用如下方法解决:\n$ LD_PRELOAD=/opt/glibc-2.14/lib/libc-2.14.so ln -s /opt/glibc-2.14/lib/libc-2.14.so /lib64/libc.so.6 如果上述更新失败可使用如下命令还原:\n$ LD_PRELOAD=/lib64/libc-2.12.so ln -s /lib64/libc-2.12.so /lib64/libc.so.6 // libc-2.12.so 此项是系统升级前的版本 "},{"id":50,"href":"/blog/linux/rk-lmMGL4/","title":"yum错误:problem making ssl connection Trying other mirror","section":"📚 我的文章","content":" yum无法使用带https的源\n环境 # yum install epel-release 运行以上命令之后，安装其他软件就报错。\n错误提示 # [Errno 14] problem making ssl connection Trying other mirror. Trying other mirror Error: Cannot retrieve repository metadata (repomd.xml) for repository: xxxx. Please verify its path and try again 经过google查询，发现似乎是ssl证书的原因。\n解决方法 # yum install ca-certificates yum update curl "},{"id":51,"href":"/blog/linux/H10_K-VQ4/","title":"CentOS7 php5.6 编译安装amqp扩展","section":"📚 我的文章","content":" php 安装最新rabbitmq扩展\n1、安装编译环境 # yum install cmake gcc gcc-c++ make openssl-devel 2、安装rabbitmq-c # wget https://github.com/alanxz/rabbitmq-c/archive/v0.9.0.zip unzip v0.9.0.zip cd rabbitmq-c-0.9.0/ cmake -DCMAKE_INSTALL_PREFIX=/usr/local/rabbitmq-c-0.9.0/ make \u0026amp;\u0026amp; make install 3、安装amqp # wget http://pecl.php.net/get/amqp-1.9.4.tgz tar zxf amqp-1.9.4.tgz cd amqp-1.9.4 /usr/bin/phpize ./configure --with-php-config=/usr/bin/php-config --with-amqp --with-librabbitmq-dir=/usr/local/rabbitmq-c-0.9.0 #由于rabbitmq-c编译出来的lib目录是lib64，所以我们要做一些小的修改 vim Makefile #将 AMQP_SHARED_LIBADD = -Wl,-rpath,/usr/local/rabbitmq-c-0.9.0/lib -L/usr/local/rabbitmq-c-0.9.0/lib -lrabbitmq #修改为 AMQP_SHARED_LIBADD = -Wl,-rpath,/usr/local/rabbitmq-c-0.9.0/lib64 -L/usr/local/rabbitmq-c-0.9.0/lib64 -lrabbitmq make \u0026amp;\u0026amp; make install 4、php.ini 添加模块 # vi /usr/local/php/etc/php.ini #增加 extension = /usr/lib64/php/modules/amqp.so 5、重启服务 # systemctl restart php-fpm "},{"id":52,"href":"/blog/linux/B11j0sF-N/","title":"记一次时间同步引起的故障","section":"📚 我的文章","content":" ntpdate同步时间，时间跳跃，引起服务中断。\n计划任务 # 0 4 * * * /usr/sbin/ntpdate 10.200.3.71 日志 # Dec 30 04:00:01 localhost systemd: Created slice user-0.slice. Dec 30 04:00:01 localhost systemd: Starting user-0.slice. Dec 30 04:00:01 localhost systemd: Started Session 16 of user root. Dec 30 04:00:01 localhost systemd: Starting Session 16 of user root. Dec 29 20:09:59 localhost systemd: Time has been changed Dec 29 20:09:59 localhost systemd: Removed slice user-0.slice. Dec 29 20:09:59 localhost systemd: Stopping user-0.slice. 故障 # 因为跳跃的时间太大，导致系统的各种服务中断（网络中断和systemctl管理的服务也有问题）。\n解析 # ntpdate同步时间，会造成时间的跳跃，对一些依赖时间的程序和服务会造成影响。比如sleep，timer等。而且，ntpd服务可以在修正时间的同时，修正cpu\ntick。理想的做法为，在开机的时候，使用ntpdate强制同步时间，在其他时候使用ntpd服务来同步时间。\n要注意的是，ntpd有一个自我保护设置: 如果本机与上源时间相差太大, ntpd不运行. 所以新设置的时间服务器一定要先ntpdate从上源取得时间初值,\n然后启动ntpd服务。ntpd服务运行后, 先是每隔指定的时间与上源服务器同步一次, 根据每次同步时测得的误差值经复杂计算逐步调整自己的时间,\n随着误差减小, 逐步增加同步的间隔. 每次跳动, 都会重复这个调整的过程.\n"},{"id":53,"href":"/blog/linux/HJJ4wWwim/","title":"解决rabbitmq依赖问题","section":"📚 我的文章","content":" 错误提示 # warning: rabbitmq-server-3.6.6-1.el6.noarch.rpm: Header V4 RSA/SHA1 Signature, key ID 6026dfca: NOKEYerror: Failed dependencies: erlang \u0026gt;= R16B-03 is needed by rabbitmq-server-3.6.6-1.el6.noarch socat is needed by rabbitmq-server-3.6.6-1.el6.noarch 解决方法 # cd /etc/yum.repos.d/ cat erlang.repo [erlang-solutions] name=Centos $releasever - $basearch - Erlang Solutions baseurl=http://packages.erlang-solutions.com/rpm/centos/$releasever/$basearch gpgcheck=0 gpgkey=http://packages.erlang-solutions.com/debian/erlang_solutions.asc enabled=1 然后再安装rabbitmq\nyum localinstall rabbitmq-server-3.6.6-1.el6.noarch.rpm 其他问题 # # /etc/init.d/rabbitmq-server start Starting rabbitmq-server: FAILED - check /var/log/rabbitmq/startup_{log, _err} rabbitmq-server. # vim /var/log/rabbitmq/startup_err init terminating in do_boot (noproc) Crash dump is being written to: erl_crash.dump...done 如果出现以上问题，说明erlang和rabbitmq的版本不相符。只能重新安装erlang了。\n"},{"id":54,"href":"/blog/linux/SJyvgQAOm/","title":"Linux bash 提取文件名和目录名","section":"📚 我的文章","content":" 在Linux Bash中分别使用basename、dirname、${}，提取文件名和目录名。\n通过变量方式 # ${}用于字符串的读取，提取和替换功能，可以使用${} 提取字符串\n1、提取文件名 # # file1=/dir1/dir2/file.txt # echo ${file1##*/} file.txt 2、提取后缀 # # echo ${file1##*.} txt 3、提取不带后缀的文件名 # # tmp=${file1##*/} # echo $tmp file.txt # echo ${tmp%.*} file 4、提取目录 # # echo ${var%/*} /dir1/dir2 通过命令 # 使用文件目录的专有命令basename和dirname\n1、提取文件名 # # file2=/dir1/dir2/file2.txt # echo $(basename $file2) file2.txt 2、提取不带后缀的文件名 # # echo $(basename $file2 .txt) file2 3、提取目录 # # dirname $file2 /dir1/dir2 # echo $(dirname $file2) /dir1/dir2 "},{"id":55,"href":"/blog/ffmpeg/Bki3dANDX/","title":"ffmpeg 9:16和16:9互相转换","section":"📚 我的文章","content":" ​今天搜集了一下16:9和9:16相互转换的命令。将多余的部分用模糊背景填充，感觉比直接加黑边好很多。\n16:9转9:16 # 命令 # ffmpeg -i input.mp4 -lavfi \u0026#34;[0:v]scale=256/81*iw:256/81*ih,boxblur=luma_radius=min(h\\,w)/40:luma_power=3:chroma_radius=min(cw\\,ch)/40:chroma_power=1[bg];[bg][0:v]overlay=(W-w)/2:(H-h)/2,setsar=1,crop=w=iw*81/256\u0026#34; output.mp4 9:16转16:9 # 命令 # ffmpeg -i input.mp4 -lavfi \u0026#39;[0:v]scale=ih*16/9:-1,boxblur=luma_radius=min(h\\,w)/20:luma_power=1:chroma_radius=min(cw\\,ch)/20:chroma_power=1[bg];[bg][0:v]overlay=(W-w)/2:(H-h)/2,crop=h=iw*9/16\u0026#39; -vb 800K output.mp4 "},{"id":56,"href":"/blog/linux/ByaB7yPSQ/","title":"nginx auth_basic登录验证遇到的坑","section":"📚 我的文章","content":" htpasswd默认使用crypt()加密，创建的密码只有前8位有效\n问题 # htpasswd -c /etc/nginx/.htpasswd test 假如，密码为abcd12345\n那么在登录的时候，不管是输入“abcd1234”、”abcd12345“或”abcd123456789sdjkal“ 都能通过验证。\n解析 # 因为htpasswd默认使用crypt()加密，而crypt()加密只有前面8位有效。\n解决方法 # htpasswd -m -c /etc/nginx/.htpasswd test 在创建账号的时候指定”-m“参数，使用MD5加密就能解决这个问题了。\n"},{"id":57,"href":"/blog/ffmpeg/SkuD1wO4X/","title":"ffmpeg输出苹果编码格式prores","section":"📚 我的文章","content":" ffmpeg输出苹果编码格式prores。分辨率1080p，25帧，5个音轨。\nffmpeg -i 06无字幕mp4-使用此视频的画面.mp4 -i 06有字幕-使用此视频的国际音轨.mov -map 0:v -s 1920x1080 -r 25 -c:v prores_ks -profile:v 3 -pix_fmt yuv422p10le -map 1:1 -acodec pcm_s24le -ar 48000 -ac 1 -map 1:2 -acodec pcm_s24le -ar 48000 -ac 1 -map 1:3 -acodec pcm_s24le -ar 48000 -ac 1 -map 1:4 -acodec pcm_s24le -ar 48000 -ac 1 -map 1:5 -acodec pcm_s24le -ar 48000 -ac 1 06-out.mov "},{"id":58,"href":"/blog/ffmpeg/SJkrWTUVm/","title":"ffmbc转码输出DVCPRO HD","section":"📚 我的文章","content":" 使用ffmbc多线程转码输出DVCPRO HD。分辨率为1440x1080，隔行扫描。\n一 # 将一个双声道音轨复制输出成两个单声道音轨\nffmbc -y -threads 8 -i 海外发行测试源文件0726.mp4 -target dvcprohd -tff -an 海外发行测试源文件0726-out.mxf -acodec pcm_s24le -ar 48000 -ac 1 -newaudio -acodec pcm_s24le -ar 48000 -newaudio -acodec pcm_s24le -ar 48000 二 # 将一个双声道音轨复制拆分成两个左右单声道音轨\nffmbc -y -threads 8 -i 海外发行测试源文件0726.mp4 -target dvcprohd -tff -an 海外发行测试源文件0726-out.mxf -acodec pcm_s24le -ar 48000 -newaudio -acodec pcm_s24le -ar 48000 -newaudio -map_audio_channel 0:1:0:0:1:0 -map_audio_channel 0:1:1:0:2:0 "},{"id":59,"href":"/blog/linux/HJlvWaG47/","title":"Nginx的connect() to xxx failed (13: Permission denied) 和 Nginx 403 forbidden","section":"📚 我的文章","content":" 解决Nginx的connect() to xxx failed (13: Permission denied) 和 Nginx 403 forbidden 错误\n查看SeLinux状态 # getenforce 如果是enabled则继续往下看。\n临时关闭（不需要重启机器） # setenforce 0 修改配置 # vim /etc/selinux/config #将SELINUX=enforcing改为SELINUX=disabled 如果你执行了临时关闭SeLinux并机器上跑了重要的业务，那可以不需要马上重启机器，等待下次重启配置生效即可。\n"},{"id":60,"href":"/blog/ffmpeg/Hy8NTRZmm/","title":"XDCAM HD422 MXF","section":"📚 我的文章","content":" 分别使用ffmpeg ffmbc 实现 输出XDCAM HD422 MXF文件\nffmpeg # ffmpeg -i test.mov -pix_fmt yuv422p -vcodec mpeg2video -non_linear_quant 1 -flags +ildct+ilme -top 1 -dc 10 -intra_vlc 1 -qmax 3 -lmin \u0026#34;1*QP2LAMBDA\u0026#34; -vtag xd5c -rc_max_vbv_use 1 -rc_min_vbv_use 1 -g 12 -b:v 50000k -minrate 50000k -maxrate 50000k -bufsize 8000k -acodec pcm_s16le -ar 48000 -bf 2 -ac 2 -f mxf_d10 output.mxf ffmbc # ffmbc -y -threads 8 -i 先导片.mp4 -target xdcamhd422 -tff -acodec pcm_s24le 先导片-out.mov "},{"id":61,"href":"/blog/macos/BkHOYBUgX/","title":"mac os pkg解包","section":"📚 我的文章","content":" jdk1.8.pkg解包\n每次安装Java的时候，都是一个pkg安装包，没有像linux下直接一个tar包那样绿色和方便。于是google搜索一下，终于找到解决的方法了。\nxar -xf JDK\\ 8\\ Update\\ 171.pkg cat jdk180171.pkg/Payload | cpio -i 是不是很简单，然后将”Contents/Home” 拷贝出来并重命名为jdk1.8，剩下的就和linux下配置java环境一样的了。\n"},{"id":62,"href":"/blog/linux/rJY7U8E9U0z/","title":"centos7 rdate 时间同步服务","section":"📚 我的文章","content":" 安装软件 # yum install -y xinetd rdate 修改配制 # vim /etc/xinetd.d/time-stream # 将disable = yes 改为 disable = no 启动服务 # # 启动xinetd systemctl start xinetd # 添加开启启动 systemctl enable xinetd 同步时间 # 服务端 # 首先在服务端执行以下命令（到底哪个是服务端呢？就是你在哪台机器上面执行了以上三个步骤就是服务端），在服务端上同步网络标准时间，然后再同步到内网各台机器上。\n/usr/bin/rdate -s -u time.nist.gov 客户端 # 其他内网需要同步时间的机器可以执行\nyum install -y rdate /usr/bin/rdate -s 服务端ip "},{"id":63,"href":"/blog/linux/rytGLI49LCf/","title":"centos7 修改内核引导顺序","section":"📚 我的文章","content":" 查看内核 # cat /boot/grub2/grub.cfg |grep menuentry menuentry \u0026#39;CentOS Linux (3.10.0-327.36.3.el7.x86_64) 7 (Core)\u0026#39; --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option \u0026#39;gnulinux-3.10.0-327.el7.x86_64-advanced-80b9b662-0a1d-4e84-b07b-c1bf19e72d97\u0026#39; { menuentry \u0026#39;CentOS Linux (3.10.0-327.22.2.el7.x86_64) 7 (Core)\u0026#39; --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option \u0026#39;gnulinux-3.10.0-327.el7.x86_64-advanced-80b9b662-0a1d-4e84-b07b-c1bf19e72d97\u0026#39; { menuentry \u0026#39;CentOS Linux (3.10.0-327.el7.x86_64) 7 (Core)\u0026#39; --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option \u0026#39;gnulinux-3.10.0-327.el7.x86_64-advanced-80b9b662-0a1d-4e84-b07b-c1bf19e72d97\u0026#39; { menuentry \u0026#39;CentOS Linux (0-rescue-7d26c16f128042a684ea474c9e2c240f) 7 (Core)\u0026#39; --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option \u0026#39;gnulinux-0-rescue-7d26c16f128042a684ea474c9e2c240f-advanced-80b9b662-0a1d-4e84-b07b-c1bf19e72d97\u0026#39; 修改默认 # grub2-set-default \u0026#34;CentOS Linux (3.10.0-327.22.2.el7.x86_64) 7 (Core)\u0026#34; 查看生效 # grub2-editenv list saved_entry=CentOS Linux (3.10.0-327.22.2.el7.x86_64) 7 (Core) "},{"id":64,"href":"/blog/linux/B1AMUL45ICM/","title":"Centos7搭建vpn","section":"📚 我的文章","content":" 准备环境 # 首先查看系统是否支持pptpd服务： # modprobe ppp-compress-18 \u0026amp;\u0026amp; echo yes 安装ppp , pptpd，iptables # yum install -y ppp pptpd iptables systemctl mask firewalld systemctl stop firewalld 修改配制 # vi /etc/pptpd.conf #找到配制文件中默认的值，去掉注释即可 localip 192.168.0.1 #本机VPN IP remoteip 192.168.0.234-238,192.168.0.245 客户端可以获取到的ip网段 #修改DNS vi /etc/ppp/options.pptpd #末尾添加dns ms-dns 8.8.8.8 ms-dns 114.114.114.114 #添加vpn账户 vi /etc/ppp/chap-secrets # client server secret IP addresses user pptpd passwd * #开启路由转发 vi /etc/sysctl.conf net.ipv4.ip_forward = 1 #添加在配制文件的末尾即可 sysctl -p #运行这个命令会输出上面添加的那一行信息，意思是使内核修改生效 #在防火墙上开启nat转发 iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -o eth0 -j MASQUERADE #IP和网口根据实际情况修改即可 开启服务 # service iptables save systemctl restart iptables systemctl restart pptpd "},{"id":65,"href":"/blog/linux/rJFUIE5I0G/","title":"Centos多网卡绑定(bonding)","section":"📚 我的文章","content":" 内核模块 # 通过modinfo bonding命令查看Linux是否支持bonding\nlsmod |grep bonding #载入bonding模块 modprobe bonding 配置bonding # # cat /etc/modprobe.d/bond0.conf alias bond0 bonding cd /etc/sysconfig/network-scripts/ # grep -v \u0026#34;^#\u0026#34; ifcfg-bond0 DEVICE=bond0 BOOTPROTO=static ONBOOT=yes IPADDR=192.168.5.88 NETMASK=255.255.255.0 GATEWAY=192.168.5.1 USERCTL=no ==================================================== BONDING_OPTS=\u0026#34;mode=0 miimon=100\u0026#34; 说明：这里使用了BONDING_OPTS选项，则不需要再使用 /etc/modprobe.d/bond0.conf 配置文件对绑定设备进行配置。参数mode=0，指负载均衡模式，详见下文。miimon是用来进行链路监测的，其原理是检测网上的链路状态，一般将miimon值设为100，表示系统每100ms监测一次链路连接状态，如果有一条线路不通就转入另一条线路。 ==================================================== # grep -v \u0026#34;^#\u0026#34; ifcfg-eth1 DEVICE=eth1 ONBOOT=yes BOOTPROTO=static MASTER=bond0 SLAVE=yes USERCTL=no # grep -v \u0026#34;^#\u0026#34; ifcfg-eth0 DEVICE=eth0 BOOTPROTO=static ONBOOT=yes MASTER=bond0 SLAVE=yes USERCTL=no 注意：建议不要指定MAC地址 # echo 100 \u0026gt; /sys/class/net/bond0/bonding/miimon # echo 6 \u0026gt; /sys/class/net/bond0/bonding/mode Mode of operation : 0 for balance-rr, 1 for active-backup, 2 for balance-xor； 3 for broadcast, 4 for 802.3ad, 5 for balance-tlb, 6 for balance-alb (charp) 重启网络 # /etc/init.d/network restart 检查下 ifconfig cat /proc/net/bonding/bond0 bonding模式 # bonding的模式：0-6，即：7种模式\n第一种模式： # mod=0 ，即：(balance-rr) Round-robin policy（平衡抡循环策略）\n特点：传输数据包顺序是依次传输（即：第1个包走eth2，下一个包就走eth3….一直循环下去，直到最后一个传输完毕），\n此模式提供负载平衡和容错能力；但是我们知道如果一个连接或者会话的数据包从不同的接口发出的话，中途再经过不同的链路，在客户端很有可能会出现数据包无序到达的问题，而无序到达的数据包需要重新要求被发送，这样网络的吞吐量就会下降\n第二种模式： # mod=1，即： (active-backup) Active-backup policy（主-备份策略）\n特点：只有一个设备处于活动状态，当\n一个宕掉另一个马上由备份转换为主设备。mac地址是外部可见得，从外面看来，bond的MAC地址是唯一的，以避免switch(交换机)发生混乱。此模式只提供了容错能力；由此可见此算法的优点是可以提供高网络连接的可用性，但是它的资源利用率较低，只有一个接口处于工作状态，在有\nN 个网络接口的情况下，资源利用率为1/N\n第三种模式： # mod=2，即：(balance-xor) XOR policy（平衡策略）\n特点：基于指定的传输HASH策略传输数据包。缺省的策略是：(源MAC地址 XOR 目标MAC地址) %\nslave数量。其他的传输策略可以通过xmit_hash_policy选项指定，此模式提供负载平衡和容错能力\n第四种模式： # mod=3，即：broadcast（广播策略） 特点：在每个slave接口上传输每个数据包，此模式提供了容错能力\n第五种模式： # mod=4，即：(802.3ad) IEEE 802.3ad Dynamic link aggregation（IEEE 802.3ad 动态链接聚合）\n特点：创建一个聚合组，它们共享同样的速率和双工设定。根据802.3ad规范将多个slave工作在同一个激活的聚合体下。\n外出流量的slave选举是基于传输hash策略，该策略可以通过xmit_hash_policy选项从缺省的XOR策略改变到其他策略。需要注意的是，并不是所有的传输策略都是802.3ad适应的，尤其考虑到在802.3ad标准43.2.4章节提及的包乱序问题。不同的实现可能会有不同的适应性。\n必要条件：\n条件1：ethtool支持获取每个slave的速率和双工设定\n条件2：switch(交换机)支持IEEE 802.3ad Dynamic link aggregation\n条件3：大多数switch(交换机)需要经过特定配置才能支持802.3ad模式\n第六种模式： # mod=5，即：(balance-tlb) Adaptive transmit load balancing（适配器传输负载均衡）\n特点：不需要任何特别的switch(交换机)支持的通道bonding。在每个slave上根据当前的负载（根据速度计算）分配外出流量。如果正在接受数据的slave出故障了，另一个slave接管失败的slave的MAC地址。\n必要条件：ethtool支持获取每个slave的速率\n第七种模式： # mod=6，即：(balance-alb) Adaptive load balancing（适配器适应性负载均衡）\n特点：\n该模式包含了balance-tlb模式，同时加上针对IPV4流量的接收负载均衡(receive load balance,\nrlb)，而且不需要任何switch(交换机)的支持。接收负载均衡是通过ARP协商实现的。\nbonding驱动截获本机发送的ARP应答，并把源硬件地址改写为bond中某个slave的唯一硬件地址，从而使得不同的对端使用不同的硬件地址进行通信。来自服务器端的接收流量也会被均衡。\n当本机发送ARP请求时，bonding驱动把对端的IP信息从ARP包中复制并保存下来。当ARP应答从对端到达时，bonding驱动把它的硬件地址提取出来，并发起一个ARP应答给bond中的某个slave。\n使用ARP协商进行负载均衡的一个问题是：每次广播\nARP请求时都会使用bond的硬件地址，因此对端学习到这个硬件地址后，接收流量将会全部刘翔当前的slave。\n这个问题通过给所有的对端发送更新（ARP应答）来解决，应答中包含他们独一无二的硬件地址，从而导致流量重新分布。当新的slave加入到bond中时，或者某个未激活的slave重新激活时，接收流量也要重新分布。\n接收的负载被顺序地分布（round\nrobin）在bond中最高速的slave上当某个链路被重新接上，或者一个新的slave加入到bond中，接收流量在所有当前激活的slave中全部重新分配，通过使用指定的MAC地址给每个\nclient发起ARP应答。下面介绍的updelay参数必须被设置为某个大于等于switch(交换机)转发延时的值，从而保证发往对端的ARP应答不会被switch(交换机)阻截。\n必要条件：\n条件1：ethtool支持获取每个slave的速率；\n条件2：底层驱动支持设置某个设备的硬件地址，从而使得总是有个slave(curr_active_slave)使用bond的硬件地址，同时保证每个bond\n中的slave都有一个唯一的硬件地址。如果curr_active_slave出故障，它的硬件地址将会被新选出来的\ncurr_active_slave接管其实mod=6与mod=0的区别：mod=6，先把eth2流量占满，再占eth3，….ethX；而mod=0的话，会发现2个口的流量都很稳定，基本一样的带宽。而mod=6，会发现第一个口流量很高，第2个口只占了小部分流量\n"},{"id":66,"href":"/blog/linux/r1bIUL458Cz/","title":"centos升级 排除不想升级的软件包","section":"📚 我的文章","content":" 方法一 # yum --exclude=\u0026#34;kernel*\u0026#34; update 方法二 # cat /etc/yum.conf [main] ...... exclude=kernel* 修改/etc/yum.conf，在“[main]”的最后加上“exclude=kernel*”即可。\n总结 # 方法一为零时的，也就是只在当次有效，而方法二为永久有效。可根据不同情况选择。\n"},{"id":67,"href":"/blog/ffmpeg/BkpKIL498RM/","title":"ffmbc之转DVCPROHD","section":"📚 我的文章","content":"ffmbc -i xx.ts -vcodec dvvideo -flags +ildct+ilme -tff -pix_fmt yuv422p -vf scale=1440:1080:1 -acodec pcm_s16le -ar 48000 -ac 1 -y xx.mxf "},{"id":68,"href":"/blog/ffmpeg/Hy0UI8V9I0M/","title":"ffmpeg 多音轨混合成多声道","section":"📚 我的文章","content":" 使用FFmpeg制作多声道视频\n将8个音轨混合成双声道\nffmpeg -i input.mkv -filter_complex \u0026#34;[0:1][0:2][0:3][0:4][0:5][0:6][0:7][0:8] amerge=inputs=8\u0026#34; -c:a pcm_s16le output.mkv "},{"id":69,"href":"/blog/ffmpeg/B1mILV58AM/","title":"ffmpeg获取display_picture_number对应帧信息","section":"📚 我的文章","content":" 使用方式 # ffmpeg -i input -vf \u0026#34;select=eq(n\\,15237)\u0026#34;,showinfo -an -f null /dev/null 输出结果 # 15237为display_picture_number\n[Parsed_showinfo_1 @ 0x41ca760] n: 0 pts:54860400 pts_time:609.56 pos:427032896 fmt:yuv420p sar:1/1 s:1920x1080 i:T iskey:0 type:B checksum:A2FB0133 plane_checksum:[7E1FA1A9 3D005549 67BC0A32] mean:[92 127 134] stdev:[62.5 9.2 20.7] 参数解释 # ### showinfo ### 不改变输入而在行中显示每帧信息。 显示的信息以`key/value`的序列形式给出 下面是将显示在输出中的值： - n 帧序数，从0开始计数 - pts 输入帧的时间戳，以时基为单位，时间依赖于输入 - pts_time 按秒计的时间戳 - pos 输入帧在输入流中的偏移定位，-1表示信息不可用和/或无意义（例如合成视频中） - fmt 像素格式名 - sar 输入帧的宽高比，表示为`num/den`格式 - s 输入帧尺寸，语法同于[视频尺寸（分辨率）](ffmpeg-doc-cn-07.md#视频尺寸（分辨率）) - i 交错模式 (\u0026#34;P\u0026#34;对应 \u0026#34;逐行\u0026#34;, \u0026#34;T\u0026#34; 对应上场优先, \u0026#34;B\u0026#34;为下场优先t) - iskey 为1表示是关键帧，0则不是 - type 输入帧图片类型 (\u0026#34;I\u0026#34;对应I帧, \u0026#34;P\u0026#34; 对应P帧, \u0026#34;B\u0026#34; 对应B帧,或者 \u0026#34;?\u0026#34;对应未知类型).参考定义与`libavutil/avutil.h`中的`av_get_picture_type_char`函数和` - checksum 输入帧所有信息内容的 Adler-32校验值 (以16进制输出) - plane_checksum 输入帧所有信息内容的 Adler-32校验值 (以16进制输出), 以格式\u0026#34;[c0 c1 c2 c3]\u0026#34;显示 "},{"id":70,"href":"/blog/ffmpeg/BJDz88N580G/","title":"ffmpeg逐行扫描转隔行扫描","section":"📚 我的文章","content":" 命令参数 # ffmpeg -i input -aspect 16:9 -c:v mpeg2video -b:v 4000k -minrate 4000k -maxrate 4000k -bufsize 2000k -dc 9 -flags +ilme+ildct -alternate_scan 1 -top 0 output 其实主要的就是如下参数：\n-flags +ilme+ildct -alternate_scan 1 -top 0 alternate_scan使用隔行转码，top不一般没有什么要求的话頂场优先就可以了。\n隔行转逐行 # ffmpeg -i input -aspect 16:9 -c:v mpeg2video -b:v 4000k -minrate 4000k -maxrate 4000k -bufsize 2000k -dc 9 -deinterlace output 添加一个“deinterlace”即可。\n"},{"id":71,"href":"/blog/linux/HJi_UUE5ICG/","title":"linux bash截取字符串的几种方法","section":"📚 我的文章","content":" # 号截取，删除左边字符，保留右边字符 # var=http://www.aaa.com/123.htm echo ${var#*//} 其中var是变量名，#号是运算符， 号是通配符，//表示从左边开始删除第一个到//处的所有字符即删除http://\n结果是 ：www.aaa.com/123.htm\n## 号截取，删除左边字符，保留右边字符 # var=http://www.aaa.com/123.htm echo ${var##*/} ##*/ 表示从左边开始删除最后（最右边）一个 / 号及左边的所有字符即删除 http://www.aaa.com/\n结果是 123.htm\n% 号截取，删除右边字符，保留左边字符 # var=http://www.aaa.com/123.htm echo ${var%/*} %/* 表示从右边开始，删除第一个 / 号及右边的字符\n结果是：http://www.aaa.com\n%% 号截取，删除右边字符，保留左边字符 # var=http://www.aaa.com/123.htm echo ${var%%/*} %%/* 表示从右边开始，删除最后（最左边）一个 / 号及右边的字符\n结果是：http:\n: 号截取，从左边第几个字符开始，及字符的个数 # var=http://www.aaa.com/123.htm echo ${var:0:5} 其中的 0 表示左边第一个字符开始，5 表示字符的总个数。\n结果是：http:\n: 号截取，从左边第几个字符开始，一直到结束 # var=http://www.aaa.com/123.htm echo ${var:7} 其中的 7 表示左边第8个字符开始，一直到结束。\n结果是 ：www.aaa.com/123.htm\n: 号截取，从右边第几个字符开始，及字符的个数 # var=http://www.aaa.com/123.htm echo ${var:0-7:3} 其中的 0-7 表示右边算起第七个字符开始，3 表示字符的个数。\n结果是：123\n: 号截取，从右边第几个字符开始，一直到结束 # var=http://www.aaa.com/123.htm echo ${var:0-7} 表示从右边第七个字符开始，一直到结束。\n结果是：123.htm\n注：（左边的第一个字符是用 0 表示，右边的第一个字符用 0-1 表示）\n"},{"id":72,"href":"/blog/linux/rJvbIUV580z/","title":"linux crontab计划任务详解","section":"📚 我的文章","content":" crontab命令常见于Unix和类Unix的操作系统之中，用于设置周期性被执行的指令\n配置文件 # cat /etc/crontab SHELL=/bin/bash 计划任务的默认脚本bash shell PATH=/sbin:/bin:/usr/sbin:/usr/bin 默认搜索路径 MAILTO=root 当计划任务有标准输出或标准错误输出时，会将结果发邮件给root HOME=/ # run-parts 01 * * * * root run-parts /etc/cron.hourly /etc/ 后面一定是个文件夹，每小时执行 02 4 * * * root run-parts /etc/cron.daily 22 4 * * 0 root run-parts /etc/cron.weekly 42 4 1 * * root run-parts /etc/cron.monthly 注意事项 # 多个计划任务不宜同时进行防止有非法计划任务周和日，月不可同时并存，容易导致计划任务时间混乱\n简要说明 # crond\n是linux用来定期执行程序的命令。当安装完成操作系统之后，默认便会启动此任务调度命令。crond命令每分锺会定期检查是否有要执行的工作，如果有要执行的工作便会自动执行该工作。而linux任务调度的工作主要分为以下两类：1、系统执行的工作：系统周期性所要执行的工作，如备份系统数据、清理缓存。2、个人执行的工作：某个用户定期要做的工作，例如每隔10分钟检查邮件服务器是否有新信，这些工作可由每个用户自行设置\ncrontab是UNIX系统下的定时任务触发器，其使用者的权限记载在下列两个文件中：\n文件含义 # /etc/cron.deny 该文件中所列的用户不允许使用Crontab命令\n/etc/cron.allow 该文件中所列的用户允许使用Crontab命令\n/var/spool/cron/ 是所有用户的crontab文件\n/var/spool/cron/crontabs /var/spool/cron/crontabs /etc/crontab 系统计划任务列表文件\nCrontab命令的格式为：crontab –l|-r|-e|-i [username]，其参数含义如表一： 参数名称 含义 示例 -l 显示用户的Crontab文件的内容 crontabl –l -i 删除用户的Crontab文件前给提示 crontabl -ri -r 从Crontab目录中删除用户的Crontab文件 crontabl -r -e 编辑用户的Crontab文件 crontabl -e 基本格式 # command \u0026lt;\u0026ndash;\u0026gt; 分　时　日　月　周　命令 第1列表示分钟1～59 每分钟用*或者 */1表示\n第2列表示小时1～23（0表示0点）\n第3列表示日期1～31\n第4列表示月份1～12\n第5列标识号星期0～6（0表示星期天）\n第6列要运行的命令\n时间数值特殊表示方法 # ＊ 表示该范围内的任意时间 ，表示间隔的多个不连续时间点\n－ 表示一个连续的时间范围\n/n 指定间隔的时间频率\n常用例子 # #每晚的21:30重启apache 30 21 * * * /usr/local/etc/rc.d/lighttpd restart #每月1、10、22日的4 : 45重启apache 45 4 1,10,22 * * /usr/local/etc/rc.d/lighttpd restart #每周六、周日的1 : 10重启apache 10 1 * * 6,0 /usr/local/etc/rc.d/lighttpd restart #每天18 : 00至23 : 00之间每隔30分钟重启apache 0,30 18-23 * * * /usr/local/etc/rc.d/lighttpd restart #每个星期的星期六的11 : 00 pm重启apache 0 23 * * 6 /usr/local/etc/rc.d/lighttpd restart #每一小时重启apache * */1 * * * /usr/local/etc/rc.d/lighttpd restart #每天的晚上11点到早上7点之间，每隔一小时重启apache * 23-7/1 * * * /usr/local/etc/rc.d/lighttpd restart #每月的4号与每周一到周三的11点重启apache 0 11 4 * mon-wed /usr/local/etc/rc.d/lighttpd restart #每年的一月一号的4点重启apache 0 4 1 jan * /usr/local/etc/rc.d/lighttpd restart "},{"id":73,"href":"/blog/linux/rJJe8UNcU0M/","title":"linux nfs配置及访问控制","section":"📚 我的文章","content":" NFS软件包 # nfs-utils portmap (rhel6换成了rpcbind ,所以启动服务时需要注意)\nNFS文件 # /etc/exports #NFS主配置文件 /etc/init.d/nfs #NFS启动脚本 /etc/init.d/protmap\n#portmap启动脚本 /var/lib/*tab #NFS日志文件\n书写规则 # 目录名(绝对路径) 客户端主机名、IP或“*”(选项) 选项可选择如下：\nsync：设置NFS服务器同步写磁盘,这样不会轻易丢失数据,建议所有的NFS共享目录使用该选项. ro：设置输出的共享目录为只读，与rw不能同时使用。\nrw：设置输出的共享目录为可读写，与ro不能同时使用。 root_squash：root用户访问共享目录的身份会自动变成nobody身份。\nno_root_squash：root用户会以自己的真实身份访问共享目录，不安全，不建议使用。 更多选项可在网上查\nshowmount # showmount命令用于查询显示NFS服务器的相关信息 显示NFS服务器的输出目录列表 显示当前本机中NFS服务器输出列表\nshowmount -e 显示指点NFS服务器中的共享目录列表\nshowmount -e IP 防火墙配置 # nfsd：2049 rhel5 portmap：111 rhel6 rpcbind：111\nrquotad,mountd,sratd和lockd可以强制使用一个大于1024的静态端口\n修改/etc/sysconfig/nfs文件 QUOTAD_PORT=40001 #rpc.quotad进程端口 LOCKD_TCPPORT=40002 #rpc.lockd进程端口 LOCKD_UDPPORT=40002 MOUNTD_PORT=40003 #rpc.mountd进程端口 STARTD_PORT=40004 #rpc.sratd进程端口 exportfs # 修改了/etc/exports文件不需要重启nfs，只要重新加载/etc/exports文件即可。\n-a：全部挂载（或卸载）/etc/exports文件内的设定。\n-r：重新加载/etc/exports中的设置，此外同步更新/etc/exports及/var/lib/nfs/xtab中的内容。\n-u：卸载某一目录。\n-v：在export时将共享的目录显示在屏幕上。\n常用组合 # exportfs -rv (重新加载配置并输出当前共享的目录)\nexportfs -auv (停止当前主机中NFS服务器的所有输出目录)\n服务配置 # vim /etc/exports /home/share 10.1.1.2(sync,rw) *(sync,ro) linux使用 # mount -t nfs ip地址:/home/share/ /mnt Windwos使用 # Windows 7或Windows 2008支持NFS客户端,NFS服务端只有Windows Server版本支持\nshowmount -e 10.1.1.1 mount \\\\10.1.1.1\\share Z: 需要注意的是，mount 挂载点和Linux及UNIX有所不同，不是使用一个目录作为挂载点，而是使用一个未被使用的盘符。\n"},{"id":74,"href":"/blog/linux/SJ68UEcUCM/","title":"linux openssh 常见问题汇总","section":"📚 我的文章","content":" 软件包名\nopenssh-server openssh-clients\n服务名：sshd\n服务端配置文件：/etc/ssh/sshd.config 客户端…\n软件包名 # openssh-server openssh-clients\n服务名：sshd # 服务端配置文件：/etc/ssh/sshd.config 客户端配置文件：/etc/ssh/ssh.config\n启动服务 # server sshd start 文件说明 # ~/.ssh/known_hosts #存放访问过的服务器的公钥 ~/.ssh/authorized_keys #存放需要验证的客户机的公钥 常见问题 # 1、ssh访问慢 # 原因：访问服务器的时候会把服务器的IP地址反向解析为域名，如果无法解析就会导致登陆时很慢。 下面几种方法都可以解决这个问题\n1、清空/etc/resolv.conf文件中的nameserver记录 2、在客户机的/etc/hosts文件中添加服务器域名的解析记录\n3、修改客户端的/etc/ssh/ssh.config文件 GSSAPLAuthentication no\n4、修改服务端的/etc/ssh/sshd.config文件 UserDNS no\n2、~/.ssh权限 # .ssh目录和下面的文件权限，组和其他人不能有w的权限 解决方法：降低第服务端的权限检查\nvim /etc/ssh/sshd_config StrictModes no 3、第一次访问sshserver时不用输入yes # ssh -o StrictHostKeyChecking=no username@sshserver vim /etc/ssh/ssh.config StrictHostKeyChecking=no 公钥认证 # ssh-keygen -t rsa #指定rsa算法 在~/.ssh/下生产两个文件 id_rsa用户的私钥 id_rsa.pub用户的公钥ssh- copy-id -i ~/.ssh/id_rsa.pub username@sshserver scp使用 # scp 用户名@服务器地址:文件 本地路径 scp 本地文件 用户名@服务器地址:目标路径\nsftp使用 # sftp 用户名@服务器地址\ntcp_wrappers访问控制 # 检查某个服务是否受tcp_wrappers管理支持\nldd $(which sshd)|grep libwrap 先检查/etc/hosts.allow然后检查/etc/hosts.deny 如果两个文件都没有匹配的规则，则放行。\nsshd:all EXCEPT 192.168.0.0/255.255.255.0 可以使用all、?、* 阻挡所有但排除192.168.0.0网段\n"},{"id":75,"href":"/blog/linux/rkxlI845IAz/","title":"linux samba配置及乱码的解决方法","section":"📚 我的文章","content":" 简要说明 # samba：这个软体主要提供了SMB伺服器所需的各项服务程式(smbd及nmbd)、的文件档、以及其他与SAMBA相关的logrotate设定档及开机预设选项档案等；\nsamba-client：这个软体则提供了当Linux做为SAMBA\nClient端时，所需要的工具指令，例如挂载SAMBA档案格式的mount.cifs、取得类似网芳相关树状图的smbtree等等；\nsamba-common：这个软体提供的则是伺服器与用户端都会使用到的资料，包括SAMBA的主要设定档(smb.conf)、语法检验指令(testparm)等等；\n/var/lib/samba/private/{passdb.tdb,secrets.tdb}：管理Samba的使用者帐号/密码时，会用到的资料库档案；\n服务配置 # vim /etc/samba/smb.conf\n[share] path = /share //共享的目录 writable = yes //是否可写 write list = test // test用户可以访问该共享 访问控制 # max connections = 最大连接数 deadtime = 断掉连接时间（分钟）【0为不限制】 hosts deny = IP 、域名、except hosts allow = IP 、域名、except 用户控制 # public = no #不允许匿名用户访问 browseable = no #隐藏目录 （知道目录同样可以访问） valid users = 用户或列表或@用户组 writable = yes #可写（目录本身要可写） weite list = 用户或列表或@用户组 read only = yes #只读设置 create mask = 0744 #控制客户机创建文件的权限 directory mask = 0744 # 控制客户机创建目录的权限 安全级别 # samba服务器的安全级别分为5种，分别是user、share、server、domain和ads。\n在设置不同的级别时，samba服务器还会使用口令服务器和加密口令。\n1、user —–客户端访问服务器时需要输入用户名和密码，通过验证后，才能使用服务器的共享资源。此级别使用加密的方式传送密码。\n2、share —–客户端连接服务器时不需要输入用户名和密码\n3、server —–客户端在访问时同样需要输入用户名和密码，但是，密码验证需要密码验证服务器来负责。\n4、domain —–采用域控制器对用户进行身份验证\n5、ads —–若samba服务器加入到Windows活动目录中，则使用ads安全级别，ads安全级别也必须指定口令服务器\n启动服务 # service smb reload 管理工具 # 修改完配置文件后，启动服务，然后添加Samba用户（pdbedit -a 用户名）\n使用pdbedit指令功能 选项与参数：\n-L ：列出目前在资料库当中的帐号与UID 等相关资讯；\n-v ：需要搭配-L 来执行，可列出更多的讯息，包括家目录等资料；\n-w ：需要搭配-L 来执行，使用旧版的smbpasswd 格式来显示资料；\n-a ：新增一个可使用Samba 的帐号，后面的帐号需要在/etc/passwd 内存在者；\n-r ：修改一个帐号的相关资讯，需搭配很多特殊参数，请man pdbedit；\n-x ：删除一个可使用Samba 的帐号，可先用-L 找到帐号后再删除；\n-m ：后面接的是机器的代码(machine account)，与domain model 有关！\n乱码问题 # cat /etc/sysconfig/i18n [global] # 如果locale是zh_CN.UTF-8，做如下设置： display charset = UTF-8 unix charset = UTF-8 dos charset = UTF-8 # 如果locale是zh_CN.GBK或zh_CN.gb2312，做如下设置： display charset = cp936 unix charset = cp936 dos charset = cp936 linux访问 # smbclient //IP/目录名 -U 登录用户名 mount -t cifs -o username=用户名,passwd=密码,iocharset=gb2312,uid,pid,rw //ip 挂载点 smbtar -s server -u user -p passwd -x sharename -t output.tar windows访问 # windows访问方式就不说了。下面说下清除windows共享访问方法：\n打开cmd. c:\\\u0026gt;net use * /del "},{"id":76,"href":"/blog/linux/B1muLLNcIRf/","title":"Linux Screen命令","section":"📚 我的文章","content":"Linux screen 命令用于多重视窗管理程序。\nscreen 为多重视窗管理程序。此处所谓的视窗，是指一个全屏幕的文字模式画面。通常只有在使用 telnet 登入主机或是使用老式的终端机时，才有可能用到 screen 程序。\n语法 # screen [-AmRvx -ls -wipe][-d \u0026lt;作业名称\u0026gt;][-h \u0026lt;行数\u0026gt;][-r \u0026lt;作业名称\u0026gt;][-s \u0026lt;shell\u0026gt;][-S \u0026lt;作业名称\u0026gt;] 参数说明：\n-A 将所有的视窗都调整为目前终端机的大小。 -d \u0026lt;作业名称\u0026gt; 将指定的 screen 作业离线。 -h \u0026lt;行数\u0026gt; 指定视窗的缓冲区行数。 -m 即使目前已在作业中的 screen 作业，仍强制建立新的 screen 作业。 -r \u0026lt;作业名称\u0026gt; 恢复离线的 screen 作业。 -R 先试图恢复离线的作业。若找不到离线的作业，即建立新的 screen 作业。 -s 指定建立新视窗时，所要执行的 shell。 -S \u0026lt;作业名称\u0026gt; 指定 screen 作业的名称。 -v 显示版本信息。 -x 恢复之前离线的 screen 作业。 -ls 或 \u0026ndash;list 显示目前所有的 screen 作业。 -wipe 检查目前所有的 screen 作业，并删除已经无法使用的 screen 作业。 实例 # 创建 screen 终端\nscreen //创建 screen 终端 创建 screen 终端 并执行任务\nscreen vi ~/main.c //创建 screen 终端 ，并执行 vi命令 离开 screen 终端\nscreen vi ~/main.c //创建 screen 终端 ，并执行 vi命令 #include main () { } \u0026#34;~/mail.c\u0026#34; 0,0-1 在 screen 终端 下 按下 Ctrl+a d键 重新连接离开的 screen 终端\nscreen -ls # 显示已创建的screen终端 There are screens on: 2433.pts-3.linux (2013年10月20日 16时48分59秒) (Detached) 2428.pts-3.linux (2013年10月20日 16时48分05秒) (Detached) 2284.pts-3.linux (2013年10月20日 16时14分55秒) (Detached) 2276.pts-3.linux (2013年10月20日 16时13分18秒) (Detached) 4 Sockets in /var/run/screen/S-root. screen -r 2276 //连接 screen_id 为 2276 的 screen终端 "},{"id":77,"href":"/blog/linux/HyYg884c80f/","title":"linux 防御SYN攻击","section":"📚 我的文章","content":" 一、默认syn配置 # sysctl -a | grep _syn net.ipv4.tcp_max_syn_backlog = 1024 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_synack_retries = 5 net.ipv4.tcp_syn_retries = 5 tcp_max_syn_backlog 是SYN队列的长度，加大SYN队列长度可以容纳更多等待连接的网络连接数。\ntcp_syncookies是一个开关，是否打开SYN Cookie 功能，该功能可以防止部分SYN攻击。\ntcp_synack_retries和tcp_syn_retries定义SYN 的重试连接次数，将默认的参数减小来控制SYN连接次数的尽量少。\n二、修改syn配置 # ulimit -HSn 65535 sysctl -w net.ipv4.tcp_max_syn_backlog=2048 sysctl -w net.ipv4.tcp_syncookies=1 sysctl -w net.ipv4.tcp_synack_retries=2 sysctl -w net.ipv4.tcp_syn_retries=2 三、添加防火墙规则 # #Syn 洪水攻击(--limit 1/s 限制syn并发数每秒1次) iptables -A INPUT -p tcp --syn -m limit --limit 1/s -j ACCEPT #防端口扫描 iptables -A FORWARD -p tcp --tcp-flags SYN,ACK,FIN,RST RST -m limit --limit 1/s -j ACCEPT #防洪水ping iptables -A FORWARD -p icmp --icmp-type echo-request -m limit --limit 1/s -j ACCEPT 四、添加开机启动 # 最后别忘记将二、三、里面的命令写到/etc/rc.d/rc.local\n"},{"id":78,"href":"/blog/linux/S13z8UE5UCf/","title":"linux内存清理释放命令","section":"📚 我的文章","content":" 命令 # sync echo 1 \u0026gt; /proc/sys/vm/drop_caches echo 2 \u0026gt; /proc/sys/vm/drop_caches echo 3 \u0026gt; /proc/sys/vm/drop_caches 解释 # cache释放： To free pagecache: echo 1 \u0026gt; /proc/sys/vm/drop_caches To free dentries and inodes: echo 2 \u0026gt; /proc/sys/vm/drop_caches To free pagecache, dentries and inodes: echo 3 \u0026gt; /proc/sys/vm/drop_caches 说明 # 释放前最好sync一下，防止丢数据。\n"},{"id":79,"href":"/blog/linux/B1FO88V580M/","title":"Linux清除内存","section":"📚 我的文章","content":" 如何在 Linux 中清除缓存（Cache）？ # 每个 Linux 系统有三种选项来清除缓存而不需要中断任何进程或服务。\n（LCTT 译注：Cache，译作“缓存”，指 CPU\n和内存之间高速缓存。Buffer，译作“缓冲区”，指在写入磁盘前的存储再内存中的内容。在本文中，Buffer 和 Cache 有时候会通指。）\n仅清除页面缓存（PageCache） # sync; echo 1 \u0026gt; /proc/sys/vm/drop_caches 清除目录项和inode # sync; echo 2 \u0026gt; /proc/sys/vm/drop_caches 清除页面缓存，目录项和inode # sync; echo 3 \u0026gt; /proc/sys/vm/drop_caches 上述命令的说明：\nsync\n将刷新文件系统缓冲区（buffer），命令通过“;”分隔，顺序执行，shell在执行序列中的下一个命令之前会等待命令的终止。正如内核文档中提到的，写入到drop_cache将清空缓存而不会杀死任何应用程序/服务，echo命令做写入文件的工作。\n如果你必须清除磁盘高速缓存，第一个命令在企业和生产环境中是最安全，”…echo 1\u0026gt; …“只会清除页面缓存。\n在生产环境中不建议使用上面的第三个选项”…echo 3 \u0026gt; …” ，除非你明确自己在做什么，因为它会清除缓存页，目录项和inodes。\n"},{"id":80,"href":"/blog/macos/H1JGLLVcL0G/","title":"MacOS 10.12 解决找不到任何来源设置","section":"📚 我的文章","content":" 安装第三方软件必备技能\n打开终端 ( 终端在 应用程序 - 实用工具内 )\n输入以下命令并回车\nsudo spctl --master-disable 然后查看问题是否解决， 偏好设置-\u0026gt;安全性与隐私-\u0026gt;通用-\u0026gt;任何来源\n"},{"id":81,"href":"/blog/linux/Sky_LU458CM/","title":"mediainfo获取ts文件大小和信息不准确（MPEG-TS：检测文件的序列）的解决办法","section":"📚 我的文章","content":" 解决mediainfo获取ts媒体信息不准确问题\n场景 # 在/opt/目录下总共有200多个文件文件名分别如下：\n/opt/2017LPL夏季赛第01集.ts\n/opt/2017LPL夏季赛第02集.ts\n/opt/2017LPL夏季赛第03集.ts\n…\n/opt/2017LPL夏季赛第227集.ts\n/opt/2017LPL夏季赛第228集.ts\n错误结果 # mediainfo /opt/2017LPL夏季赛第01集.ts General ID : 1 (0x1) Complete name : Z:\\vrs\\new_upload\\2018-01-16\\2017LPL夏季赛第01集.ts CompleteName_Last : Z:\\vrs\\new_upload\\2018-01-16\\2017LPL夏季赛第228集.ts Format : MPEG-TS File size : 560 GiB Duration : 53mn 32s Overall bit rate mode : Constant Overall bit rate : 1 496 Mbps Video ID : 100 (0x64) Menu ID : 1 (0x1) Format : AVC Format/Info : Advanced Video Codec Format profile : High@L4.0 Format settings, CABAC : No Format settings, ReFrames : 2 frames Codec ID : 27 Duration : 53mn 32s Bit rate mode : Constant Bit rate : 1 422 Mbps Nominal bit rate : 7 800 Kbps / 7 800 Kbps Width : 1 920 pixels Height : 1 080 pixels Display aspect ratio : 16:9 Frame rate : 25.000 fps Color space : YUV Chroma subsampling : 4:2:0 Bit depth : 8 bits Scan type : Progressive Bits/(Pixel*Frame) : 27.431 Stream size : 532 GiB (95%) Writing library : x264 core 148 r2705 3f5ed56 Encoding settings : cabac=0 / ref=2 / deblock=1:0:0 / analyse=0x3:0x13 / me=hex / subme=7 / psy=1 / psy_rd=1.00:0.00 / mixed_ref=1 / me_range=16 / chroma_me=1 / trellis=1 / 8x8dct=1 / cqm=0 / deadzone=21,11 / fast_pskip=1 / chroma_qp_offset=-2 / threads=34 / lookahead_threads=5 / sliced_threads=0 / nr=0 / decimate=1 / interlaced=0 / bluray_compat=0 / constrained_intra=0 / bframes=3 / b_pyramid=0 / b_adapt=1 / b_bias=0 / direct=1 / weightb=1 / open_gop=0 / weightp=1 / keyint=32 / keyint_min=16 / scenecut=40 / intra_refresh=0 / rc_lookahead=32 / rc=cbr / mbtree=1 / bitrate=7800 / ratetol=1.0 / qcomp=0.60 / qpmin=0 / qpmax=69 / qpstep=4 / vbv_maxrate=7800 / vbv_bufsize=1560 / nal_hrd=cbr / filler=1 / ip_ratio=1.40 / aq=1:1.00 Audio ID : 101 (0x65) Menu ID : 1 (0x1) Format : MPEG Audio Format version : Version 1 Format profile : Layer 2 Codec ID : 3 Duration : 53mn 32s Bit rate mode : Constant Bit rate : 96.0 Kbps Channel(s) : 2 channels Sampling rate : 48.0 KHz Compression mode : Lossy Delay relative to video : -10ms Stream size : 36.8 MiB (0%) Menu ID : 4096 (0x1000) Menu ID : 1 (0x1) Duration : 53mn 32s List : 100 (0x64) (AVC) / 101 (0x65) (MPEG Audio) Service name : RM_SERVICE_01 Service provider : RealMagic Service type : digital television 正确结果 # mediainfo /opt/2017LPL夏季赛第01集.ts General ID : 1 (0x1) Complete name : /data/stb/product/vrs/new_upload/./2018-01-16/2017LPL夏季赛第01集.ts Format : MPEG-TS File size : 2.58 GiB Duration : 43mn 42s Overall bit rate mode : Constant Overall bit rate : 8 464 Kbps Video ID : 100 (0x64) Menu ID : 1 (0x1) Format : AVC Format/Info : Advanced Video Codec Format profile : High@L4.0 Format settings, CABAC : No Format settings, ReFrames : 2 frames Codec ID : 27 Duration : 43mn 42s Bit rate mode : Constant Bit rate : 7 800 Kbps / 7 800 Kbps Width : 1 920 pixels Height : 1 080 pixels Display aspect ratio : 16:9 Frame rate : 25.000 fps Color space : YUV Chroma subsampling : 4:2:0 Bit depth : 8 bits Scan type : Progressive Bits/(Pixel*Frame) : 0.150 Stream size : 2.43 GiB (94%) Writing library : x264 core 148 r2705 3f5ed56 Encoding settings : cabac=0 / ref=2 / deblock=1:0:0 / analyse=0x3:0x13 / me=hex / subme=7 / psy=1 / psy_rd=1.00:0.00 / mixed_ref=1 / me_range=16 / chroma_me=1 / trellis=1 / 8x8dct=1 / cqm=0 / deadzone=21,11 / fast_pskip=1 / chroma_qp_offset=-2 / threads=34 / lookahead_threads=5 / sliced_threads=0 / nr=0 / decimate=1 / interlaced=0 / bluray_compat=0 / constrained_intra=0 / bframes=3 / b_pyramid=0 / b_adapt=1 / b_bias=0 / direct=1 / weightb=1 / open_gop=0 / weightp=1 / keyint=32 / keyint_min=16 / scenecut=40 / intra_refresh=0 / rc_lookahead=32 / rc=cbr / mbtree=1 / bitrate=7800 / ratetol=1.0 / qcomp=0.60 / qpmin=0 / qpmax=69 / qpstep=4 / vbv_maxrate=7800 / vbv_bufsize=1560 / nal_hrd=cbr / filler=1 / ip_ratio=1.40 / aq=1:1.00 Audio ID : 101 (0x65) Menu ID : 1 (0x1) Format : MPEG Audio Format version : Version 1 Format profile : Layer 2 Codec ID : 3 Duration : 43mn 42s Bit rate mode : Constant Bit rate : 96.0 Kbps Channel(s) : 2 channels Sampling rate : 48.0 KHz Compression mode : Lossy Delay relative to video : -10ms Stream size : 30.0 MiB (1%) Menu ID : 4096 (0x1000) Menu ID : 1 (0x1) Duration : 43mn 42s List : 100 (0x64) (AVC) / 101 (0x65) (MPEG Audio) Service name : RM_SERVICE_01 Service provider : RealMagic Service type : digital television 解决办法 # 根据作者的github上提交的代码描述\nhttps://github.com/MediaArea/MediaInfoLib/commit/78f739893c85d4b1397276ef15badd160907b7aa\nvim \u0026#34;Source/MediaInfo/Multiple/File_MpegTs.cpp\u0026#34; void File_MpegTs::Streams_Accept() { ... if (!IsSub) { ... //TestContinuousFileNames(); ... } } 我们只要将”TestContinuousFileNames();“这行注释掉即可解决默认获取ts文件序列问题\n"},{"id":82,"href":"/blog/linux/ByS8884qI0M/","title":"nginx+php+ThinkPHP环境常见错误总结","section":"📚 我的文章","content":" 错误一\n2017/09/07 16:39:18 [error] 21753#0: *26 FastCGI sent in stderr: “Primary s…\n错误一 # 2017/09/07 16:39:18 [error] 21753#0: *26 FastCGI sent in stderr: \u0026#34;Primary script unknown\u0026#34; while reading response header from upstream, client: 172.31.26.114, server: localhost, request: \u0026#34;GET /1.php HTTP/1.1\u0026#34;, upstream: \u0026#34;fastcgi://127.0.0.1:9000\u0026#34;, host: \u0026#34;10.200.8.220:8000\u0026#34; 解决版本 # 在server节点下添加以下配置\nroot /var/www/web; index index.php index.html index.htm; location ~ \\.php$ { try_files $uri = 404; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi.conf; } ThinkPHP配置 # 假如网站的根目录是/var/www/web，如果ThinkPHP的网站在/var/www/web/Test目录配置如下\nlocation /Test/ { if (!-e $request_filename){ rewrite ^/Test/(.*)$ /Test/index.php?s=$1 last; } } location ~ \\.php/?.*$ { try_files $uri = 404; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi.conf; #设置PATH_INFO并改写SCRIPT_FILENAME,SCRIPT_NAME服务器环境变量 #set $fastcgi_script_name2 $fastcgi_script_name; #if ($fastcgi_script_name ~ \u0026#34;^(.+\\.php)(/.+)$\u0026#34;) { # set $fastcgi_script_name2 $1; # set $path_info $2; #} #fastcgi_param PATH_INFO $path_info; #fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name2; #fastcgi_param SCRIPT_NAME $fastcgi_script_name2; } 如果是放在根目录下\nlocation / { if (!-e $request_filename){ rewrite ^/(.*)$ /index.php?s=$1 last; } } location ~ \\.php/?.*$ { try_files $uri = 404; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi.conf; #设置PATH_INFO并改写SCRIPT_FILENAME,SCRIPT_NAME服务器环境变量 #set $fastcgi_script_name2 $fastcgi_script_name; #if ($fastcgi_script_name ~ \u0026#34;^(.+\\.php)(/.+)$\u0026#34;) { # set $fastcgi_script_name2 $1; # set $path_info $2; #} #fastcgi_param PATH_INFO $path_info; #fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name2; #fastcgi_param SCRIPT_NAME $fastcgi_script_name2; } 最后来个完整的例子\nuser root; worker_processes auto; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; root /var/www/web; index index.php index.html index.htm; location / { index index.htm index.html index.php; } location /Test/ { if (!-e $request_filename){ rewrite ^/Test/(.*)$ /Test/index.php?s=$1 last; } } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } location ~ \\.php/?.*$ { try_files $uri = 404; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi.conf; #设置PATH_INFO并改写SCRIPT_FILENAME,SCRIPT_NAME服务器环境变量 #set $fastcgi_script_name2 $fastcgi_script_name; #if ($fastcgi_script_name ~ \u0026#34;^(.+\\.php)(/.+)$\u0026#34;) { # set $fastcgi_script_name2 $1; # set $path_info $2; #} #fastcgi_param PATH_INFO $path_info; #fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name2; #fastcgi_param SCRIPT_NAME $fastcgi_script_name2; } } } "},{"id":83,"href":"/blog/linux/rykY88V58CG/","title":"nignx修改最大上传文件大小限制","section":"📚 我的文章","content":"location / { root html; index index.html index.htm; client_max_body_size 1000m; } “client_max_body_size”设置一下上传的最大上限,然后重启nginx即可。\n"},{"id":84,"href":"/blog/linux/HybPILE5U0z/","title":"RabbitMQ 三种 Exchange 模式","section":"📚 我的文章","content":"RabbitMQ 中的 Exchange（交换机）负责接收生产者发送的消息，并根据类型将消息路由到相应的队列。常见的三种 Exchange 类型如下：\n1. Direct Exchange（直连模式） # ✅ 特点： # 根据消息的 routing key 精确匹配，将消息路由到绑定了 相同 routing key 的队列。 🎯 适用场景： # 一对一消息传递。 多个队列分别订阅不同的消息类型。 📌 示例： # 绑定情况：\nQueue A 绑定 routing key：error Queue B 绑定 routing key：info 发送消息：\nProducer 发送消息，routing key 为 error 结果：\n只有 Queue A 会接收到该消息。 2. Fanout Exchange（广播模式） # ✅ 特点： # 忽略 routing key。 所有绑定到该 Exchange 的队列都会收到消息。 🎯 适用场景： # 广播场景，例如系统通知、群发消息。 📌 示例： # 绑定情况：\nQueue A、Queue B 都绑定到同一个 fanout Exchange 发送消息：\nProducer 发送任意消息（routing key 无效） 结果：\nQueue A 和 Queue B 都会接收到该消息。 3. Topic Exchange（主题模式） # ✅ 特点： # 支持 通配符 匹配 routing key： *：匹配一个单词（以 . 分隔） #：匹配零个或多个单词 🎯 适用场景： # 灵活的订阅机制，如日志系统、新闻推送等。 📌 示例： # 绑定情况：\nQueue A 绑定 routing key：*.error Queue B 绑定 routing key：log.# 发送消息：\nProducer 发送 routing key：app.error → Queue A 接收 Producer 发送 routing key：log.system.info → Queue B 接收 🧾 模式对比表 # Exchange 类型 Routing Key 是否参与路由 匹配方式 典型应用场景 Direct ✅ 是 精确匹配 精准路由，分类消息 Fanout ❌ 否 广播 系统通知，全员推送 Topic ✅ 是 通配符匹配（*/#） 日志订阅，事件分发 "},{"id":85,"href":"/blog/linux/HkXeLI4cIAG/","title":"rabbitmq 消息队列安装和配置","section":"📚 我的文章","content":" erlang # 首先安装erlang语言环境\nyum install erlang -y rabbitMQ # rabbitMQ下载地址：直达安装方法:\nrpm -ivh --force --nodeps rabbitmq-server-3.6.0-1.noarch.rpm 或者 yum localinstall rabbitmq-server-3.6.0-1.noarch.rpm -y 启动服务 # /etc/init.d/rabbitmq-server start rabbitmq-plugins enable rabbitmq_management 配置主备 # 同步cookie # chmod 777 /var/lib/rabbitmq/.erlang.cookie scp /var/lib/rabbitmq/.erlang.cookie Go02:/var/lib/rabbitmq/.erlang.cookie chmod 400 /var/lib/rabbitmq/.erlang.cookie 添加节点 # rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl join_cluster [--ram] rabbit@Go01 //此处的Go01为主节点的hostname,需要在/etc/hosts中指定 rabbitmqctl start_app 删除节点 # rabbitmqctl stop_app rabbitmqctl forget_cluster_node rabbit@rabbit1 修改类型 # rabbitmqctl stop_app rabbitmqctl change_cluster_node_type ram rabbitmqctl start_app 添加用户 # rabbitmqctl add_user admin admin # 添加权限: rabbitmqctl set_permissions -p \u0026#34;/\u0026#34; admin \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; # 删除测试用户: rabbitmqctl delete_user guest # 赋予其administrator角色： rabbitmqctl set_user_tags admin administrator # 修改密码： rabbitmqctl change_password admin \u0026#39;12341234\u0026#39; 修改配置 # //防止服务端异常中断恢复后镜像队列不能恢复的问题 vim /etc/rabbitmq/rabbitmq.conf [ {rabbit,[{tcp_listeners,[5672]}, {cluster_partition_handling, autoheal}]} ]. #不要忘记最后面的那个点号哦！ 环境变量 # touch /etc/rabbitmq/rabbitmq-env.conf#输入 RABBITMQ_NODENAME=FZTEC-240088 节点名称 RABBITMQ_NODE_IP_ADDRESS=127.0.0.1 监听IP RABBITMQ_NODE_PORT=5672 监听端口 RABBITMQ_LOG_BASE=/data/rabbitmq/log 日志目录 RABBITMQ_PLUGINS_DIR=/data/rabbitmq/plugins 插件目录 RABBITMQ_MNESIA_BASE=/data/rabbitmq/mnesia 后端存储目录 RabbitMQ的用户角色分类 # none、management、policymaker、monitoring、administrator\nRabbitMQ各类角色描述： # none # 不能访问 management plugin\nmanagement # 用户可以通过AMQP做的任何事外加： 列出自己可以通过AMQP登入的virtual hosts 查看自己的virtual hosts中的queues,\nexchanges 和 bindings 查看和关闭自己的channels 和 connections 查看有关自己的virtual\nhosts的“全局”的统计信息，包含其他用户在这些virtual hosts中的活动。\npolicymaker # management可以做的任何事外加： 查看、创建和删除自己的virtual hosts所属的policies和parameters\nmonitoring # management可以做的任何事外加： 列出所有virtual hosts，包括他们不能登录的virtual hosts\n查看其他用户的connections和channels 查看节点级别的数据如clustering和memory使用情况 查看真正的关于所有virtual\nhosts的全局的统计信息\nadministrator # policymaker和monitoring可以做的任何事外加: 创建和删除virtual hosts 查看、创建和删除users\n查看创建和删除permissions 关闭其他用户的connections\n"},{"id":86,"href":"/blog/linux/H1z5LL49I0z/","title":"RabbitMQ性能优化","section":"📚 我的文章","content":" rabbitmq.config # rabbitmq.config文件时rabbitmq的配置文件，他遵守Erlang配置文件定义。\nrabbitmq.config文件位置：\nUnix $RABBITMQ_HOME/etc/rabbitmq Windows %APPDATA%\\RabbitMQ\\ 例子如下：\n[ {mnesia, [{dump_log_write_threshold, 1000}]}, {rabbit, [{tcp_listeners, [5673]}]} ]. Memory配置和设置 # RabbitMQ在使用当前机器的40%以上内存时候，会发出内存警告，并组织RabbitMQ所有连接（producer连接）。直到RabbitMQ将当前数据刷入到硬盘或者消息被客户端消费。\n当Erlang的垃圾回收机制运行起来（这是一个非常耗费资源的工作），会消费两倍内存。（默认是80%的内存）。因此需要操作系统支持OS swap和page\nfile.\n注意：在32为架构下，每个进程被限制为2GB。通常64架构系统限制每个进程为256TB，64位windows限制为8TB。就算在64位操作系统下，32位的进程只能用2GB内存。\n因此强烈推荐使用64bit Erlang vm和64bit os。\n当RabbitMQ不能识别你的系统的时候，你必须对vm_memory_high_watermark进行修改。\n当rabbitmq不能识别系统的时候，会设置内存为1024MB。所以rabbitmq实际使用的内存仅仅410MB。\n当系统为8GB的时候，我们可以这是vm_memory_high_watermark=3，那么我们实际可以使用的内存为3GB。\n配置Memory Threshold文件\n默认配置RabbitMQ的vm_memory_high_watermark=0.4\n[{rabbit, [{vm_memory_high_watermark, 0.4}]}]. 举例说明： # 当机器内存为16GB，那么40%，为6.4GB。主要当32系统时候，实际可以使用的内存为2GB，那么实际可以使用的内存为820MB。\n当我配置vm_memory_high_watermark=0 我们可以阻止所有消息发送。\n注意：这个百分比，最好不要修改。应为Erlang VM回收的时候会占据系统内存的80%。已经达到系统临界区。不要设置超过50%的百分比。\n配置Page Threshold文件 # 当内存中的数据达到一定数量后，他需要被page out出来。 默认配置\nvm_memory_high_watermark_paging_ratio=0.5。也就是vm_memory_high_watermark0.5。假设总内存8GB，0.4的使用内存是3.2。那么当内存叨叨3.20.5=1.6GB时候，系统将会大量置换页面。\n因此我们可以将页面置换的百分比调高。设置为0.75\n[{rabbit, [{vm_memory_high_watermark_paging_ratio, 0.75}, {vm_memory_high_watermark, 0.4}]}]. 注意：我们可以将vm_memory_high_watermark_paging_ratio设置超过1.0，那么不会发生内存换页的情况，也就是说，当内存超过总内存的40%之后，将会阻止所有producer产生消息。\n配置命令 # rabbitmqctl set_vm_memory_high_watermark 0.4 这是内存使用占总内存数的百分比\nrabbitmqctl set_vm_memory_high_watermark_paging_ratio 0.75 设置rabbitmq使用内存达到rabbitmq可用内存百分比，就出发页面交换功能。\nrabbitmqctl status 获得系统配置。\nDisk配置和设置 # RabbitMQ会在硬盘空间不够的时候，阻止Producer发送消息。这样可以保证RabbitMQ可以再任何时候，将内存中的数据置换到磁盘中来。通常会将硬盘剩余数据大小设置为机器的总内存大小。\n全局流控制会被触发，当可用总硬盘容量已经低于配置信息。broker数据库将会最少10秒检查一下警告是否发出或者清除。\n在RabbitMQ启动的后，会打印disk limit限制，但是不能识别的平台就不能显示信息。\n注意：当RabbitMQ是集群情况下，当其中有一台机器硬盘不足的时候，所有节点的producer链接都会被阻止。\nRabbitMQ会定期价检查总磁盘可用空间的大小。通常时间为10秒每次，当限制快被达到时候，RabbitMQ检查的时候会达到10次/s.\n配置Disk Free Space Limit # 我们可以直接设置硬盘的最小限制。也可以设置相对内存大小的设置。\n先设置磁盘1GB限制\n[{rabbit, [{disk_free_limit, 1000000000}]}]. 在这时相对于机器总内存\n[{rabbit, [{disk_free_limit, {mem_relative, 1.0}}]}]. Erlang的Hipe优化 # 可以设置hipe_compiles设置。可以看到有20-50%的性能优化。而你只需要付出1分钟左右的延迟启动。\nHiPE需要你检查是否编译进入你的Erlang安装环境。Ubuntu，需要安装erlang-base-hipe.默认有些平台不支持。如果Erlang VM\nsegfaults,请关闭这个选项。\n[{rabbit, [{hipe_compile, true}]}]. 参考：http://www.rabbitmq.com/configure.html#configuration-file\n"},{"id":87,"href":"/blog/linux/rkCKI84cLAG/","title":"rabbitmq之机器机器全部断电恢复记录","section":"📚 我的文章","content":"今天遇到一个rabbitmq集群同时断电，当机器全部启动的时候发现rabbitmq无法正常启动，然后发现如下日志。\n=INFO REPORT==== 25-Apr-2018::11:11:07 === Starting RabbitMQ 3.5.3 on Erlang R16B03-1 Copyright (C) 2007-2014 GoPivotal, Inc. Licensed under the MPL. See http://www.rabbitmq.com/ =INFO REPORT==== 25-Apr-2018::11:11:07 === node : rabbit@WIN-ACC2J7AGNM9 home dir : C:\\Users\\Administrator config file(s) : e:/RabbitMQ Data/rabbitmq.config (not found) cookie hash : kR4NuIdBr2n8/4Qt9uIgqQ== log : E:/RabbitMQ Data/log/rabbit@WIN-ACC2J7AGNM9.log sasl log : E:/RabbitMQ Data/log/rabbit@WIN-ACC2J7AGNM9-sasl.log database dir : e:/RabbitMQ Data/db/rabbit@WIN-ACC2J7AGNM9-mnesia =WARNING REPORT==== 25-Apr-2018::11:11:07 === Kernel poll (epoll, kqueue, etc) is disabled. Throughput and CPU utilization may worsen. =INFO REPORT==== 25-Apr-2018::11:11:08 === Memory limit set to 13095MB of 32738MB total. =INFO REPORT==== 25-Apr-2018::11:11:08 === Disk free limit set to 50MB =INFO REPORT==== 25-Apr-2018::11:11:08 === Limiting to approx 8092 file handles (7280 sockets) =INFO REPORT==== 25-Apr-2018::11:11:38 === Timeout contacting cluster nodes: [\u0026#39;rabbit@WIN-2W6NDAIZBIA\u0026#39;]. BACKGROUND ========== This cluster node was shut down while other nodes were still running. To avoid losing data, you should start the other nodes first, then start this one. To force this node to start, first invoke \u0026#34;rabbitmqctl force_boot\u0026#34;. If you do so, any changes made on other cluster nodes after this one was shut down may be lost. DIAGNOSTICS =========== attempted to contact: [\u0026#39;rabbit@WIN-2W6NDAIZBIA\u0026#39;] rabbit@WIN-2W6NDAIZBIA: * connected to epmd (port 4369) on WIN-2W6NDAIZBIA * epmd reports: node \u0026#39;rabbit\u0026#39; not running at all no other nodes on WIN-2W6NDAIZBIA * suggestion: start the node current node details: - node name: \u0026#39;rabbit@WIN-ACC2J7AGNM9\u0026#39; - home dir: C:\\Users\\Administrator - cookie hash: kR4NuIdBr2n8/4Qt9uIgqQ== 关键的地方在于中间的这段说明：\nThis cluster node was shut down while other nodes were still running. To avoid losing data, you should start the other nodes first, then start this one. To force this node to start, first invoke \u0026#34;rabbitmqctl force_boot\u0026#34;. If you do so, any changes made on other cluster nodes after this one was shut down may be lost. 只要执行rabbitmqctl force_boot，将所有的节点全部强制设置成最后一个关闭的即可。\n"},{"id":88,"href":"/blog/linux/ry3FIUV58AM/","title":"rabbitmq之修改数据和log目录位置位置","section":"📚 我的文章","content":" vim /etc/rabbitmq/rabbitmq-env.conf # I am a complete /etc/rabbitmq/rabbitmq-env.conf file. # Comment lines start with a hash character. # This is a /bin/sh script file - use ordinary envt var syntax MNESIA_BASE=/data/rabbitmq/mnesia LOG_BASE=/data/logs/rabbitmq "},{"id":89,"href":"/blog/ffmpeg/S1EdILNqU0M/","title":"Rematrix is needed between 10 channels and 7.1(wide) but there is not enough","section":"📚 我的文章","content":" 解决办法\n将10个声道拆分成10个音轨\nffmpeg -i INPUTFILE -filter_complex “[0:a]pan=mono|c0=c0[…\n解决办法 # 将10个声道拆分成10个音轨\nffmpeg -i INPUTFILE -filter_complex \u0026#34;[0:a]pan=mono|c0=c0[a0];[0:a]pan=mono|c0=c1[a1];[0:a]pan=mono|c0=c2[a2];[0:a]pan=mono|c0=c3[a3];[0:a]pan=mono|c0=c4[a4];[0:a]pan=mono|c0=c5[a5];[0:a]pan=mono|c0=c6[a6];[0:a]pan=mono|c0=c7[a7];[0:a]pan=mono|c0=c8[a8];[0:a]pan=mono|c0=c9[a9]\u0026#34; -map \u0026#34;[a0]\u0026#34; -map \u0026#34;[a1]\u0026#34; -map \u0026#34;[a2]\u0026#34; -map \u0026#34;[a3]\u0026#34; -map \u0026#34;[a4]\u0026#34; -map \u0026#34;[a5]\u0026#34; -map \u0026#34;[a6]\u0026#34; -map \u0026#34;[a7]\u0026#34; -map \u0026#34;[a8]\u0026#34; -map \u0026#34;[a9]\u0026#34; -vn -c:a pcm_s24le OUTPUTFILE ffmpeg -i INPUTFILE -vn -c:a pcm_s24le -map 0:1 -filter:a:0 \u0026#34;pan=mono|c0=c0\u0026#34; -map 0:1 -filter:a:1 \u0026#34;pan=mono|c0=c1\u0026#34; -map 0:1 -filter:a:2 \u0026#34;pan=mono|c0=c2\u0026#34; -map 0:1 -filter:a:3 \u0026#34;pan=mono|c0=c3\u0026#34; -map 0:1 -filter:a:4 \u0026#34;pan=mono|c0=c4\u0026#34; -map 0:1 -filter:a:5 \u0026#34;pan=mono|c0=c5\u0026#34; -map 0:1 -filter:a:6 \u0026#34;pan=mono|c0=c6\u0026#34; -map 0:1 -filter:a:7 \u0026#34;pan=mono|c0=c7\u0026#34; -map 0:1 -filter:a:8 \u0026#34;pan=mono|c0=c8\u0026#34; -map 0:1 -filter:a:9 \u0026#34;pan=mono|c0=c9\u0026#34; OUTPUTFILE "},{"id":90,"href":"/blog/linux/BJrx8LE98CG/","title":"vsftpd 配置方法及访问控制","section":"📚 我的文章","content":" vsftpd 详细配置说明\nvsftpd常用配置 # #关闭匿名用户访问权限 anonymous_enable=NO #开启本地用户权限 local_enable=YES #开启写权限 write_enable=YES #设置侦听端口 listen_port=21 #写文件时的umask local_umask=002 #被动模式及开放端口段 #pasv_enable=yes #pasv_min_port=30000 #pasv_max_port=50000 #超时时间 #idle_session_timeout=6000000 #data_connection_timeout=6000000 dirmessage_enable=YES xferlog_enable=YES connect_from_port_20=YES xferlog_std_format=YES chroot_local_user=YES chroot_list_enable=YES chroot_list_file=/etc/vsftpd/chroot_list listen=YES pam_service_name=vsftpd userlist_enable=YES tcp_wrappers=YES use_localtime=YES reverse_lookup_enable=NO #convert_charset_enable=0 #local_charset=UTF8 #remote_charset=GB2312 #double_377=1 创建账户\nuseradd -M -s /sbin/nologin -d /mnt/usernamefile/ username for i in name1 name2 name3;do useradd -M -s /sbin/nologin -d /mnt/$i/ $i;done for i in name1 name2 name3;do echo \u0026#34;$i\u0026#34;123 | passwd --stdin $i ;done 创建目录 # mkdir usernamefile chown username:username usernamefile for i in name1 name2 name3;do mkdir /mnt/$i;done for i in name1 name2 name3;do chown $i:$i /mnt/$i/;done chmod -R 770 * vsftpd被动模式 # 1、开启被动模式 # vim vsftpd.conf pasv_enable=YES #开启被动模式 pasv_min_port=3000 #随机最小端口 pasv_max_port=4000 #随机最大端口 2、加载内核 # modprobe ip_conntrack_ftp modprobe ip_nat_ftp 3、防火墙 # vim /etc/sysconfig/iptables 在*filter下加入下 -A OUTPUT -p tcp --sport 3000:4000 -j ACCEPT -A INPUT -p tcp --dport 3000:4000 -j ACCEPT iptables-restore \u0026lt; /etc/sysconfig/iptables 加载iptables配置 vsftpd虚拟用户 # 1、vsftpd安装 # yum -y install vsftpd #vsftpd软件 yum -y install db4-utils #生成虚拟用户认证数据文件命令 2、配置vsftp # vim /etc/vsftpd/vsftpd.conf listen=YES #独立运行vsftpd anonymous_enable=NO #限制匿名用户登录 dirmessage_enable=YES xferlog_enable=YES xferlog_file=/var/log/vsftpd.log xferlog_std_format=YES chroot_list_enable=YES #限制虚拟用户切换目录 chroot_list_file=/etc/vsftpd/chroot_list #限制切换目录的用户列表 chroot_local_user=YES guest_enable=YES #开启虚拟用户认证 guest_username=ftp #映射的真实用户 user_config_dir=/etc/vsftpd/vsftpd_user_conf #虚拟用户配置目录 pam_service_name=vsftpd.vu #vsftpd认证的pam认证模块 local_enable=YES 3、虚拟用户db # cd /etc/vsftpd vim user.txt yuangang #用户名 123456 #密码 db_load -T -t hash -f user.txt /etc/vsftpd/vsftpd_login.db chmod 600 /etc/vsftpd/vsftpd_login.db # 配置pam认证 vim /etc/pam.d/vsftpd.vu auth required /lib/security/pam_userdb.so db=/etc/vsftpd/vsftpd_login account required /lib/security/pam_userdb.so db=/etc/vsftpd/vsftpd_login vim /etc/vsftpd/chroot_list #限制虚拟用户切换目录 ftp yuangang 4、配置虚拟用户 # cd /etc/vsftpd/vsftpd_user_conf vim yuangang write_enable=YES anon_world_readable_only=NO anon_upload_enable=YES anon_mkdir_write_enable=YES anon_other_write_enable=YES local_root=/data/httpd/yuangang # 建立虚拟用户ftp目录 mkdir /data/httpd/yuangang chown -R ftp.root /data/httpd chmod o+rw /data/httpd/yuangang vsftpd cmds_allowed # cmds_allowed=ABOR,CWD,LIST,MDTM,MKD,NLST, PASS,PASV,PORT,PWD,QUIT,RETR,RMD,RNFR, RNTO,SITE,SIZE,STOR,TYPE,USER,ACCT, APPE,CDUP,HELP,MODE,NOOP,REIN,STAT,STOU,STRU,SYST 注意:一定不能使用换行和空格，不然就没效果..\n全部参数 # # ABOR - abort a file transfer 取消文件传输 # CWD - change working directory 更改目录 # DELE - delete a remote file 删除文件 # LIST - list remote files 列目录 # MDTM - return the modification time of a file 返回文件的更新时间 # MKD - make a remote directory 新建文件夹 # NLST - name list of remote directory # PASS - send password # PASV - enter passive mode # PORT - open a data port 打开一个传输端口 # PWD - print working directory 显示当前工作目录 # QUIT - terminate the connection 退出 # RETR - retrieve a remote file 下载文件 # RMD - remove a remote directory # RNFR - rename from # RNTO - rename to # SITE - site-specific commands # SIZE - return the size of a file 返回文件大小 # STOR - store a file on the remote host 上传文件 # TYPE - set transfer type # USER - send username # less common commands: # ACCT* - send account information # APPE - append to a remote file # CDUP - CWD to the parent of the current directory # HELP - return help on using the server # MODE - set transfer mode # NOOP - do nothing # REIN* - reinitialize the connection # STAT - return server status # STOU - store a file uniquely # STRU - set file transfer structure # SYST - return system type 常用参数 # # CWD - change working directory 更改目录 # LIST - list remote files 列目录 # MKD - make a remote directory 新建文件夹 # NLST - name list of remote directory # PWD - print working directory 显示当前工作目录 # RETR - retrieve a remote file 下载文件 # STOR - store a file on the remote host 上传文件 # DELE - delete a remote file 删除文件 # RMD - remove a remote directory 删除目录 # RNFR - rename from 重命名 # RNTO - rename to 重命名 以上是常用的一些参数，大家对照学习一下！\n几个例子 # 1、只能上传。不能下载、删除、重命名。 cmds_allowed＝FEAT,REST,CWD,LIST,MDTM,MKD,NLST,PASS,PASV,PORT,PWD,QUIT,RMD,SIZE,STOR,TYPE,USER,ACCT, APPE,CDUP,HELP,MODE,NOOP,REIN,STAT,STOU,STRU,SYST 2、只能下载。不能上传、删除、重命名。write_enable=NO 3、只能上传、删除、重命名。不能下载。download_enable＝NO 4、只能下载、删除、重命名。不能上传。 cmds_allowed=FEAT,REST,CWD,LIST,MDTM,MKD,NLST,PASS,PASV,PORT,PWD,QUIT,RMD,RNFR,RNTO, RETR,DELE,SIZE,TYPE,USER,ACCT,APPE,CDUP,HELP,MODE,NOOP,REIN,STAT,STOU,STRU,SYST 日志格式解析 # Sun Feb 23 22:08:26 2014 | 6 | 212.73.193.130 | 1023575 |\n/Lille_IconSP/win_230214_52_11.jpg | b| _| i| r| sipafranch| ftp| 0| *| c\n记录 含义\nSun Feb 23 22:08:26 2014 FTP传输时间\n6 传输文件所用时间。单位/秒\n212.73.193.130 ftp客户端名称/IP\n1023575 传输文件大小。单位/Byte\n/Lille_IconSP/win_230214_52_11.jpg 传输文件名，包含路径\nb 传输方式： a以ASCII方式传输; b以二进制(binary)方式传输;\n_ 特殊处理标志位：”_“不做任何处理；”C”文件是压缩格式；”U”文件非压缩格式；”T”文件是tar格式；\ni 传输方向：”i”上传；”o”下载；\nr 用户访问模式：“a”匿名用户；”g”访客模式；”r”系统中用户;\nsipafranch 登录用户名\nftp 服务名称，一般都是ftp\n0 认证方式：”0”无；”1”RFC931认证；\n认证用户id，”*“表示无法获取id c 完成状态：”i”传输未完成；”c”传输已完成；\n"},{"id":91,"href":"/blog/linux/SJ_88EqU0M/","title":"web运维相关查询命令","section":"📚 我的文章","content":" 1. 查看TCP连接状态 # netstat -nat |awk \u0026#39;{print $6}\u0026#39;|sort|uniq -c|sort -rn netstat -n | awk \u0026#39;/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}\u0026#39; 或 netstat -n | awk \u0026#39;/^tcp/ {++state[$NF]}; END {for(key in state) print key,\u0026#34;\\t\u0026#34;,state[key]}\u0026#39; netstat -n | awk \u0026#39;/^tcp/ {++arr[$NF]};END {for(k in arr) print k,\u0026#34;\\t\u0026#34;,arr[k]}\u0026#39; netstat -n |awk \u0026#39;/^tcp/ {print $NF}\u0026#39;|sort|uniq -c|sort -rn netstat -ant | awk \u0026#39;{print $NF}\u0026#39; | grep -v \u0026#39;[a-z]\u0026#39; | sort | uniq -c 以上每一行实现的效果基本相同，在此列出不同的写法，方便对脚本写法的更深理解\n2. 查找请求数请20个IP（常用于查找攻来源） # netstat -anlp|grep 80|grep tcp|awk \u0026#39;{print $5}\u0026#39;|awk -F: \u0026#39;{print $1}\u0026#39;|sort|uniq -c|sort -nr|head -n20 netstat -ant |awk \u0026#39;/:80/{split($5,ip,\u0026#34;:\u0026#34;);++A[ip[1]]}END{for(i in A) print A[i],i}\u0026#39; |sort -rn|head -n20 3. 用tcpdump嗅探80端口的访问看看谁最高 # tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F\u0026#34;.\u0026#34; \u0026#39;{print $1\u0026#34;.\u0026#34;$2\u0026#34;.\u0026#34;$3\u0026#34;.\u0026#34;$4}\u0026#39; | sort | uniq -c | sort -nr |head -20 4. 查找较多time_wait连接 # netstat -n|grep TIME_WAIT|awk \u0026#39;{print $5}\u0026#39;|sort|uniq -c|sort -rn|head -n20 5. 找查较多的SYN连接 # netstat -an | grep SYN | awk \u0026#39;{print $5}\u0026#39; | awk -F: \u0026#39;{print $1}\u0026#39; | sort | uniq -c | sort -nr | more 6. 根据端口列进程 # netstat -ntlp | grep 80 | awk \u0026#39;{print $7}\u0026#39; | cut -d/ -f1 7. 查看有多少个PHP-CGI进程活动 # netstat -anp | grep php-cgi | grep ^tcp | wc -l 8.查看PHP-CGI占用内存的总数 # total=0; for i in `ps -C php-cgi -o rss=`; do total=$(($total+$i)); done; echo \u0026#34;PHP-CGI Memory usage: $total kb\u0026#34; "},{"id":92,"href":"/blog/linux/SytNL84q8Af/","title":"阿里云ECS Linux的rc.local（开机启动）设置不生效","section":"📚 我的文章","content":" none\n使用场景 # 前段时间使用阿里云的ecs，将一些开机启动的命令写到/etc/rc.local里面，发现不生效。经过一番查询和搜索之后，最后发现一个坑，居然要给这个文件设置执行权限才生效。\n解决方法 # chmod +x /etc/rc.local "},{"id":93,"href":"/blog/linux/HJqtULE5I0z/","title":"排查linux根目录空间占用与实际空间不符","section":"📚 我的文章","content":" 发现问题 # 首先使用”df -Th”查看根目录的空间使用和”du -sh /“的结果进行对比。\n排查问题 # 第一种情况 # 文件被删掉，但是写这个文件的进程没退出\nlsof -n|grep delete 使用以上命令得到相关的进程，然后使用得到的pid找到对应的程序，然后重启程序或kill掉即可释放被删除文件的空间。\n第二种情况 # lsof -n|grep delete 没有得到任何返回结果。\n那么我们首先查看下根目录的文件系统，如果是“xfs”,那么可以使用\nxfs_db -c frag -r /dev/sdxx 查看碎片的占比，如果较高的话，那么我们应该整理下xfs的碎片了。\nxfs_fsr /dev/sdxx #整理碎片 然后你再“df”看看释放空间已经释放了。\n备注 # xfs虽然性能比较好，但是稳定性还是有所欠缺，不是很建议使用。\n如果以上的方法没有解决你的问题或者你还有其他情况，欢迎留言一起探讨。\n"}]