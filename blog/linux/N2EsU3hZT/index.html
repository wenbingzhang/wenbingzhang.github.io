<!doctype html><html lang=zh dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content='
ä½¿ç”¨deviceQueryè·å–æ˜¾å¡ä¿¡æ¯


  ç¯å¢ƒ
  #

Linuxã€nvidiaã€cuda

  å‘½ä»¤
  #

/usr/local/cuda/extras/demo_suite/deviceQuery

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 2 CUDA Capable device(s)

Device 0: "GeForce RTX 2080 Ti"
  CUDA Driver Version / Runtime Version          10.1 / 10.1
  CUDA Capability Major/Minor version number:    7.5
  Total amount of global memory:                 11019 MBytes (11554717696 bytes)
  (68) Multiprocessors, ( 64) CUDA Cores/MP:     4352 CUDA Cores
  GPU Max Clock rate:                            1545 MHz (1.54 GHz)
  Memory Clock rate:                             7000 Mhz
  Memory Bus Width:                              352-bit
  L2 Cache Size:                                 5767168 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  1024
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0
  Compute Mode:
     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >

Device 1: "GeForce RTX 2080 Ti"
  CUDA Driver Version / Runtime Version          10.1 / 10.1
  CUDA Capability Major/Minor version number:    7.5
  Total amount of global memory:                 11019 MBytes (11554717696 bytes)
  (68) Multiprocessors, ( 64) CUDA Cores/MP:     4352 CUDA Cores
  GPU Max Clock rate:                            1545 MHz (1.54 GHz)
  Memory Clock rate:                             7000 Mhz
  Memory Bus Width:                              352-bit
  L2 Cache Size:                                 5767168 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  1024
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 2 / 0
  Compute Mode:
     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >
> Peer access from GeForce RTX 2080 Ti (GPU0) -> GeForce RTX 2080 Ti (GPU1) : Yes
> Peer access from GeForce RTX 2080 Ti (GPU1) -> GeForce RTX 2080 Ti (GPU0) : Yes

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.1, CUDA Runtime Version = 10.1, NumDevs = 2

  æºç 
  #

https://github.com/NVIDIA/cuda-samples/tree/master/Samples/deviceQuery'><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://notes.zhangwenbing.com/blog/linux/N2EsU3hZT/"><meta property="og:site_name" content="å¼ æ–‡å…µçš„ç¬”è®°"><meta property="og:title" content="linux nvidia è·å–æ˜¾å¡ä¿¡æ¯"><meta property="og:description" content=' ä½¿ç”¨deviceQueryè·å–æ˜¾å¡ä¿¡æ¯
ç¯å¢ƒ # Linuxã€nvidiaã€cuda
å‘½ä»¤ # /usr/local/cuda/extras/demo_suite/deviceQuery CUDA Device Query (Runtime API) version (CUDART static linking) Detected 2 CUDA Capable device(s) Device 0: "GeForce RTX 2080 Ti" CUDA Driver Version / Runtime Version 10.1 / 10.1 CUDA Capability Major/Minor version number: 7.5 Total amount of global memory: 11019 MBytes (11554717696 bytes) (68) Multiprocessors, ( 64) CUDA Cores/MP: 4352 CUDA Cores GPU Max Clock rate: 1545 MHz (1.54 GHz) Memory Clock rate: 7000 Mhz Memory Bus Width: 352-bit L2 Cache Size: 5767168 bytes Maximum Texture Dimension Size (x,y,z) 1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384) Maximum Layered 1D Texture Size, (num) layers 1D=(32768), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(32768, 32768), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 1024 Maximum number of threads per block: 1024 Max dimension size of a thread block (x,y,z): (1024, 1024, 64) Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535) Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and kernel execution: Yes with 3 copy engine(s) Run time limit on kernels: No Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Alignment requirement for Surfaces: Yes Device has ECC support: Disabled Device supports Unified Addressing (UVA): Yes Device supports Compute Preemption: Yes Supports Cooperative Kernel Launch: Yes Supports MultiDevice Co-op Kernel Launch: Yes Device PCI Domain ID / Bus ID / location ID: 0 / 1 / 0 Compute Mode: < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) > Device 1: "GeForce RTX 2080 Ti" CUDA Driver Version / Runtime Version 10.1 / 10.1 CUDA Capability Major/Minor version number: 7.5 Total amount of global memory: 11019 MBytes (11554717696 bytes) (68) Multiprocessors, ( 64) CUDA Cores/MP: 4352 CUDA Cores GPU Max Clock rate: 1545 MHz (1.54 GHz) Memory Clock rate: 7000 Mhz Memory Bus Width: 352-bit L2 Cache Size: 5767168 bytes Maximum Texture Dimension Size (x,y,z) 1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384) Maximum Layered 1D Texture Size, (num) layers 1D=(32768), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(32768, 32768), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 1024 Maximum number of threads per block: 1024 Max dimension size of a thread block (x,y,z): (1024, 1024, 64) Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535) Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and kernel execution: Yes with 3 copy engine(s) Run time limit on kernels: No Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Alignment requirement for Surfaces: Yes Device has ECC support: Disabled Device supports Unified Addressing (UVA): Yes Device supports Compute Preemption: Yes Supports Cooperative Kernel Launch: Yes Supports MultiDevice Co-op Kernel Launch: Yes Device PCI Domain ID / Bus ID / location ID: 0 / 2 / 0 Compute Mode: < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) > > Peer access from GeForce RTX 2080 Ti (GPU0) -> GeForce RTX 2080 Ti (GPU1) : Yes > Peer access from GeForce RTX 2080 Ti (GPU1) -> GeForce RTX 2080 Ti (GPU0) : Yes deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.1, CUDA Runtime Version = 10.1, NumDevs = 2 æºç  # https://github.com/NVIDIA/cuda-samples/tree/master/Samples/deviceQuery'><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-06-04T06:40:16+08:00"><meta property="article:modified_time" content="2020-06-04T06:40:16+08:00"><meta property="article:tag" content="Linux"><title>linux nvidia è·å–æ˜¾å¡ä¿¡æ¯ | å¼ æ–‡å…µçš„ç¬”è®°</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png><link rel=canonical href=https://notes.zhangwenbing.com/blog/linux/N2EsU3hZT/><link rel=stylesheet href=/book.min.7bc0bb908f28131671779537cc0c91a39075ed4cba93497f05888d37375171ce.css integrity="sha256-e8C7kI8oExZxd5U3zAyRo5B17Uy6k0l/BYiNNzdRcc4=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/zh.search.min.210aa5fca8aef8461939aafd1f59c5ca5f752cf863a04c07586f0cc5165c0b65.js integrity="sha256-IQql/Kiu+EYZOar9H1nFyl91LPhjoEwHWG8MxRZcC2U=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>å¼ æ–‡å…µçš„ç¬”è®°</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=æœç´¢ aria-label=æœç´¢ maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-6d1804e163fb7f5fbc576b94719a59cb class=toggle>
<label for=section-6d1804e163fb7f5fbc576b94719a59cb class="flex justify-between"><a role=button>ğŸ‘¨ğŸ¼â€ğŸ’» ç¼–ç¨‹ç›¸å…³</a></label><ul><li><input type=checkbox id=section-8ec8d24621de2d29aa3aa48e5e4147bf class=toggle>
<label for=section-8ec8d24621de2d29aa3aa48e5e4147bf class="flex justify-between"><a role=button>ğŸ“” C/C++</a></label><ul><li><input type=checkbox id=section-3436919d500fd2bb71607f1799c530e9 class=toggle>
<label for=section-3436919d500fd2bb71607f1799c530e9 class="flex justify-between"><a role=button>ğŸ”– MacOS</a></label><ul><li><a href=/notes/2024/06/06/sf4ff6x8cuyhvzougj9dwg/>ğŸ“ MacOSç­¾å</a></li><li><a href=/notes/2024/05/28/3txbbb7iruppjsg4p7rwnb/>ğŸ“ MacOSå †æ ˆå¤§å°</a></li></ul></li><li><input type=checkbox id=section-9c529f10c7b539e237ae1f42d47b905f class=toggle>
<label for=section-9c529f10c7b539e237ae1f42d47b905f class="flex justify-between"><a role=button>ğŸ”– QtWidget</a></label><ul><li><a href=/notes/2025/05/13/gfegatfpustuecdeaifds7/>ğŸ“ deferå®ç°</a></li><li><a href=/notes/2025/05/13/6dhpyx7jyybzrnvw7qremy/>ğŸ“ å¼‚æ­¥æ›´æ–°UI</a></li></ul></li><li><input type=checkbox id=section-3be7c6476ab3ef4abcb7bd8a29aca7ca class=toggle>
<label for=section-3be7c6476ab3ef4abcb7bd8a29aca7ca class="flex justify-between"><a role=button>ğŸ”– QtQml</a></label><ul><li><a href=/notes/2024/08/01/rnc4n7cfifidx8ca2rhjme/>ğŸ“ QMLé¼ æ ‡äº‹ä»¶</a></li><li><a href=/notes/2024/08/06/ny773erqjgbzmzgfikfvds/>ğŸ“ QMLè™šæ‹Ÿåˆ—è¡¨</a></li></ul></li><li><input type=checkbox id=section-543c46644dbaa17c070d1fbbe6f809c8 class=toggle>
<label for=section-543c46644dbaa17c070d1fbbe6f809c8 class="flex justify-between"><a role=button>ğŸ”– build</a></label><ul><li><a href=/notes/2025/04/28/akhjvrsank3gkyirsrxgtc/>ğŸ“ è¿è¡Œæ˜¯å´©æºƒ</a></li><li><a href=/notes/2025/04/30/fqog2lfxmepcxbbyzucxeq/>ğŸ“ å†…å­˜é‡å </a></li></ul></li><li><input type=checkbox id=section-7ef42c94e3a59c5cb77c843c093effb8 class=toggle>
<label for=section-7ef42c94e3a59c5cb77c843c093effb8 class="flex justify-between"><a role=button>ğŸ”– Python</a></label><ul><li><a href=/notes/2025/02/10/7auahqg8nnxm5ydhxzqrnr/>ğŸ“ è°ƒç”¨Pythonä»£ç </a></li><li><a href=/notes/2025/02/10/gqci9riugfetribe6j6fou/>ğŸ“ è°ƒç”¨Pythonæ–¹æ³•</a></li><li><a href=/notes/2025/02/10/pkdrvn9md3ggfmbxahx4ef/>ğŸ“ æ³¨å†ŒPythonæ¨¡å—</a></li></ul></li></ul></li><li><input type=checkbox id=section-aea9addc7ea0cf58a2c2c9ec52f959c9 class=toggle>
<label for=section-aea9addc7ea0cf58a2c2c9ec52f959c9 class="flex justify-between"><a role=button>ğŸ“” Git</a></label><ul><li><a href=/notes/2024/03/11/j3c62fv8dglvf2kg975zlv/>ğŸ“ æ ‡ç­¾æ“ä½œ</a></li><li><a href=/notes/2024/03/14/5kqlzqjqawbxf2t6vusxar/>ğŸ“ åˆ é™¤Commit</a></li><li><a href=/blog/git/WNYzxj6GR/>ğŸ“ gitä¹‹åˆ é™¤è¿œç¨‹åˆ†æ”¯</a></li><li><a href=/blog/git/-fZeBsu3T/>ğŸ“ gitæ›´æ–°.gitignore</a></li><li><a href=/blog/git/H1Krv6b-4/>ğŸ“ gitä¿®æ”¹å†å²cimmitä¿¡æ¯</a></li><li><a href=/blog/git/By9OI51xN/>ğŸ“ gitåŸºç¡€ç¬”è®°</a></li><li><a href=/blog/git/Hk6GGp6cQ/>ğŸ“ Gitå›æ»šåˆ°æŸä¸ªcommit</a></li></ul></li></ul></li><li><input type=checkbox id=section-caf3b688bb818cc6cfc82165db78eba5 class=toggle>
<label for=section-caf3b688bb818cc6cfc82165db78eba5 class="flex justify-between"><a role=button>â™»ï¸ å›æ”¶å½’æ¡£</a></label><ul><li><input type=checkbox id=section-4a72fedb3d7dfc18dbbcab83511bf75a class=toggle>
<label for=section-4a72fedb3d7dfc18dbbcab83511bf75a class="flex justify-between"><a role=button>ğŸ“” Rust</a></label><ul><li><input type=checkbox id=section-8aa26b33a0315c1be70924160dd1a92c class=toggle>
<label for=section-8aa26b33a0315c1be70924160dd1a92c class="flex justify-between"><a role=button>ğŸ”– å­¦ä¹ ç¬”è®°</a></label><ul><li><a href=/notes/2024/03/06/e3ksq3zkmps14gcxuirwzx/>ğŸ“ æ‰€æœ‰æƒ</a></li><li><a href=/notes/2024/03/06/o4arkqgfnqygr5ckif2gkk/>ğŸ“ å€Ÿç”¨ä¸å¼•ç”¨</a></li></ul></li></ul></li></ul></li><li><a href=/links/>ğŸ¤ å‹æƒ…é“¾æ¥</a></li></ul><ul><li><a href=/articles/>ğŸ“š æˆ‘çš„æ–‡ç« </a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>linux nvidia è·å–æ˜¾å¡ä¿¡æ¯</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#ç¯å¢ƒ>ç¯å¢ƒ</a></li><li><a href=#å‘½ä»¤>å‘½ä»¤</a></li><li><a href=#æºç >æºç </a><ul><li><a href=#ç¼–è¯‘>ç¼–è¯‘</a></li></ul></li></ul></nav></aside></header><article class="markdown book-post"><h1 class=book-post-title><a href=/blog/linux/N2EsU3hZT/>linux nvidia è·å–æ˜¾å¡ä¿¡æ¯</a></h1><div class=book-post-meta><span class=book-post-meta-date>2020-06-04</span>
<span class=book-post-meta-separator-categories>&nbsp; | &nbsp;</span>
<span class=book-post-meta-categories><a href=/categories/linux/>Linux</a>
</span><span class=book-post-meta-separator-tags>&nbsp; | &nbsp;</span>
<span class=book-post-meta-tags><a href=/tags/linux/>Linux</a></span></div><blockquote><p>ä½¿ç”¨deviceQueryè·å–æ˜¾å¡ä¿¡æ¯</p></blockquote><h2 id=ç¯å¢ƒ>ç¯å¢ƒ
<a class=anchor href=#%e7%8e%af%e5%a2%83>#</a></h2><p>Linuxã€nvidiaã€cuda</p><h2 id=å‘½ä»¤>å‘½ä»¤
<a class=anchor href=#%e5%91%bd%e4%bb%a4>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>/usr/local/cuda/extras/demo_suite/deviceQuery
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span> CUDA Device Query <span style=color:#f92672>(</span>Runtime API<span style=color:#f92672>)</span> version <span style=color:#f92672>(</span>CUDART static linking<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Detected <span style=color:#ae81ff>2</span> CUDA Capable device<span style=color:#f92672>(</span>s<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Device 0: <span style=color:#e6db74>&#34;GeForce RTX 2080 Ti&#34;</span>
</span></span><span style=display:flex><span>  CUDA Driver Version / Runtime Version          10.1 / 10.1
</span></span><span style=display:flex><span>  CUDA Capability Major/Minor version number:    7.5
</span></span><span style=display:flex><span>  Total amount of global memory:                 <span style=color:#ae81ff>11019</span> MBytes <span style=color:#f92672>(</span><span style=color:#ae81ff>11554717696</span> bytes<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>(</span>68<span style=color:#f92672>)</span> Multiprocessors, <span style=color:#f92672>(</span> 64<span style=color:#f92672>)</span> CUDA Cores/MP:     <span style=color:#ae81ff>4352</span> CUDA Cores
</span></span><span style=display:flex><span>  GPU Max Clock rate:                            <span style=color:#ae81ff>1545</span> MHz <span style=color:#f92672>(</span>1.54 GHz<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  Memory Clock rate:                             <span style=color:#ae81ff>7000</span> Mhz
</span></span><span style=display:flex><span>  Memory Bus Width:                              352-bit
</span></span><span style=display:flex><span>  L2 Cache Size:                                 <span style=color:#ae81ff>5767168</span> bytes
</span></span><span style=display:flex><span>  Maximum Texture Dimension Size <span style=color:#f92672>(</span>x,y,z<span style=color:#f92672>)</span>         1D<span style=color:#f92672>=(</span>131072<span style=color:#f92672>)</span>, 2D<span style=color:#f92672>=(</span>131072, 65536<span style=color:#f92672>)</span>, 3D<span style=color:#f92672>=(</span>16384, 16384, 16384<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  Maximum Layered 1D Texture Size, <span style=color:#f92672>(</span>num<span style=color:#f92672>)</span> layers  1D<span style=color:#f92672>=(</span>32768<span style=color:#f92672>)</span>, <span style=color:#ae81ff>2048</span> layers
</span></span><span style=display:flex><span>  Maximum Layered 2D Texture Size, <span style=color:#f92672>(</span>num<span style=color:#f92672>)</span> layers  2D<span style=color:#f92672>=(</span>32768, 32768<span style=color:#f92672>)</span>, <span style=color:#ae81ff>2048</span> layers
</span></span><span style=display:flex><span>  Total amount of constant memory:               <span style=color:#ae81ff>65536</span> bytes
</span></span><span style=display:flex><span>  Total amount of shared memory per block:       <span style=color:#ae81ff>49152</span> bytes
</span></span><span style=display:flex><span>  Total number of registers available per block: <span style=color:#ae81ff>65536</span>
</span></span><span style=display:flex><span>  Warp size:                                     <span style=color:#ae81ff>32</span>
</span></span><span style=display:flex><span>  Maximum number of threads per multiprocessor:  <span style=color:#ae81ff>1024</span>
</span></span><span style=display:flex><span>  Maximum number of threads per block:           <span style=color:#ae81ff>1024</span>
</span></span><span style=display:flex><span>  Max dimension size of a thread block <span style=color:#f92672>(</span>x,y,z<span style=color:#f92672>)</span>: <span style=color:#f92672>(</span>1024, 1024, 64<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  Max dimension size of a grid size    <span style=color:#f92672>(</span>x,y,z<span style=color:#f92672>)</span>: <span style=color:#f92672>(</span>2147483647, 65535, 65535<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  Maximum memory pitch:                          <span style=color:#ae81ff>2147483647</span> bytes
</span></span><span style=display:flex><span>  Texture alignment:                             <span style=color:#ae81ff>512</span> bytes
</span></span><span style=display:flex><span>  Concurrent copy and kernel execution:          Yes with <span style=color:#ae81ff>3</span> copy engine<span style=color:#f92672>(</span>s<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  Run time limit on kernels:                     No
</span></span><span style=display:flex><span>  Integrated GPU sharing Host Memory:            No
</span></span><span style=display:flex><span>  Support host page-locked memory mapping:       Yes
</span></span><span style=display:flex><span>  Alignment requirement <span style=color:#66d9ef>for</span> Surfaces:            Yes
</span></span><span style=display:flex><span>  Device has ECC support:                        Disabled
</span></span><span style=display:flex><span>  Device supports Unified Addressing <span style=color:#f92672>(</span>UVA<span style=color:#f92672>)</span>:      Yes
</span></span><span style=display:flex><span>  Device supports Compute Preemption:            Yes
</span></span><span style=display:flex><span>  Supports Cooperative Kernel Launch:            Yes
</span></span><span style=display:flex><span>  Supports MultiDevice Co-op Kernel Launch:      Yes
</span></span><span style=display:flex><span>  Device PCI Domain ID / Bus ID / location ID:   <span style=color:#ae81ff>0</span> / <span style=color:#ae81ff>1</span> / <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>  Compute Mode:
</span></span><span style=display:flex><span>     &lt; Default <span style=color:#f92672>(</span>multiple host threads can use ::cudaSetDevice<span style=color:#f92672>()</span> with device simultaneously<span style=color:#f92672>)</span> &gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Device 1: <span style=color:#e6db74>&#34;GeForce RTX 2080 Ti&#34;</span>
</span></span><span style=display:flex><span>  CUDA Driver Version / Runtime Version          10.1 / 10.1
</span></span><span style=display:flex><span>  CUDA Capability Major/Minor version number:    7.5
</span></span><span style=display:flex><span>  Total amount of global memory:                 <span style=color:#ae81ff>11019</span> MBytes <span style=color:#f92672>(</span><span style=color:#ae81ff>11554717696</span> bytes<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>(</span>68<span style=color:#f92672>)</span> Multiprocessors, <span style=color:#f92672>(</span> 64<span style=color:#f92672>)</span> CUDA Cores/MP:     <span style=color:#ae81ff>4352</span> CUDA Cores
</span></span><span style=display:flex><span>  GPU Max Clock rate:                            <span style=color:#ae81ff>1545</span> MHz <span style=color:#f92672>(</span>1.54 GHz<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  Memory Clock rate:                             <span style=color:#ae81ff>7000</span> Mhz
</span></span><span style=display:flex><span>  Memory Bus Width:                              352-bit
</span></span><span style=display:flex><span>  L2 Cache Size:                                 <span style=color:#ae81ff>5767168</span> bytes
</span></span><span style=display:flex><span>  Maximum Texture Dimension Size <span style=color:#f92672>(</span>x,y,z<span style=color:#f92672>)</span>         1D<span style=color:#f92672>=(</span>131072<span style=color:#f92672>)</span>, 2D<span style=color:#f92672>=(</span>131072, 65536<span style=color:#f92672>)</span>, 3D<span style=color:#f92672>=(</span>16384, 16384, 16384<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  Maximum Layered 1D Texture Size, <span style=color:#f92672>(</span>num<span style=color:#f92672>)</span> layers  1D<span style=color:#f92672>=(</span>32768<span style=color:#f92672>)</span>, <span style=color:#ae81ff>2048</span> layers
</span></span><span style=display:flex><span>  Maximum Layered 2D Texture Size, <span style=color:#f92672>(</span>num<span style=color:#f92672>)</span> layers  2D<span style=color:#f92672>=(</span>32768, 32768<span style=color:#f92672>)</span>, <span style=color:#ae81ff>2048</span> layers
</span></span><span style=display:flex><span>  Total amount of constant memory:               <span style=color:#ae81ff>65536</span> bytes
</span></span><span style=display:flex><span>  Total amount of shared memory per block:       <span style=color:#ae81ff>49152</span> bytes
</span></span><span style=display:flex><span>  Total number of registers available per block: <span style=color:#ae81ff>65536</span>
</span></span><span style=display:flex><span>  Warp size:                                     <span style=color:#ae81ff>32</span>
</span></span><span style=display:flex><span>  Maximum number of threads per multiprocessor:  <span style=color:#ae81ff>1024</span>
</span></span><span style=display:flex><span>  Maximum number of threads per block:           <span style=color:#ae81ff>1024</span>
</span></span><span style=display:flex><span>  Max dimension size of a thread block <span style=color:#f92672>(</span>x,y,z<span style=color:#f92672>)</span>: <span style=color:#f92672>(</span>1024, 1024, 64<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  Max dimension size of a grid size    <span style=color:#f92672>(</span>x,y,z<span style=color:#f92672>)</span>: <span style=color:#f92672>(</span>2147483647, 65535, 65535<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  Maximum memory pitch:                          <span style=color:#ae81ff>2147483647</span> bytes
</span></span><span style=display:flex><span>  Texture alignment:                             <span style=color:#ae81ff>512</span> bytes
</span></span><span style=display:flex><span>  Concurrent copy and kernel execution:          Yes with <span style=color:#ae81ff>3</span> copy engine<span style=color:#f92672>(</span>s<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  Run time limit on kernels:                     No
</span></span><span style=display:flex><span>  Integrated GPU sharing Host Memory:            No
</span></span><span style=display:flex><span>  Support host page-locked memory mapping:       Yes
</span></span><span style=display:flex><span>  Alignment requirement <span style=color:#66d9ef>for</span> Surfaces:            Yes
</span></span><span style=display:flex><span>  Device has ECC support:                        Disabled
</span></span><span style=display:flex><span>  Device supports Unified Addressing <span style=color:#f92672>(</span>UVA<span style=color:#f92672>)</span>:      Yes
</span></span><span style=display:flex><span>  Device supports Compute Preemption:            Yes
</span></span><span style=display:flex><span>  Supports Cooperative Kernel Launch:            Yes
</span></span><span style=display:flex><span>  Supports MultiDevice Co-op Kernel Launch:      Yes
</span></span><span style=display:flex><span>  Device PCI Domain ID / Bus ID / location ID:   <span style=color:#ae81ff>0</span> / <span style=color:#ae81ff>2</span> / <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>  Compute Mode:
</span></span><span style=display:flex><span>     &lt; Default <span style=color:#f92672>(</span>multiple host threads can use ::cudaSetDevice<span style=color:#f92672>()</span> with device simultaneously<span style=color:#f92672>)</span> &gt;
</span></span><span style=display:flex><span>&gt; Peer access from GeForce RTX <span style=color:#ae81ff>2080</span> Ti <span style=color:#f92672>(</span>GPU0<span style=color:#f92672>)</span> -&gt; GeForce RTX <span style=color:#ae81ff>2080</span> Ti <span style=color:#f92672>(</span>GPU1<span style=color:#f92672>)</span> : Yes
</span></span><span style=display:flex><span>&gt; Peer access from GeForce RTX <span style=color:#ae81ff>2080</span> Ti <span style=color:#f92672>(</span>GPU1<span style=color:#f92672>)</span> -&gt; GeForce RTX <span style=color:#ae81ff>2080</span> Ti <span style=color:#f92672>(</span>GPU0<span style=color:#f92672>)</span> : Yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>deviceQuery, CUDA Driver <span style=color:#f92672>=</span> CUDART, CUDA Driver Version <span style=color:#f92672>=</span> 10.1, CUDA Runtime Version <span style=color:#f92672>=</span> 10.1, NumDevs <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>
</span></span></code></pre></div><h2 id=æºç >æºç 
<a class=anchor href=#%e6%ba%90%e7%a0%81>#</a></h2><p><a href=https://github.com/NVIDIA/cuda-samples/tree/master/Samples/deviceQuery>https://github.com/NVIDIA/cuda-samples/tree/master/Samples/deviceQuery</a></p><h3 id=ç¼–è¯‘>ç¼–è¯‘
<a class=anchor href=#%e7%bc%96%e8%af%91>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>/usr/local/cuda/bin/nvcc deviceQuery.cpp -I /usr/local/cuda/samples/common/inc/ -o deviceQuery
</span></span></code></pre></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#ç¯å¢ƒ>ç¯å¢ƒ</a></li><li><a href=#å‘½ä»¤>å‘½ä»¤</a></li><li><a href=#æºç >æºç </a><ul><li><a href=#ç¼–è¯‘>ç¼–è¯‘</a></li></ul></li></ul></nav></div></aside></main><footer class=page-footer><p><span id=page-footer-time>è½½å…¥ä¸­...</span>
<script>function secondToDate(e){if(!e)return 0;var t=new Array(0,0,0,0,0);return e>=365*24*3600&&(t[0]=parseInt(e/(365*24*3600)),e%=365*24*3600),e>=24*3600&&(t[1]=parseInt(e/(24*3600)),e%=24*3600),e>=3600&&(t[2]=parseInt(e/3600),e%=3600),e>=60&&(t[3]=parseInt(e/60),e%=60),e>0&&(t[4]=e),t}</script><script type=text/javascript language=javascript>function setTime(){var e=Math.round(new Date(Date.UTC(2016,11,1,0,0,0)).getTime()/1e3),t=Math.round(((new Date).getTime()+8*60*60*1e3)/1e3);currentTime=secondToDate(t-e),currentTimeHtml=currentTime[0]+"å¹´"+currentTime[1]+"å¤©"+currentTime[2]+"æ—¶"+currentTime[3]+"åˆ†"+currentTime[4]+"ç§’",document.getElementById("page-footer-time").innerHTML="ç½‘ç«™è¿è¡Œ:"+currentTimeHtml}setInterval(setTime,1e3)</script></p></footer></body></html>